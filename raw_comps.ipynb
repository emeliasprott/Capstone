{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Legislative dashboard precomputations\n",
        "\n",
        "This notebook consolidates the preprocessing required for the interactive dashboard. It reads the\n",
        "canonical tables produced by the ETL pipeline, derives descriptive features, and serialises the\n",
        "results in a `precomp_outputs` dictionary consumed by the front-end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import warnings\n",
        "from collections import Counter, defaultdict\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    import geopandas as gpd\n",
        "except Exception:\n",
        "    gpd = None\n",
        "\n",
        "pd.options.display.float_format = \"{:,.3f}\".format\n",
        "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "DATA_DIR = Path(\"ca_leg/legislation_data\")\n",
        "CALACCESS_DIR = Path(\"calaccess\")\n",
        "MAP_DIR = Path(\"dashboard/backend/data\")\n",
        "LABELS_PATH = Path(\"bill_labels_updated.json\")\n",
        "\n",
        "\n",
        "def read_csv_safe(path: Path, **kwargs) -> pd.DataFrame:\n",
        "    if not path.exists():\n",
        "        warnings.warn(f\"Missing data file: {path}\")\n",
        "        return pd.DataFrame()\n",
        "    return pd.read_csv(path, **kwargs)\n",
        "\n",
        "\n",
        "bill_history = read_csv_safe(DATA_DIR / \"bill_history_tbl.csv\",\n",
        "                             dtype={\"action_status\": str, \"primary_location\": str,\n",
        "                                    \"secondary_location\": str, \"end_status\": str})\n",
        "bill_history.rename(columns={c: c.lower() for c in bill_history.columns}, inplace=True)\n",
        "\n",
        "history = read_csv_safe(DATA_DIR / \"history.csv\")\n",
        "history.rename(columns={c: c.lower() for c in history.columns}, inplace=True)\n",
        "\n",
        "bill_versions = read_csv_safe(DATA_DIR / \"bill_versions.csv\")\n",
        "bill_versions.rename(columns={c: c.lower() for c in bill_versions.columns}, inplace=True)\n",
        "\n",
        "bill_summary_votes = read_csv_safe(DATA_DIR / \"bill_summary_vote_tbl.csv\")\n",
        "bill_summary_votes.rename(columns={c: c.lower() for c in bill_summary_votes.columns}, inplace=True)\n",
        "\n",
        "bill_votes = read_csv_safe(DATA_DIR / \"bill_detail_vote_tbl.csv\", parse_dates=[\"session_date\", \"vote_date_time\"])\n",
        "bill_votes.rename(columns={c: c.lower() for c in bill_votes.columns}, inplace=True)\n",
        "\n",
        "bill_motions = read_csv_safe(DATA_DIR / \"bill_motion_tbl.csv\")\n",
        "bill_motions.rename(columns={c: c.lower() for c in bill_motions.columns}, inplace=True)\n",
        "\n",
        "committee_codes = read_csv_safe(DATA_DIR / \"committee_codes.csv\")\n",
        "committee_codes.rename(columns={c: c.lower() for c in committee_codes.columns}, inplace=True)\n",
        "\n",
        "committee_hearings = read_csv_safe(DATA_DIR / \"committee_hearing_tbl.csv\")\n",
        "committee_hearings.rename(columns={c: c.lower() for c in committee_hearings.columns}, inplace=True)\n",
        "\n",
        "authors = read_csv_safe(DATA_DIR / \"authors.csv\")\n",
        "authors.rename(columns={c: c.lower() for c in authors.columns}, inplace=True)\n",
        "\n",
        "digests = read_csv_safe(DATA_DIR / \"digest.csv\")\n",
        "digests.rename(columns={c: c.lower() for c in digests.columns}, inplace=True)\n",
        "\n",
        "politicians = read_csv_safe(DATA_DIR / \"politicians.csv\")\n",
        "politicians.rename(columns={c: c.lower() for c in politicians.columns}, inplace=True)\n",
        "\n",
        "lobbying = read_csv_safe(CALACCESS_DIR / \"lobbying_clean2.csv\",\n",
        "                         dtype={\"PAYEE_NAMS\": str, \"BAKREF_TID\": str})\n",
        "expend_assembly = read_csv_safe(CALACCESS_DIR / \"expend_assembly_matched.csv\",\n",
        "                                dtype={\"TargetPropositionName\": str})\n",
        "expend_senate = read_csv_safe(CALACCESS_DIR / \"expend_senate_matched.csv\",\n",
        "                              dtype={\"TargetPropositionName\": str})\n",
        "\n",
        "with LABELS_PATH.open() as fp:\n",
        "    bill_topics = json.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Canonical identifiers ---------------------------------------------------------------------\n",
        "\n",
        "bill_versions = bill_versions.assign(\n",
        "    version_id=bill_versions.get(\"id\", bill_versions.get(\"ID\")),\n",
        "    bill_id_canonical=bill_versions.groupby(\"bill_id\")[\"bill_id\"].transform(\"first\"),\n",
        ")\n",
        "\n",
        "version_to_bill = bill_versions.set_index(\"bill_id\").get(\"bill_id_canonical\", pd.Series(dtype=str)).to_dict()\n",
        "if not version_to_bill:\n",
        "    version_to_bill = bill_versions.set_index(\"bill_id\")\n",
        "\n",
        "for frame in [history, bill_history, bill_votes, bill_summary_votes, committee_hearings, digests]:\n",
        "    if frame.empty:\n",
        "        continue\n",
        "    if \"bill_id\" in frame.columns:\n",
        "        frame[\"bill_id\"] = frame[\"bill_id\"].map(version_to_bill).fillna(frame[\"bill_id\"])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Date harmonisation ------------------------------------------------------------------------\n",
        "\n",
        "for df, cols in [\n",
        "    (history, [\"date\", \"action_date\", \"actiondate\"]),\n",
        "    (bill_history, [\"action_date\", \"date\"]),\n",
        "    (bill_votes, [\"vote_date_time\", \"vote_date\", \"session_date\"]),\n",
        "    (bill_summary_votes, [\"vote_date\", \"session_date\"]),\n",
        "    (committee_hearings, [\"hearing_date\"]),\n",
        "]:\n",
        "    if df.empty:\n",
        "        continue\n",
        "    for col in cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
        "\n",
        "if not bill_votes.empty:\n",
        "    bill_votes[\"term\"] = bill_votes[\"vote_date_time\"].apply(\n",
        "        lambda ts: f\"{ts.year}-{ts.year + 1}\" if ts.year % 2 else\n",
        "        (f\"{ts.year - 1}-{ts.year}\" if ts.month < 11 else f\"{ts.year + 1}-{ts.year + 2}\")\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Helpers -----------------------------------------------------------------------------------\n",
        "\n",
        "def canonical_topic(bill_id):\n",
        "    return bill_topics.get(str(bill_id))\n",
        "\n",
        "\n",
        "def infer_origin_chamber(bill_id):\n",
        "    bill_id = str(bill_id or \"\")\n",
        "    if bill_id.startswith(\"AB\"):\n",
        "        return \"Assembly\"\n",
        "    if bill_id.startswith(\"SB\"):\n",
        "        return \"Senate\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def weeks_between(start, end):\n",
        "    if pd.isna(start) or pd.isna(end):\n",
        "        return np.nan\n",
        "    return (pd.to_datetime(end) - pd.to_datetime(start)).days / 7.0\n",
        "\n",
        "\n",
        "def infer_term_from_date(ts):\n",
        "    ts = pd.to_datetime(ts, errors='coerce')\n",
        "    if pd.isna(ts):\n",
        "        return None\n",
        "    year = ts.year\n",
        "    if year % 2 == 1:\n",
        "        return f\"{year}-{year + 1}\"\n",
        "    return f\"{year - 1}-{year}\" if ts.month < 11 else f\"{year + 1}-{year + 2}\"\n",
        "\n",
        "\n",
        "VOTE_MAP = {\"AYE\": 1, \"YES\": 1, \"NO\": -1, \"NOE\": -1}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Roll call aggregation ---------------------------------------------------------------------\n",
        "\n",
        "votes = bill_votes.copy()\n",
        "if not votes.empty:\n",
        "    votes[\"vote_value\"] = votes[\"vote_code\"].str.upper().map(VOTE_MAP).fillna(0).astype(int)\n",
        "    votes[\"date\"] = votes[\"vote_date_time\"].dt.date\n",
        "    votes[\"is_floor\"] = votes[\"location_code\"].isin([\"AFLOOR\", \"SFLOOR\"])\n",
        "    votes[\"is_committee\"] = ~votes[\"is_floor\"]\n",
        "else:\n",
        "    votes = pd.DataFrame(columns=[\"bill_id\", \"vote_value\", \"date\", \"is_floor\", \"is_committee\", \"motion_id\", \"term\", \"location_code\"])\n",
        "\n",
        "roll_group_cols = [\"bill_id\", \"date\", \"motion_id\", \"location_code\", \"is_floor\", \"is_committee\", \"term\"]\n",
        "roll = (votes\n",
        "        .groupby(roll_group_cols, dropna=False)\n",
        "        .agg(yes=(\"vote_value\", lambda x: int((np.array(x) > 0).sum())),\n",
        "             no=(\"vote_value\", lambda x: int((np.array(x) < 0).sum())),\n",
        "             total=(\"vote_value\", \"count\"))\n",
        "        .reset_index()) if not votes.empty else pd.DataFrame(columns=roll_group_cols + [\"yes\", \"no\", \"total\"])\n",
        "roll[\"pass\"] = roll.get(\"yes\", 0) > roll.get(\"no\", 0)\n",
        "\n",
        "motion_lookup = bill_motions.set_index(\"motion_id\").get(\"motion_text\", pd.Series(dtype=str)).to_dict() if not bill_motions.empty else {}\n",
        "roll[\"motion_text\"] = roll[\"motion_id\"].map(motion_lookup) if \"motion_id\" in roll.columns else None"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Stage timing -------------------------------------------------------------------------------\n",
        "\n",
        "intro_lookup = (history.groupby(\"bill_id\")[\"date\"].min()\n",
        "                .combine_first(bill_history.groupby(\"bill_id\")[\"action_date\"].min())) if not history.empty else pd.Series(dtype=\"datetime64[ns]\")\n",
        "last_action_lookup = (history.groupby(\"bill_id\")[\"date\"].max()\n",
        "                      .combine_first(bill_history.groupby(\"bill_id\")[\"action_date\"].max())) if not history.empty else pd.Series(dtype=\"datetime64[ns]\")\n",
        "\n",
        "def _stage_dates(group: pd.DataFrame):\n",
        "    g = group.sort_values(\"date\")\n",
        "    intro = intro_lookup.get(group.name, pd.NaT)\n",
        "    first_committee = g.loc[g[\"is_committee\"], \"date\"].min() if g.get(\"is_committee\", pd.Series()).any() else pd.NaT\n",
        "    first_floor = g.loc[g[\"is_floor\"], \"date\"].min() if g.get(\"is_floor\", pd.Series()).any() else pd.NaT\n",
        "\n",
        "    second_committee = pd.NaT\n",
        "    if pd.notna(first_floor):\n",
        "        after_floor = g[(g[\"date\"] > first_floor) & g[\"is_committee\"]]\n",
        "        if not after_floor.empty:\n",
        "            second_committee = after_floor[\"date\"].min()\n",
        "\n",
        "    second_floor = pd.NaT\n",
        "    if pd.notna(second_committee):\n",
        "        after_second = g[(g[\"date\"] > second_committee) & g[\"is_floor\"]]\n",
        "        if not after_second.empty:\n",
        "            second_floor = after_second[\"date\"].min()\n",
        "\n",
        "    asm_pass = pd.NaT\n",
        "    sen_pass = pd.NaT\n",
        "    if \"location_code\" in g.columns:\n",
        "        asm_mask = (g[\"location_code\"] == \"AFLOOR\") & g[\"pass\"]\n",
        "        sen_mask = (g[\"location_code\"] == \"SFLOOR\") & g[\"pass\"]\n",
        "        if asm_mask.any():\n",
        "            asm_pass = g.loc[asm_mask, \"date\"].min()\n",
        "        if sen_mask.any():\n",
        "            sen_pass = g.loc[sen_mask, \"date\"].min()\n",
        "\n",
        "    return pd.Series({\n",
        "        \"intro\": intro,\n",
        "        \"first_committee\": first_committee,\n",
        "        \"first_floor\": first_floor,\n",
        "        \"second_committee\": second_committee,\n",
        "        \"second_floor\": second_floor,\n",
        "        \"asm_floor_pass\": asm_pass,\n",
        "        \"sen_floor_pass\": sen_pass,\n",
        "    })\n",
        "\n",
        "stages_df = roll.groupby(\"bill_id\").apply(_stage_dates).reset_index() if not roll.empty else pd.DataFrame(columns=[\"bill_id\", \"intro\"])\n",
        "stages_df[\"topic\"] = stages_df[\"bill_id\"].map(canonical_topic)\n",
        "stages_df[\"origin_chamber\"] = stages_df[\"bill_id\"].map(infer_origin_chamber)\n",
        "stages_df = stages_df.dropna(subset=[\"topic\"]) if not stages_df.empty else stages_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Outcomes -----------------------------------------------------------------------------------\n",
        "\n",
        "OUTCOME_TERMS = {\n",
        "    \"CHAPTERED\": 1,\n",
        "    \"ENROLLED\": 1,\n",
        "    \"APPROVED\": 1,\n",
        "    \"SIGNED\": 1,\n",
        "    \"VETOED\": -1,\n",
        "    \"FAILED\": -1,\n",
        "}\n",
        "\n",
        "history_outcomes = history.copy()\n",
        "if not history_outcomes.empty and \"action\" in history_outcomes.columns:\n",
        "    history_outcomes[\"action\"] = history_outcomes[\"action\"].astype(str).str.upper()\n",
        "else:\n",
        "    history_outcomes = pd.DataFrame(columns=[\"bill_id\", \"action\", \"date\"])\n",
        "\n",
        "outcome_lookup = (history_outcomes.sort_values(\"date\", ascending=False)\n",
        "                  .groupby(\"bill_id\")[\"action\"].first()) if not history_outcomes.empty else pd.Series(dtype=str)\n",
        "\n",
        "def classify_outcome(action):\n",
        "    if not isinstance(action, str):\n",
        "        return 0\n",
        "    for key, value in OUTCOME_TERMS.items():\n",
        "        if key in action:\n",
        "            return value\n",
        "    return 0\n",
        "\n",
        "outcome_series = outcome_lookup.map(classify_outcome) if not outcome_lookup.empty else pd.Series(dtype=int)\n",
        "y_df = stages_df[[\"bill_id\", \"topic\"]].copy() if not stages_df.empty else pd.DataFrame(columns=[\"bill_id\", \"topic\"])\n",
        "y_df[\"outcome\"] = y_df[\"bill_id\"].map(outcome_series)\n",
        "y_df[\"last_action\"] = y_df[\"bill_id\"].map(last_action_lookup)\n",
        "y_df[\"first_action\"] = y_df[\"bill_id\"].map(intro_lookup)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Pipeline metrics ---------------------------------------------------------------------------\n",
        "\n",
        "stage_order = [\"intro\", \"first_committee\", \"first_floor\", \"second_committee\", \"second_floor\", \"asm_floor_pass\", \"sen_floor_pass\"]\n",
        "stage_order = [s for s in stage_order if s in stages_df.columns]\n",
        "\n",
        "pipe_records = []\n",
        "for _, row in stages_df.iterrows():\n",
        "    for idx in range(len(stage_order) - 1):\n",
        "        current_stage = stage_order[idx]\n",
        "        next_stage = stage_order[idx + 1]\n",
        "        entered = pd.notna(row[current_stage])\n",
        "        advanced = entered and pd.notna(row[next_stage])\n",
        "        pipe_records.append({\n",
        "            \"bill_id\": row[\"bill_id\"],\n",
        "            \"topic\": row[\"topic\"],\n",
        "            \"from_stage\": current_stage,\n",
        "            \"to_stage\": next_stage,\n",
        "            \"entered\": int(entered),\n",
        "            \"advanced\": int(advanced),\n",
        "            \"days_in_stage\": weeks_between(row[current_stage], row[next_stage]) * 7 if advanced else np.nan,\n",
        "        })\n",
        "\n",
        "pipeline_stage_funnel = (pd.DataFrame(pipe_records)\n",
        "                         .groupby([\"from_stage\", \"to_stage\", \"topic\"])\n",
        "                         .agg(entered=(\"entered\", \"sum\"),\n",
        "                              advanced=(\"advanced\", \"sum\"),\n",
        "                              median_days=(\"days_in_stage\", \"median\"))\n",
        "                         .reset_index()) if pipe_records else pd.DataFrame(columns=[\"from_stage\", \"to_stage\", \"topic\", \"entered\", \"advanced\", \"median_days\"])\n",
        "\n",
        "if not pipeline_stage_funnel.empty:\n",
        "    pipeline_stage_funnel[\"pass_rate\"] = np.where(\n",
        "        pipeline_stage_funnel[\"entered\"] > 0,\n",
        "        pipeline_stage_funnel[\"advanced\"] / pipeline_stage_funnel[\"entered\"],\n",
        "        np.nan\n",
        "    )\n",
        "    pipeline_stage_funnel = pipeline_stage_funnel.rename(columns={\"from_stage\": \"from\", \"to_stage\": \"to\"})\n",
        "\n",
        "pipeline_stage_durations = (pd.DataFrame(pipe_records)\n",
        "                            .dropna(subset=[\"days_in_stage\"])\n",
        "                            .groupby([\"from_stage\", \"topic\"])\n",
        "                            .agg(median_days=(\"days_in_stage\", \"median\"),\n",
        "                                 p90_days=(\"days_in_stage\", lambda x: float(np.nanpercentile(x, 90))))\n",
        "                            .reset_index().rename(columns={\"from_stage\": \"stage\"})) if pipe_records else pd.DataFrame(columns=[\"stage\", \"topic\", \"median_days\", \"p90_days\"])\n",
        "\n",
        "stage_events = []\n",
        "for stage in stage_order:\n",
        "    valid = stages_df[[\"bill_id\", \"topic\", stage]].dropna()\n",
        "    if valid.empty:\n",
        "        continue\n",
        "    tmp = valid.rename(columns={stage: \"date\"})\n",
        "    tmp[\"stage\"] = stage\n",
        "    stage_events.append(tmp)\n",
        "\n",
        "stage_calendar = (pd.concat(stage_events)\n",
        "                  .assign(week=lambda d: pd.to_datetime(d[\"date\"]).dt.to_period(\"W\").dt.start_time)\n",
        "                  .groupby([\"stage\", \"week\"]).agg(bills=(\"bill_id\", \"nunique\")).reset_index()) if stage_events else pd.DataFrame(columns=[\"stage\", \"week\", \"bills\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Route archetypes ---------------------------------------------------------------------------\n",
        "\n",
        "hearings_clean = (committee_hearings\n",
        "                  .merge(committee_codes[[\"committee_code\", \"committee_clean\"]],\n",
        "                         left_on=\"location_code\", right_on=\"committee_code\", how=\"left\")) if not committee_hearings.empty else pd.DataFrame(columns=[\"bill_id\", \"committee_clean\", \"hearing_date\"])\n",
        "\n",
        "hearings_clean = hearings_clean.dropna(subset=[\"bill_id\"]) if not hearings_clean.empty else hearings_clean\n",
        "if not hearings_clean.empty and \"hearing_date\" in hearings_clean.columns:\n",
        "    hearings_clean[\"hearing_date\"] = pd.to_datetime(hearings_clean[\"hearing_date\"], errors=\"coerce\")\n",
        "\n",
        "route_sequences = (hearings_clean.sort_values([\"bill_id\", \"hearing_date\"])\n",
        "                   .groupby(\"bill_id\")[\"committee_clean\"]\n",
        "                   .apply(lambda seq: tuple(dict.fromkeys([c for c in seq if isinstance(c, str)])))\n",
        "                   .reset_index(name=\"route\")) if not hearings_clean.empty else pd.DataFrame(columns=[\"bill_id\", \"route\"])\n",
        "\n",
        "route_sequences[\"route_key\"] = route_sequences[\"route\"].apply(lambda r: \" > \".join(list(r)[:5]) if isinstance(r, tuple) else None)\n",
        "route_sequences[\"topic\"] = route_sequences[\"bill_id\"].map(canonical_topic)\n",
        "route_sequences = route_sequences.dropna(subset=[\"topic\", \"route_key\"]) if not route_sequences.empty else route_sequences\n",
        "\n",
        "route_archetypes = (route_sequences\n",
        "                    .merge(y_df[[\"bill_id\", \"outcome\"]], on=\"bill_id\", how=\"left\")\n",
        "                    .groupby([\"topic\", \"route_key\"], as_index=False)\n",
        "                    .agg(n=(\"bill_id\", \"nunique\"),\n",
        "                         pass_rate=(\"outcome\", lambda x: float((np.array(x) == 1).mean()) if len(x) else np.nan))\n",
        "                    .sort_values([\"topic\", \"n\"], ascending=[True, False])) if not route_sequences.empty else pd.DataFrame(columns=[\"topic\", \"route_key\", \"n\", \"pass_rate\"])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Amendment churn ---------------------------------------------------------------------------\n",
        "\n",
        "import re\n",
        "\n",
        "def tokenise(text: str) -> set[str]:\n",
        "    tokens = re.sub(r\"[^a-z0-9\\s]\", \" \", str(text).lower())\n",
        "    return set(t for t in tokens.split() if t)\n",
        "\n",
        "bill_version_tokens = (bill_versions[[\"bill_id\", \"versionnum\"]]\n",
        "                       .merge(digests[[\"bill_id\", \"digesttext\"]], on=\"bill_id\", how=\"left\")\n",
        "                       .dropna(subset=[\"digesttext\"])) if not bill_versions.empty else pd.DataFrame(columns=[\"bill_id\", \"versionnum\", \"digesttext\"])\n",
        "\n",
        "amendment_rows = []\n",
        "for bill_id, group in bill_version_tokens.groupby(\"bill_id\"):\n",
        "    ordered = group.sort_values(\"versionnum\")\n",
        "    toks = [tokenise(text) for text in ordered[\"digesttext\"]]\n",
        "    if not toks:\n",
        "        continue\n",
        "    sims = [1.0]\n",
        "    for prev, curr in zip(toks, toks[1:]):\n",
        "        sims.append(len(prev & curr) / len(prev | curr) if prev | curr else 1.0)\n",
        "    amendment_rows.append({\n",
        "        \"bill_id\": bill_id,\n",
        "        \"n_versions\": len(toks),\n",
        "        \"median_similarity\": float(np.median(sims)),\n",
        "        \"final_similarity\": sims[-1],\n",
        "    })\n",
        "\n",
        "amendment_churn = pd.DataFrame(amendment_rows)\n",
        "amendment_churn[\"topic\"] = amendment_churn[\"bill_id\"].map(canonical_topic)\n",
        "amendment_churn = amendment_churn.dropna(subset=[\"topic\"]) if not amendment_churn.empty else amendment_churn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Procedural risk heuristics -----------------------------------------------------------------\n",
        "\n",
        "stage_percentiles = {}\n",
        "for stage in stage_order:\n",
        "    durations = []\n",
        "    for _, row in stages_df.iterrows():\n",
        "        idx = stage_order.index(stage)\n",
        "        if idx + 1 >= len(stage_order):\n",
        "            continue\n",
        "        start = row.get(stage)\n",
        "        end = row.get(stage_order[idx + 1])\n",
        "        if pd.notna(start) and pd.notna(end):\n",
        "            durations.append((pd.to_datetime(end) - pd.to_datetime(start)).days)\n",
        "    if durations:\n",
        "        stage_percentiles[stage] = np.nanpercentile(durations, 80)\n",
        "\n",
        "route_pass_lookup = (route_archetypes\n",
        "                     .set_index([\"topic\", \"route_key\"])['pass_rate']\n",
        "                     .to_dict()) if not route_archetypes.empty else {}\n",
        "\n",
        "sponsor_outcomes = (authors.dropna(subset=[\"bill_id\", \"name\"])\n",
        "                    .assign(topic=lambda d: d[\"bill_id\"].map(canonical_topic))\n",
        "                    .dropna(subset=[\"topic\"])\n",
        "                    .merge(y_df[[\"bill_id\", \"outcome\"]], on=\"bill_id\", how=\"left\")) if not authors.empty else pd.DataFrame(columns=[\"bill_id\", \"name\", \"topic\", \"outcome\"])\n",
        "\n",
        "sponsor_success = (sponsor_outcomes.groupby([\"name\", \"topic\"])['outcome']\n",
        "                   .apply(lambda s: float((np.array(s) == 1).mean()) if len(s) else np.nan)\n",
        "                   .reset_index(name=\"success_rate\")) if not sponsor_outcomes.empty else pd.DataFrame(columns=[\"name\", \"topic\", \"success_rate\"])\n",
        "\n",
        "risk_rows = []\n",
        "now = pd.Timestamp.today().normalize()\n",
        "for _, row in stages_df.iterrows():\n",
        "    last_dates = row.dropna()\n",
        "    last_date = pd.to_datetime(last_dates.iloc[-1]) if not last_dates.empty else pd.NaT\n",
        "    days_since_last = (now - last_date).days if pd.notna(last_date) else np.nan\n",
        "\n",
        "    route_key = None\n",
        "    if not route_sequences.empty:\n",
        "        rk = route_sequences.loc[route_sequences[\"bill_id\"] == row[\"bill_id\"], \"route_key\"].head(1)\n",
        "        route_key = rk.iloc[0] if not rk.empty else None\n",
        "    route_pass = route_pass_lookup.get((row[\"topic\"], route_key), np.nan)\n",
        "\n",
        "    churn = amendment_churn.loc[amendment_churn[\"bill_id\"] == row[\"bill_id\"], \"n_versions\"].max()\n",
        "    churn_flag = bool(churn and churn >= 5)\n",
        "    route_flag = bool(route_pass and route_pass < 0.3)\n",
        "\n",
        "    stage_flag = False\n",
        "    for stg, pctl in stage_percentiles.items():\n",
        "        date_val = row.get(stg)\n",
        "        if pd.notna(date_val):\n",
        "            delta = (now - pd.to_datetime(date_val)).days\n",
        "            if delta > pctl:\n",
        "                stage_flag = True\n",
        "                break\n",
        "\n",
        "    sponsor = sponsor_outcomes.loc[sponsor_outcomes[\"bill_id\"] == row[\"bill_id\"], \"name\"].head(1)\n",
        "    sponsor = sponsor.iloc[0] if not sponsor.empty else None\n",
        "    sponsor_flag = False\n",
        "    if sponsor is not None:\n",
        "        ss = sponsor_success.loc[(sponsor_success[\"name\"] == sponsor) & (sponsor_success[\"topic\"] == row[\"topic\"]), \"success_rate\"]\n",
        "        sponsor_flag = bool((not ss.empty) and ss.iloc[0] < 0.4)\n",
        "\n",
        "    risk_score = int(stage_flag) + int(churn_flag) + int(route_flag) + int(sponsor_flag)\n",
        "    reasons = []\n",
        "    if stage_flag:\n",
        "        reasons.append(\"behind schedule\")\n",
        "    if churn_flag:\n",
        "        reasons.append(\"high churn\")\n",
        "    if route_flag:\n",
        "        reasons.append(\"weak route history\")\n",
        "    if sponsor_flag:\n",
        "        reasons.append(\"sponsor below norm\")\n",
        "\n",
        "    risk_rows.append({\n",
        "        \"bill_id\": row[\"bill_id\"],\n",
        "        \"topic\": row[\"topic\"],\n",
        "        \"route_key\": route_key,\n",
        "        \"risk_score\": risk_score,\n",
        "        \"days_since_last\": days_since_last,\n",
        "        \"reasons\": \", \".join(reasons)\n",
        "    })\n",
        "\n",
        "risk_register = pd.DataFrame(risk_rows)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Committee metrics -------------------------------------------------------------------------\n",
        "\n",
        "committee_votes = roll.merge(committee_codes[[\"committee_code\", \"committee_clean\"]],\n",
        "                             on=\"location_code\", how=\"left\") if not roll.empty else pd.DataFrame(columns=[\"committee\", \"bill_id\"])\n",
        "if not committee_votes.empty:\n",
        "    committee_votes[\"committee\"] = committee_votes[\"committee_clean\"].fillna(committee_votes[\"location_code\"])\n",
        "\n",
        "committee_gatekeeping = (committee_votes\n",
        "                          .loc[committee_votes.get(\"is_committee\", False)]\n",
        "                          .groupby(\"committee\", as_index=False)\n",
        "                          .agg(bills_heard=(\"bill_id\", \"nunique\"),\n",
        "                               pass_through=(\"pass\", \"sum\"))) if not committee_votes.empty else pd.DataFrame(columns=[\"committee\", \"bills_heard\", \"pass_through\"])\n",
        "if not committee_gatekeeping.empty:\n",
        "    committee_gatekeeping[\"gatekeeping\"] = 1 - (committee_gatekeeping[\"pass_through\"] /\n",
        "                                                 committee_gatekeeping[\"bills_heard\"].replace(0, np.nan))\n",
        "\n",
        "committee_workload = (committee_gatekeeping.merge(\n",
        "    committee_votes.groupby(\"committee\")[\"bill_id\"].nunique().reset_index(name=\"unique_bills\"),\n",
        "    on=\"committee\", how=\"left\") if not committee_gatekeeping.empty else committee_gatekeeping)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Cross-chamber friction --------------------------------------------------------------------\n",
        "\n",
        "cross_chamber = stages_df[[\"bill_id\", \"topic\", \"asm_floor_pass\", \"sen_floor_pass\"]].copy() if not stages_df.empty else pd.DataFrame(columns=[\"bill_id\", \"topic\"])\n",
        "if not cross_chamber.empty:\n",
        "    cross_chamber[\"asm_to_sen\"] = cross_chamber[\"asm_floor_pass\"].notna() & cross_chamber[\"sen_floor_pass\"].notna()\n",
        "    cross_chamber[\"sen_to_asm\"] = cross_chamber[\"sen_floor_pass\"].notna() & cross_chamber[\"asm_floor_pass\"].notna()\n",
        "\n",
        "cross_chamber_friction = (cross_chamber.groupby(\"topic\", as_index=False)\n",
        "                          .agg(pass_asm_to_sen=(\"asm_to_sen\", \"sum\"),\n",
        "                               pass_sen_to_asm=(\"sen_to_asm\", \"sum\"))) if not cross_chamber.empty else pd.DataFrame(columns=[\"topic\", \"pass_asm_to_sen\", \"pass_sen_to_asm\"])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Survival curves ----------------------------------------------------------------------------\n",
        "\n",
        "survival_records = []\n",
        "for topic, group in y_df.groupby(\"topic\"):\n",
        "    starts = pd.to_datetime(group[\"first_action\"])\n",
        "    ends = pd.to_datetime(group[\"last_action\"])\n",
        "    if starts.isna().all():\n",
        "        continue\n",
        "    timeline = pd.date_range(starts.min(), (ends.dropna().max() if ends.notna().any() else pd.Timestamp.today()), freq=\"14D\")\n",
        "    total = len(group)\n",
        "    for dt in timeline:\n",
        "        alive = ((ends.isna()) | (ends > dt)).sum()\n",
        "        survival_records.append({\"topic\": topic, \"date\": dt, \"survival\": alive / total if total else np.nan})\n",
        "\n",
        "survival_curves = pd.DataFrame(survival_records)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Voting blocs & controversy ----------------------------------------------------------------\n",
        "\n",
        "votes_long = votes.copy()\n",
        "if not votes_long.empty:\n",
        "    votes_long[\"topic\"] = votes_long[\"bill_id\"].map(canonical_topic)\n",
        "    votes_long = votes_long.dropna(subset=[\"topic\"])\n",
        "    votes_long[\"chamber\"] = votes_long[\"location_code\"].apply(lambda code: \n",
        "        'Assembly' if isinstance(code, str) and code.startswith('A') else \n",
        "        ('Senate' if isinstance(code, str) and code.startswith('S') else 'Both')\n",
        "    )\n",
        "else:\n",
        "    votes_long = pd.DataFrame(columns=[\"bill_id\", \"topic\", \"vote_value\", \"chamber\"])\n",
        "\n",
        "vote_matrix = (votes_long\n",
        "               .pivot_table(index=\"legislator_name\", columns=\"bill_id\", values=\"vote_value\", fill_value=0)) if not votes_long.empty else pd.DataFrame()\n",
        "\n",
        "similarity_rows = []\n",
        "legislators = vote_matrix.index.tolist()\n",
        "for i, a in enumerate(legislators):\n",
        "    for b in legislators[i + 1:]:\n",
        "        vec_a = vote_matrix.loc[a].values\n",
        "        vec_b = vote_matrix.loc[b].values\n",
        "        if not np.any(vec_a) or not np.any(vec_b):\n",
        "            continue\n",
        "        sim = float(np.corrcoef(vec_a, vec_b)[0, 1])\n",
        "        if np.isnan(sim):\n",
        "            continue\n",
        "        if sim >= 0.6:\n",
        "            similarity_rows.append({\"source\": a, \"target\": b, \"weight\": sim})\n",
        "\n",
        "vote_similarity_edges = pd.DataFrame(similarity_rows)\n",
        "if not vote_similarity_edges.empty:\n",
        "    vote_similarity_edges = vote_similarity_edges.rename(columns={\"weight\": \"sim\", \"source\": \"u\", \"target\": \"v\"})\n",
        "\n",
        "party_votes = votes_long.merge(politicians[[\"full_name\", \"party\", \"term\"]],\n",
        "                               left_on=[\"legislator_name\", \"term\"], right_on=[\"full_name\", \"term\"], how=\"left\") if not votes_long.empty else pd.DataFrame(columns=[\"bill_id\", \"topic\", \"party\", \"vote_value\"])\n",
        "party_votes = party_votes.dropna(subset=[\"party\"]) if not party_votes.empty else party_votes\n",
        "\n",
        "roll_party = (party_votes.groupby([\"bill_id\", \"topic\", \"party\"], as_index=False)\n",
        "              .agg(yes_rate=(\"vote_value\", lambda x: float((np.array(x) > 0).mean()) if len(x) else np.nan))) if not party_votes.empty else pd.DataFrame(columns=[\"bill_id\", \"topic\", \"party\", \"yes_rate\"])\n",
        "\n",
        "party_pivot = roll_party.pivot_table(index=[\"bill_id\", \"topic\"], columns=\"party\", values=\"yes_rate\") if not roll_party.empty else pd.DataFrame()\n",
        "if not party_pivot.empty:\n",
        "    party_pivot = party_pivot.reset_index().rename(columns={\"D\": \"dem_yes\", \"R\": \"rep_yes\"})\n",
        "    party_pivot[\"polarization\"] = (party_pivot[\"dem_yes\"] - party_pivot[\"rep_yes\"]).abs()\n",
        "else:\n",
        "    party_pivot = pd.DataFrame(columns=[\"bill_id\", \"topic\", \"dem_yes\", \"rep_yes\", \"polarization\"])\n",
        "\n",
        "topic_controversy = (party_pivot.groupby(\"topic\", as_index=False)\n",
        "                     .agg(mean_polarization=(\"polarization\", \"mean\"),\n",
        "                          party_split_rate=(\"polarization\", lambda x: float((np.array(x) > 0.5).mean())))) if not party_pivot.empty else pd.DataFrame(columns=[\"topic\", \"mean_polarization\", \"party_split_rate\"])\n",
        "\n",
        "rollcall_party_splits = party_pivot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Committee vs floor drift ------------------------------------------------------------------\n",
        "\n",
        "committee_votes_long = votes_long.loc[votes_long.get(\"is_committee\", False)] if not votes_long.empty else pd.DataFrame(columns=[\"legislator_name\", \"bill_id\"])\n",
        "floor_votes_long = votes_long.loc[votes_long.get(\"is_floor\", False)] if not votes_long.empty else pd.DataFrame(columns=[\"legislator_name\", \"bill_id\"])\n",
        "\n",
        "committee_summary = (committee_votes_long\n",
        "                     .groupby([\"legislator_name\", \"bill_id\"], as_index=False)['vote_value']\n",
        "                     .mean().rename(columns={\"vote_value\": \"committee_score\"})) if not committee_votes_long.empty else pd.DataFrame(columns=[\"legislator_name\", \"bill_id\", \"committee_score\"])\n",
        "\n",
        "floor_summary = (floor_votes_long\n",
        "                 .groupby([\"legislator_name\", \"bill_id\"], as_index=False)['vote_value']\n",
        "                 .mean().rename(columns={\"vote_value\": \"floor_score\"})) if not floor_votes_long.empty else pd.DataFrame(columns=[\"legislator_name\", \"bill_id\", \"floor_score\"])\n",
        "\n",
        "committee_floor_drift = (committee_summary.merge(floor_summary, on=[\"legislator_name\", \"bill_id\"], how=\"inner\")\n",
        "                          .assign(drift=lambda d: d[\"committee_score\"] - d[\"floor_score\"])) if not committee_summary.empty else pd.DataFrame(columns=[\"legislator_name\", \"bill_id\", \"committee_score\", \"floor_score\", \"drift\"])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Text lift (log odds) ----------------------------------------------------------------------\n",
        "\n",
        "text_rows = []\n",
        "for _, row in digests.iterrows():\n",
        "    bill_id = row.get(\"bill_id\")\n",
        "    topic = canonical_topic(bill_id)\n",
        "    if not topic:\n",
        "        continue\n",
        "    outcome = y_df.loc[y_df[\"bill_id\"] == bill_id, \"outcome\"].head(1)\n",
        "    if outcome.empty:\n",
        "        continue\n",
        "    tokens = tokenise(row.get(\"digesttext\", \"\"))\n",
        "    for token in tokens:\n",
        "        text_rows.append({\"topic\": topic, \"token\": token, \"outcome\": int(outcome.iloc[0])})\n",
        "\n",
        "text_df = pd.DataFrame(text_rows)\n",
        "\n",
        "def log_odds(good, bad, alpha=0.01):\n",
        "    return math.log((good + alpha) / (bad + alpha))\n",
        "\n",
        "text_stats = []\n",
        "for (topic, token), group in text_df.groupby([\"topic\", \"token\"]):\n",
        "    passed = (group[\"outcome\"] == 1).sum()\n",
        "    failed = (group[\"outcome\"] != 1).sum()\n",
        "    lift = log_odds(passed, failed)\n",
        "    text_stats.append({\"topic\": topic, \"token\": token, \"log_lift_pass_vs_other\": lift, \"pos\": passed, \"neg\": failed})\n",
        "\n",
        "text_lift_top_tokens = pd.DataFrame(text_stats) if text_stats else pd.DataFrame(columns=[\"topic\", \"token\", \"log_lift_pass_vs_other\", \"pos\", \"neg\"])\n",
        "if not text_lift_top_tokens.empty:\n",
        "    text_lift_top_tokens[\"count\"] = text_lift_top_tokens[\"pos\"] + text_lift_top_tokens[\"neg\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Funding allocation ------------------------------------------------------------------------\n",
        "\n",
        "if not lobbying.empty:\n",
        "    lobbying[\"expn_date\"] = pd.to_datetime(lobbying.get(\"EXPN_DATE\", lobbying.get(\"expn_date\")), errors=\"coerce\")\n",
        "    lobbying[\"term\"] = lobbying[\"expn_date\"].apply(lambda x: np.nan if pd.isna(x) else (\n",
        "        f\"{x.year-1}-{x.year}\" if (x.year % 2 == 0 and x.month < 11) else\n",
        "        f\"{x.year+1}-{x.year+2}\" if (x.year % 2 == 0) else\n",
        "        f\"{x.year}-{x.year+1}\"\n",
        "    ))\n",
        "    lobbying[\"beneficiary_clean\"] = lobbying.get(\"clean_beneficiary\", lobbying.get(\"BENEFICIARY\"))\n",
        "    lobby_by_leg = (lobbying.dropna(subset=[\"beneficiary_clean\", \"term\"])\n",
        "                    .groupby([\"beneficiary_clean\", \"term\"], as_index=False)[\"BENE_AMT\"].sum()\n",
        "                    .rename(columns={\"BENE_AMT\": \"lobbying\"}))\n",
        "else:\n",
        "    lobby_by_leg = pd.DataFrame(columns=[\"beneficiary_clean\", \"term\", \"lobbying\"])\n",
        "\n",
        "for df in (expend_assembly, expend_senate):\n",
        "    if not df.empty and \"matched_target_name\" in df.columns:\n",
        "        df[\"target_clean\"] = df[\"matched_target_name\"].str.lower().str.replace(\",\", \"\", regex=False)\n",
        "        df[\"term\"] = df[\"year\"]\n",
        "\n",
        "don_as = (expend_assembly.groupby([\"target_clean\", \"term\"], as_index=False)[\"Amount\"].sum()\n",
        "          if not expend_assembly.empty else pd.DataFrame(columns=[\"target_clean\", \"term\", \"Amount\"]))\n",
        "\n",
        "don_sen = (expend_senate.groupby([\"target_clean\", \"term\"], as_index=False)[\"Amount\"].sum()\n",
        "           if not expend_senate.empty else pd.DataFrame(columns=[\"target_clean\", \"term\", \"Amount\"]))\n",
        "\n",
        "donations = (pd.concat([don_as, don_sen], ignore_index=True)\n",
        "             .rename(columns={\"target_clean\": \"beneficiary_clean\", \"Amount\": \"donations\"})) if not don_as.empty or not don_sen.empty else pd.DataFrame(columns=[\"beneficiary_clean\", \"term\", \"donations\"])\n",
        "\n",
        "funding = (donations.merge(lobby_by_leg, on=[\"beneficiary_clean\", \"term\"], how=\"outer\")\n",
        "           .fillna({\"donations\": 0.0, \"lobbying\": 0.0})) if not donations.empty or not lobby_by_leg.empty else pd.DataFrame(columns=[\"beneficiary_clean\", \"term\", \"donations\", \"lobbying\"])\n",
        "funding[\"total_received\"] = funding.get(\"donations\", 0) + funding.get(\"lobbying\", 0)\n",
        "\n",
        "votes_topic_weights = (votes_long.groupby([\"legislator_name\", \"term\", \"topic\"])\n",
        "                       [\"vote_value\"].apply(lambda x: float((np.array(x) > 0).sum()) / max(len(x), 1))\n",
        "                       .reset_index(name=\"topic_weight\")) if not votes_long.empty else pd.DataFrame(columns=[\"legislator_name\", \"term\", \"topic\", \"topic_weight\"])\n",
        "\n",
        "if not funding.empty:\n",
        "    funding[\"beneficiary_lower\"] = funding[\"beneficiary_clean\"].astype(str)\n",
        "    ca_legislator_funding = (funding\n",
        "                             .groupby([\"beneficiary_lower\", \"term\"], as_index=False)\n",
        "                             .agg(total_received=(\"total_received\", \"sum\"),\n",
        "                                  donations=(\"donations\", \"sum\"),\n",
        "                                  lobbying=(\"lobbying\", \"sum\")))\n",
        "    funding_alloc = (funding\n",
        "                     .merge(votes_topic_weights, left_on=[\"beneficiary_lower\", \"term\"],\n",
        "                            right_on=[\"legislator_name\", \"term\"], how=\"left\")\n",
        "                     .fillna({\"topic_weight\": 0.0}))\n",
        "    funding_alloc[\"donations_topic\"] = funding_alloc[\"donations\"] * funding_alloc[\"topic_weight\"]\n",
        "    funding_alloc[\"lobbying_topic\"] = funding_alloc[\"lobbying\"] * funding_alloc[\"topic_weight\"]\n",
        "    funding_alloc[\"total_topic\"] = funding_alloc[\"total_received\"] * funding_alloc[\"topic_weight\"]\n",
        "else:\n",
        "    ca_legislator_funding = pd.DataFrame(columns=[\"beneficiary_lower\", \"term\", \"total_received\", \"donations\", \"lobbying\"])\n",
        "    funding_alloc = pd.DataFrame(columns=[\"beneficiary_lower\", \"term\", \"topic_weight\", \"donations\", \"lobbying\", \"total_received\"])\n",
        "\n",
        "topic_funding_by_term = (funding_alloc.groupby([\"topic\", \"term\"], as_index=False)\n",
        "                         .agg(total_donations=(\"donations_topic\", \"sum\"),\n",
        "                              total_lobbying=(\"lobbying_topic\", \"sum\"),\n",
        "                              total_received=(\"total_topic\", \"sum\"))) if not funding_alloc.empty else pd.DataFrame(columns=[\"topic\", \"term\", \"total_donations\", \"total_lobbying\", \"total_received\"])\n",
        "\n",
        "legislator_topic_funding = (funding_alloc.groupby([\"beneficiary_lower\", \"term\", \"topic\"], as_index=False)\n",
        "                            .agg(donations=(\"donations_topic\", \"sum\"),\n",
        "                                 lobbying=(\"lobbying_topic\", \"sum\"),\n",
        "                                 total=(\"total_topic\", \"sum\"))) if not funding_alloc.empty else pd.DataFrame(columns=[\"beneficiary_lower\", \"term\", \"topic\", \"donations\", \"lobbying\", \"total\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Funding geography -------------------------------------------------------------------------\n",
        "\n",
        "geo_records = []\n",
        "if gpd is not None and MAP_DIR.exists():\n",
        "    geo_file = next(MAP_DIR.glob(\"ca_legislator_funding_geo.*\"), None)\n",
        "    if geo_file is not None:\n",
        "        try:\n",
        "            geo_df = gpd.read_file(geo_file)\n",
        "            keep_cols = [c for c in [\"district\", \"chamber\", \"geometry\"] if c in geo_df.columns]\n",
        "            geo_df = geo_df[keep_cols]\n",
        "            geo_records = json.loads(geo_df.to_crs(epsg=4326).to_json())\n",
        "        except Exception as exc:\n",
        "            warnings.warn(f\"Unable to read legislator geography: {exc}\")\n",
        "else:\n",
        "    warnings.warn(\"Geopandas not available or map directory missing; skipping geography export.\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Bill browser table ------------------------------------------------------------------------\n",
        "\n",
        "bill_longevity = (y_df\n",
        "                  .assign(longevity_days=lambda d: (pd.to_datetime(d[\"last_action\"]) -\n",
        "                                                    pd.to_datetime(d[\"first_action\"]))\n",
        "                          .dt.days)) if not y_df.empty else pd.DataFrame(columns=[\"bill_id\", \"topic\", \"longevity_days\"])\n",
        "\n",
        "bills_table = (bill_longevity\n",
        "               .merge(amendment_churn[[\"bill_id\", \"n_versions\", \"median_similarity\"]], on=\"bill_id\", how=\"left\")\n",
        "               .merge(route_sequences[[\"bill_id\", \"route_key\"]], on=\"bill_id\", how=\"left\")\n",
        "               .merge(risk_register[[\"bill_id\", \"risk_score\"]], on=\"bill_id\", how=\"left\")) if not bill_longevity.empty else pd.DataFrame(columns=[\"bill_id\", \"topic\"])\n",
        "\n",
        "bills_table.rename(columns={\"first_action\": \"first_action_date\", \"last_action\": \"last_action_date\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Precomputed payload -----------------------------------------------------------------------\n",
        "\n",
        "precomp_outputs = {\n",
        "    \"pipeline_stage_funnel\": pipeline_stage_funnel,\n",
        "    \"pipeline_stage_durations\": pipeline_stage_durations,\n",
        "    \"pipeline_stage_calendar\": stage_calendar,\n",
        "    \"route_archetypes\": route_archetypes,\n",
        "    \"amendment_churn\": amendment_churn,\n",
        "    \"risk_register\": risk_register,\n",
        "    \"committee_gatekeeping\": committee_gatekeeping,\n",
        "    \"committee_workload\": committee_workload,\n",
        "    \"cross_chamber_friction\": cross_chamber_friction,\n",
        "    \"survival_curves\": survival_curves,\n",
        "    \"topic_controversy\": topic_controversy,\n",
        "    \"rollcall_party_splits\": rollcall_party_splits,\n",
        "    \"vote_similarity_edges\": vote_similarity_edges,\n",
        "    \"committee_floor_drift\": committee_floor_drift,\n",
        "    \"text_lift_top_tokens\": text_lift_top_tokens,\n",
        "    \"topic_funding_by_term\": topic_funding_by_term,\n",
        "    \"topic_funding_by_leg\": legislator_topic_funding,\n",
        "    \"ca_legislator_funding_geo\": geo_records,\n",
        "    \"ca_legislator_funding\": ca_legislator_funding,\n",
        "    \"bills_table\": bills_table,\n",
        "}\n",
        "\n",
        "precomp_outputs\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}