{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e10e4af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, torch, json, pickle, itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from community import community_louvain\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bd3f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bill_subjects.json', 'r') as f:\n",
    "    bill_subjects = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c5afe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_originals = pickle.load(open('subjects_original.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb8f7cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "so = {k: subject_originals[v] for k, v in bill_subjects.items() if v in subject_originals}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684cf49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canonical(sub):\n",
    "    txt = sub.lower()\n",
    "    txt = re.sub(r'[^a-z\\s]', ' ', txt)\n",
    "    txt = re.sub(r'(?:california|state|bill|law|act|amendment|proposition|measure|initiative|program|act|code|section|chapter|month|awareness|prevention)', '', txt)\n",
    "    txt = re.sub(r'\\s+', ' ', txt).strip()\n",
    "    txt = ' '.join([w for w in txt.split() if w not in stopwords])\n",
    "    return txt.strip()\n",
    "\n",
    "canonical_subjects = {k: canonical(v) for k, v in so.items()}\n",
    "canonical_set = set(canonical_subjects.values())\n",
    "\n",
    "model = SentenceTransformer(\"google/embeddinggemma-300m-qat-q4_0-unquantized\")\n",
    "subs = list(canonical_set)\n",
    "embs = model.encode(subs, show_progress_bar=True, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec8b0d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig, leidenalg as la\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "X = normalize(embs.astype(np.float32))\n",
    "nbrs = NearestNeighbors(n_neighbors=min(22, max(10, int(np.sqrt(len(X))))), metric=\"cosine\").fit(X)\n",
    "dist, idx = nbrs.kneighbors(X)\n",
    "sim = 1.0 - dist\n",
    "rows = np.repeat(np.arange(len(X)), idx.shape[1])\n",
    "cols = idx.ravel()\n",
    "weights = sim.ravel()\n",
    "m = np.vstack([rows, cols, weights]).T\n",
    "m = m[rows != cols]\n",
    "G = ig.Graph(n=len(X), edges=list(map(tuple, m[:, :2].astype(int))), directed=False)\n",
    "G.es[\"weight\"] = m[:, 2].astype(float)\n",
    "res_grid = np.linspace(0.2, 6.0, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82c4f69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = []\n",
    "scores = []\n",
    "for r in res_grid:\n",
    "    part = la.find_partition(G, la.RBConfigurationVertexPartition, weights=\"weight\", resolution_parameter=float(r), seed=42)\n",
    "    labels = np.array(part.membership)\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        try:\n",
    "            s = silhouette_score(X, labels, metric=\"cosine\")\n",
    "        except Exception:\n",
    "            s = -1.0\n",
    "    else:\n",
    "        s = -1.0\n",
    "    parts.append(labels)\n",
    "    scores.append(s)\n",
    "best = int(np.argmax(scores))\n",
    "labels = parts[best]\n",
    "k = len(np.unique(labels))\n",
    "centroids = []\n",
    "for c in range(k):\n",
    "    msk = labels==c\n",
    "    v = X[msk].mean(axis=0)\n",
    "    v = v/np.linalg.norm(v) if np.linalg.norm(v)>0 else v\n",
    "    centroids.append(v)\n",
    "centroids = np.stack(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b4db314",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = X @ centroids.T\n",
    "cluster_sim = sims[np.arange(len(X)), labels]\n",
    "thr = np.percentile(cluster_sim, 10)\n",
    "noise = cluster_sim < max(thr, 0.1)\n",
    "labels_noise = labels.copy()\n",
    "labels_noise[noise] = -1\n",
    "clusters = {}\n",
    "for cid in sorted(set(labels_noise) - {-1}):\n",
    "    idx_c = np.where(labels_noise==cid)[0]\n",
    "    cvec = centroids[cid]\n",
    "    ex_i = idx_c[np.argmax(X[idx_c] @ cvec)]\n",
    "    clusters[int(cid)] = {\n",
    "        \"indices\": idx_c.tolist(),\n",
    "        \"subjects\": [subs[i] for i in idx_c],\n",
    "        \"centroid\": cvec.tolist(),\n",
    "        \"exemplar_index\": int(ex_i),\n",
    "        \"exemplar_subject\": subs[ex_i]\n",
    "    }\n",
    "result = {\n",
    "    \"labels\": labels_noise.tolist(),\n",
    "    \"clusters\": clusters,\n",
    "    \"noise_indices\": np.where(labels_noise==-1)[0].tolist(),\n",
    "    \"resolution\": float(res_grid[best]),\n",
    "    \"silhouette\": float(scores[best])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21875ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [(c['exemplar_subject'], c['subjects'], len(c['subjects'])) for c in result['clusters'].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f78a5626",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame({\n",
    "    'bill_id': list(so.keys()),\n",
    "    'subject': list(so.values())\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0540d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_reverse = {sub: cid for cid, c in clusters.items() for sub in c['subjects']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a5bb52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['clean_subject'] = labels['bill_id'].map(canonical_subjects)\n",
    "labels['cluster'] = labels['clean_subject'].map(clust_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1ddba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bill_ids.txt', 'r') as f:\n",
    "    bill_ids = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4b22c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('missed_bills.txt', 'r') as f:\n",
    "    missed_bills = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d073320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_id_mapping = pickle.load(open('bill_id_mapping.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31c351a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_variations = [k for k, v in bill_id_mapping.items() if v in missed_bills]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70e8059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_labels = {}\n",
    "for _, row in labels[['bill_id', 'cluster']].drop_duplicates().iterrows():\n",
    "    bill_labels[row['bill_id']] = row['cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e06a54b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bill_labels.json', 'w') as f:\n",
    "    json.dump(bill_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43e78f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "digests = pd.read_csv('ca_leg/legislation_data/digest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97292f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "digest_embeddings = torch.load('digests.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11a8e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "repairs = digests.loc[digests['bill_id'].isin(missing_variations)]\n",
    "repairs['bill'] = repairs['bill_id'].map(bill_id_mapping)\n",
    "repairs['version'] = repairs['bill_id'].apply(lambda x: x[-5:-3]).astype(int)\n",
    "repairs = repairs.sort_values('version', ascending=False).groupby('bill').head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79035831",
   "metadata": {},
   "outputs": [],
   "source": [
    "de = {k: v.cpu().numpy() for k, v in digest_embeddings.items() if k in repairs['DigestText'].values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10458241",
   "metadata": {},
   "outputs": [],
   "source": [
    "repairs['digest_embedding'] = repairs['DigestText'].map(de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3ed503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = labels['cluster'].value_counts().to_dict()\n",
    "\n",
    "def sample_weighted(labs, sample_weights, n):\n",
    "    lab = labs.copy().sample(frac=1).reset_index(drop=True)\n",
    "    weights = labs['cluster'].map(sample_weights)\n",
    "    return lab.sample(n, weights=weights, replace=True)\n",
    "\n",
    "training_sample = sample_weighted(labels.loc[~labels['bill_id'].isin(missed_bills)], sample_weights, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03223df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vars = [k for k, v in bill_id_mapping.items() if v in training_sample['bill_id'].values]\n",
    "t = digests.loc[digests['bill_id'].isin(t_vars)]\n",
    "t['bill'] = t['bill_id'].map(bill_id_mapping)\n",
    "t['version'] = t['bill_id'].apply(lambda x: re.sub(r'\\D+', '', x)[-2:]).astype(int)\n",
    "t = t.sort_values('version', ascending=False).groupby('bill').head(1)\n",
    "\n",
    "dee = {k: v.cpu().numpy() for k, v in digest_embeddings.items() if k in t['DigestText'].values}\n",
    "t['digest_embedding'] = t['DigestText'].map(dee)\n",
    "t = t.loc[t['digest_embedding'].notna()]\n",
    "t = t.merge(training_sample[['bill_id', 'cluster']], right_on='bill_id', left_on='bill', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f6c14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack(t['digest_embedding'].values)\n",
    "y = t['cluster'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78420205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:47<00:00,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=1)\n",
    "grid = ParameterGrid(param_grid)\n",
    "best_score, best_params = 0, None\n",
    "for params in tqdm(grid):\n",
    "    rf.set_params(**params)\n",
    "    rf.fit(X, y)\n",
    "    score = rf.score(X, y)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "print(f\"Best Score: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73e5e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "repairs['label_pred'] = rf.predict(np.vstack(repairs['digest_embedding']))\n",
    "reps = {k: v for k, v in repairs[['bill', 'label_pred']].values if v is not None}\n",
    "bbb = bill_labels.copy()\n",
    "for k, v in reps.items():\n",
    "    bbb[k] = v\n",
    "\n",
    "with open('bill_labels_updated.json', 'w') as f:\n",
    "    json.dump(bbb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff37214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bill_labels_updated.json', 'r') as f:\n",
    "    updated_labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8831723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('sampled_labels - sampled_labels.csv')\n",
    "so = {row['cluster']: row['Label'] for _, row in labels.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16d2c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = {}\n",
    "\n",
    "for l in labels.groupby('Label')['cluster'].count().sort_values(ascending=False).loc[lambda x: x > 1].index:\n",
    "    correction = [k for k, v in so.items() if v == l]\n",
    "    m = min(correction)\n",
    "    for c in correction:\n",
    "        if c != m:\n",
    "            corrections[c] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "081451fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_labels2 = {}\n",
    "\n",
    "for k, v in updated_labels.items():\n",
    "    if v in corrections:\n",
    "        updated_labels2[k] = corrections[v]\n",
    "    else:\n",
    "        updated_labels2[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09af0bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bill_labels_updated.json', 'w') as f:\n",
    "    json.dump(updated_labels2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41a95f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame.from_dict(updated_labels, orient='index', columns=['cluster']).reset_index(names='bill_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2e72331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "bill_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cluster",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "subject",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "77f0a105-41e9-47b6-8e54-29b72a005d2a",
       "rows": [
        [
         "0",
         "200320040SB73",
         "82",
         "national guard"
        ],
        [
         "1",
         "200520060AB1484",
         "5",
         "sexually violent predators definition"
        ],
        [
         "2",
         "200920100AB2531",
         "32",
         "redevelopment economic development"
        ],
        [
         "3",
         "200520060SB1576",
         "102",
         "foster care transitional housing"
        ],
        [
         "4",
         "200920100AB383",
         "34",
         "criminal procedure dna evidence"
        ],
        [
         "5",
         "201520160SB1090",
         "105",
         "sexually transmitted diseases outreach and screening services"
        ],
        [
         "6",
         "201720180AB1219",
         "90",
         "food donations"
        ],
        [
         "7",
         "202120220AB2593",
         "0",
         "coastal resources coastal development permits blue carbon projects"
        ],
        [
         "8",
         "201320140SB99",
         "22",
         "budget act of 2013"
        ],
        [
         "9",
         "200520060AB1691",
         "34",
         "teachers criminal records checks"
        ],
        [
         "10",
         "202320240SB960",
         "17",
         "transportation planning transit priority projects multimodal"
        ],
        [
         "11",
         "200320040AB1638",
         "68",
         "charter schools nonclassroom based instruction"
        ],
        [
         "12",
         "201720180SB831",
         "79",
         "land use accessory dwelling units"
        ],
        [
         "13",
         "201520160SB1475",
         "78",
         "state warrants records"
        ],
        [
         "14",
         "201920200AB1392",
         "97",
         "state lands commission grant of trust lands city of redwood city"
        ],
        [
         "15",
         "200720080AB1626",
         "50",
         "county employees retirement conformance with federal law"
        ],
        [
         "16",
         "200520060SB74",
         "23",
         "emergency flood protection and levee repair bond act of 2006"
        ],
        [
         "17",
         "200720080AB2575",
         "46",
         "foster care investigations audio recording"
        ],
        [
         "18",
         "201520160ACR64",
         "41",
         "asthma awareness month"
        ],
        [
         "19",
         "200920100AB2361",
         "51",
         "weights and measures inspection fees"
        ],
        [
         "20",
         "202320240SB804",
         "46",
         "criminal procedure hearsay testimony at preliminary hearings"
        ],
        [
         "21",
         "202520260SB786",
         "111",
         "planning and zoning general plan judicial challenges"
        ],
        [
         "22",
         "202320240AB3239",
         "113",
         "state parks and monuments"
        ],
        [
         "23",
         "200120022SB64",
         "97",
         "energy qualified agricultural biomass incentive grants"
        ],
        [
         "24",
         "200320040AB216",
         "45",
         "alcohol fee youth alcohol recovery and prevention"
        ],
        [
         "25",
         "201720180AB563",
         "6",
         "calfresh employment and training program"
        ],
        [
         "26",
         "202120220AB2105",
         "51",
         "contractors initial license fee reduction veterans"
        ],
        [
         "27",
         "200320040SB1285",
         "13",
         "juvenile court criminal history reporting"
        ],
        [
         "28",
         "202320240AB2576",
         "34",
         "diversion attempted murder"
        ],
        [
         "29",
         "202320240SB129",
         "66",
         "housing"
        ],
        [
         "30",
         "200520060SB1185",
         "55",
         "school employees compulsory leave of absence compensation"
        ],
        [
         "31",
         "201920200AB1087",
         "27",
         "pupil instruction requirements for graduation economics"
        ],
        [
         "32",
         "200720080AB256",
         "65",
         "highway users tax account appropriation of funds"
        ],
        [
         "33",
         "200120020ACR142",
         "53",
         "judge harry pregerson interchange"
        ],
        [
         "34",
         "200720080SCR89",
         "39",
         "cancer survivor beauty and support day"
        ],
        [
         "35",
         "202120220AB1611",
         "64",
         "oil spills potential casualties with submerged oil pipelines vessels reporting"
        ],
        [
         "36",
         "202520260AB720",
         "45",
         "winegrowers and brandy manufacturers privileges off premises"
        ],
        [
         "37",
         "200720080SB1467",
         "44",
         "insurance guarantee fund"
        ],
        [
         "38",
         "202120220AB2021",
         "7",
         "property tax sales sale to local agency or qualified nonprofit organizations"
        ],
        [
         "39",
         "200520060ACR125",
         "115",
         "agriculture day"
        ],
        [
         "40",
         "201320140SB397",
         "40",
         "the california community colleges veterans education pilot program"
        ],
        [
         "41",
         "200320040ACR258",
         "89",
         "red ribbon week"
        ],
        [
         "42",
         "202320240SB45",
         "94",
         "california acute care psychiatric hospital loan fund"
        ],
        [
         "43",
         "201920200AB1763",
         "59",
         "public utilities commission membership"
        ],
        [
         "44",
         "200120020SB550",
         "86",
         "endangered species"
        ],
        [
         "45",
         "202320240SCR135",
         "115",
         "california holocaust memorial day"
        ],
        [
         "46",
         "201720180ACR256",
         "115",
         "rosie s day"
        ],
        [
         "47",
         "202120220AB2137",
         "29",
         "family justice centers"
        ],
        [
         "48",
         "200920100AB970",
         "32",
         "local government economic development"
        ],
        [
         "49",
         "200120020SB736",
         "32",
         "local law enforcement funding"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 46100
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_id</th>\n",
       "      <th>cluster</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200320040SB73</td>\n",
       "      <td>82</td>\n",
       "      <td>national guard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200520060AB1484</td>\n",
       "      <td>5</td>\n",
       "      <td>sexually violent predators definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200920100AB2531</td>\n",
       "      <td>32</td>\n",
       "      <td>redevelopment economic development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200520060SB1576</td>\n",
       "      <td>102</td>\n",
       "      <td>foster care transitional housing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200920100AB383</td>\n",
       "      <td>34</td>\n",
       "      <td>criminal procedure dna evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46095</th>\n",
       "      <td>201720180ACR25</td>\n",
       "      <td>115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46096</th>\n",
       "      <td>200920100SJR35</td>\n",
       "      <td>115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46097</th>\n",
       "      <td>201720180AB291</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46098</th>\n",
       "      <td>201720180ACR6</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46099</th>\n",
       "      <td>201720180ACR1</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               bill_id  cluster                                subject\n",
       "0        200320040SB73       82                         national guard\n",
       "1      200520060AB1484        5  sexually violent predators definition\n",
       "2      200920100AB2531       32     redevelopment economic development\n",
       "3      200520060SB1576      102       foster care transitional housing\n",
       "4       200920100AB383       34        criminal procedure dna evidence\n",
       "...                ...      ...                                    ...\n",
       "46095   201720180ACR25      115                                    NaN\n",
       "46096   200920100SJR35      115                                    NaN\n",
       "46097   201720180AB291       34                                    NaN\n",
       "46098    201720180ACR6       56                                    NaN\n",
       "46099    201720180ACR1       70                                    NaN\n",
       "\n",
       "[46100 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = labels['bill_id'].map(bill_subjects)\n",
    "labels['subject'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4af88a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = labels.groupby('cluster').sample(50).reset_index()\n",
    "sample['count'] = sample.groupby('cluster').cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7aee460",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.pivot(index='cluster', columns='count', values='subject').to_csv('sampled_labels.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef85488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40969fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.groupby('cluster').sample(50, replace=True).sort_values('cluster').to_csv('sampled_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "64d23161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r\"\\b(state|bill|act|law|code|section|chapter|california|month)\\b\", \" \", text, flags=re.I)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).lower()\n",
    "    return text\n",
    "\n",
    "def text_cluster(label, ngram_range=(2, 3), max_features=125):\n",
    "    section = labels.loc[labels['cluster'] == label, 'subject'].values\n",
    "    cleaned_texts = [_clean(text) for text in section if text and isinstance(text, str)]\n",
    "\n",
    "    if not cleaned_texts:\n",
    "        return []\n",
    "\n",
    "    vectorizer = CountVectorizer(\n",
    "        ngram_range=ngram_range,\n",
    "        max_features=max_features,\n",
    "        stop_words='english',\n",
    "        min_df=5,\n",
    "        lowercase=True\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        count_matrix = vectorizer.fit_transform(cleaned_texts)\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "        phrase_counts = count_matrix.sum(axis=0).A1\n",
    "\n",
    "        phrase_count_pairs = list(zip(feature_names, phrase_counts))\n",
    "        phrase_count_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        return phrase_count_pairs[:3]\n",
    "\n",
    "    except ValueError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e4f4a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_phrases = {}\n",
    "for label in labels['cluster'].unique():\n",
    "    cluster_phrases[label] = text_cluster(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "087801b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = pd.DataFrame.from_dict(cluster_phrases, orient='index', columns=['phrase1', 'phrase2', 'phrase3']).reset_index(names='cluster').sort_values('cluster')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
