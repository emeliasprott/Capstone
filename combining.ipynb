{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Up the Data\n",
    "In this notebook, I will identify the relationships between all of the data. Many of the relationships depend on string matches, but the text data is inconsistent and has many typos. For example, *'Assemblymember'* could be written as *'Assemblyman'*, *'Assemblywoman'*, *'A semblmember'*, and more. At the same time, with so many repeated words and phrases, many strings appear to match when they should not. A simple string-distance algorithm might find 'Assemblymember David Chiu' to match with 'Assemblymember Dave Chu', which is not correct. Therefore I use an approach that combines fuzzy string matching and regex  with spacy token similarity and entity linking to match the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/jkjxx5pj447bytbqv8pkw9nh0000gn/T/ipykernel_22615/176948873.py:1: DtypeWarning: Columns (4,6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  bill_analysis = pd.read_csv('ca_leg/legislation_data/bill_analysis_tbl.csv')\n"
     ]
    }
   ],
   "source": [
    "bill_analysis = pd.read_csv('ca_leg/legislation_data/bill_analysis_tbl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "committee_codes = bill_analysis.loc[bill_analysis['committee_code'].notna(), ['committee_code', 'committee_name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "committee_codes.to_csv('ca_leg/legislation_data/committee_codes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bills = pd.read_csv('ca_leg/legislation_data/bill_tbl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_history = pd.read_csv('ca_leg/legislation_data/bill_history_tbl.csv', dtype={'action_status': str, 'primary_location': str, 'secondary_location': str, 'end_status': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_versions = pd.read_csv('ca_leg/legislation_data/bill_version_tbl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ca_leg/legislation_data/bill_version_text.json\", \"r\") as f:\n",
    "    bill_text = json.load(f)\n",
    "    authors_data = {bill_id: bill_info['Authors']\n",
    "                   for bill_id, bill_info in bill_text.items()\n",
    "                   if 'Authors' in bill_info}\n",
    "    bill_text_data = {}\n",
    "    for bill_id, bill_info in bill_text.items():\n",
    "        record = {}\n",
    "        if 'Title' in bill_info.keys():\n",
    "            title = bill_info.get('Title')\n",
    "            record.update({'title': title})\n",
    "        if 'GeneralSubject' in bill_info.keys():\n",
    "            general_subject = bill_info.get('GeneralSubject')\n",
    "            record.update({'general_subject': general_subject})\n",
    "        if 'DigestText' in bill_info.keys():\n",
    "            digest_text = bill_info.get('DigestText')\n",
    "            record.update({'digest_text': digest_text})\n",
    "        if 'BillContent' in bill_info.keys():\n",
    "            content = bill_info.get('BillContent')\n",
    "            record.update({'content': content})\n",
    "        bill_text_data[bill_id] = record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRINCIPAL_COAUTHOR', 'COAUTHOR', 'null', 'LEAD_AUTHOR']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set([a for b in [v.keys() for v in authors_data.values()] for a in b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'VersionNum': '95',\n",
       " 'History': {'INTRODUCED': '2024-02-16', 'AMENDED_ASSEMBLY': '2024-04-24'},\n",
       " 'SessionYear': '2023',\n",
       " 'SessionNum': '0',\n",
       " 'MeasureType': 'AB',\n",
       " 'MeasureNum': '2968',\n",
       " 'MeasureState': 'AMD',\n",
       " 'Authors': {'LEAD_AUTHOR': {'ASSEMBLY': 'Connolly'}},\n",
       " 'Title': 'An act to amend Section 32282 of, and to add Article 4.5 (commencing with Section 32277) to Chapter 2.5 of Part 19 of Division 1 of Title 1 of, the Education Code, relating to fire protection.',\n",
       " 'GeneralSubject': 'School safety and fire prevention: fire hazard severity zones: comprehensive school safety plans: communication and evacuation plans. ',\n",
       " 'DigestText': 'Existing law requires the State Fire Marshal to identify, according to specified procedures, high and very high fire hazard severity zones within state responsibility areas and lands that are not within state responsibility areas.Existing law provides that school districts and county offices of education are\\n\\t\\t\\t responsible for the overall development of a comprehensive school safety plan for each of its schools, as provided. Existing law requires a schoolsite council to write and develop a comprehensive school safety plan relevant to the needs and resources of that particular school, in consultation with a representative from a law enforcement agency, a fire department, and other first responder entities, as specified, while providing an alternate mechanism for compliance with this requirement for small school districts, as defined. Existing law requires the comprehensive school safety plan to include appropriate strategies and programs relating to school safety and school safety law compliance, including the development of specified disaster procedures. Existing law authorizes a chartering authority to deny a petition for the establishment of a charter school for specified reasons, including the absence in the charter petition of a reasonably comprehensive description of the development of a school safety plan\\n\\t\\t\\t that includes these same topics. This bill would, commencing with the 2026–27 fiscalThe California Constitution requires the state to reimburse local agencies and school districts for certain costs mandated by the state. Statutory provisions establish procedures for making that reimbursement.This bill would provide that, if the Commission on State Mandates determines that the bill contains costs mandated by the state, reimbursement for those costs shall be made pursuant to the statutory provisions noted above.',\n",
       " 'BillContent': 'Education Code Education Code If the Commission on State Mandates determines that this act contains costs mandated by the state, reimbursement to local agencies and school districts for those costs shall be made pursuant to Part 7 (commencing with Section 17500) of Division 4 of Title 2 of the Government Code.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bill_text['20230AB__296895AMD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for bill_id, authors in authors_data.items():\n",
    "    for author_type, house in authors.items():\n",
    "        for house_name, author_name in house.items():\n",
    "            records.append([bill_id, author_type, \"COMMITTEE\" if house_name == 'UNKNOWN' else house_name, author_name])\n",
    "\n",
    "df = pd.DataFrame(records, columns=['bill_id', 'author_type', 'house', 'author_name'])\n",
    "df['bill_id'] = df['bill_id'].apply(lambda x: re.sub(r'__', '', x))\n",
    "combined = df.merge(bill_versions, left_on='bill_id', right_on='bill_version_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_text_records = []\n",
    "for bill_id, text_info in bill_text_data.items():\n",
    "    record = {'bill_id': bill_id}\n",
    "    record.update(text_info)\n",
    "    bill_text_records.append(record)\n",
    "bill_text_df = pd.DataFrame(bill_text_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_text_df.to_csv('ca_leg/legislation_data/bill_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = combined.loc[combined['bill_version_action'].notna()].merge(bills, left_on='bill_id_y', right_on='bill_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.to_csv('ca_leg/legislation_data/combined_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/jkjxx5pj447bytbqv8pkw9nh0000gn/T/ipykernel_53776/2120954024.py:1: DtypeWarning: Columns (30,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  full = pd.read_csv('ca_leg/legislation_data/combined_table.csv')\n"
     ]
    }
   ],
   "source": [
    "full = pd.read_csv('ca_leg/legislation_data/combined_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bill_id_x', 'author_type', 'house', 'author_name', 'bill_version_id',\n",
       "       'bill_id_y', 'version_num', 'bill_version_action_date',\n",
       "       'bill_version_action', 'request_num', 'subject', 'vote_required',\n",
       "       'appropriation', 'fiscal_committee', 'local_program',\n",
       "       'substantive_changes', 'urgency', 'taxlevy', 'bill_xml', 'year_x',\n",
       "       'bill_id', 'session_year', 'session_num', 'measure_num',\n",
       "       'measure_state', 'chapter_year', 'chapter_type', 'chapter_session_num',\n",
       "       'chapter_num', 'latest_bill_version_id', 'current_location',\n",
       "       'current_status', 'year_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "disclosure = pd.read_csv('calaccess/CVR_LOBBY_DISCLOSURE_CD.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditure = pd.read_csv('calaccess/LEXP_CD.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lobbying = disclosure[['FILING_ID', 'FIRM_NAME']].merge(expenditure, on='FILING_ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lobbying['EXPN_DATE'] = pd.to_datetime(lobbying['EXPN_DATE'], format='%m/%d/%Y %H:%M:%S %p', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = lobbying.loc[(lobbying['EXPN_DATE'].notna()) & (lobbying['EXPN_DATE'] > pd.to_datetime('2001-01-01', format='%Y-%m-%d')) & ((lobbying['BENE_NAME'].notna()) | (lobbying['BENE_POSIT'].notna()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_committees = pd.read_csv('pdf_parsing/assembly_committees_clean.csv')\n",
    "assembly_roster = pd.read_csv('pdf_parsing/assembly_roster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "senate_committees = pd.read_csv('pdf_parsing/senate_committees_cleaned.csv')\n",
    "senate_roster = pd.read_csv('pdf_parsing/senate_roster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "senate_roster['Last'] = senate_roster['Name'].str.split(',').str[0].apply(lambda x: x.strip())\n",
    "senate_roster['Term'] = senate_roster['pages'].apply(lambda x: f\"{2000 + int(x.split(',')[0].strip())}-{2000 + int(x.split(',')[1].strip())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def politician_table(committees, roster):\n",
    "    doubles = committees.loc[committees['politician'].str.contains(',')]\n",
    "    hyphens = committees.loc[committees['politician'].str.contains('-')]\n",
    "    neither = committees.loc[(~committees['politician'].str.contains(',')) & (~committees['politician'].str.contains('-'))]\n",
    "    hyphens['Last'] = hyphens['politician'].apply(lambda x: re.sub(r'-', ' ', x))\n",
    "    hyp = hyphens.merge(roster, left_on=['Last', 'term'], right_on=['Last', 'Term'], how='inner')\n",
    "    if len(doubles) > 0:\n",
    "        doubles[['Last', 'First']] = doubles['politician'].str.split(',', expand=True)\n",
    "        doubles['Last'] = doubles['Last'].str.strip()\n",
    "        doubles['First'] = doubles['First'].str.strip()\n",
    "        doubles.rename(columns={'term': 'Term'}, inplace=True)\n",
    "        dbs = doubles.merge(roster, on=['Last', 'First', 'Term'], how='left')\n",
    "        politicians = pd.concat([neither.merge(roster, left_on=['politician', 'term'], right_on=['Last', 'Term'], how='inner'), hyp, dbs])\n",
    "    else:\n",
    "        politicians = pd.concat([neither.merge(roster, left_on=['politician', 'term'], right_on=['Last', 'Term'], how='inner'), hyp])\n",
    "    return politicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly = politician_table(assembly_committees, assembly_roster)\n",
    "senate = politician_table(senate_committees, senate_roster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly['full_name'] = assembly['First'] + ' ' + assembly['Last']\n",
    "senate['full_name'] = senate['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.strip()) + ' ' + senate['Name'].apply(lambda x: x.split(',')[0]).apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly['chamber'] = 'assembly'\n",
    "senate['chamber'] = 'senate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians = pd.concat([assembly[['committee_clean', 'position', 'Occupation', 'Party', 'District No.', 'Seat No.', 'Term', 'Last', 'full_name', 'chamber']], senate[['committee_clean', 'position', 'Occupation', 'Party', 'District No.', 'Seat No.', 'Term', 'Last', 'full_name', 'chamber']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians.to_csv('ca_leg/legislation_data/politicians.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "po = pd.read_csv('ca_leg/legislation_data/politicians.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from rapidfuzz import fuzz, process\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = unidecode(text.lower().strip())\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "df_lob = lb.copy()[['BENE_NAME', 'BENE_POSIT']].drop_duplicates()\n",
    "df_legislators = politicians['full_name'].drop_duplicates().apply(clean_text).tolist()\n",
    "df_committees = politicians['committee_clean'].drop_duplicates().apply(clean_text).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_ids = {name: f\"LEG_{i}\" for i, name in enumerate(df_legislators)}\n",
    "entity_ids.update({name: f\"COM_{i}\" for i, name in enumerate(df_committees)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = unidecode(text).upper()\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    prefixes = r'^(HON|HONORABLE|REP|REPRESENTATIVE|SEN|SENATOR|ASSEMBLY|ASSEMBLYMAN|ASSEMBLYMEMBER|COMMITTEE\\s+ON|THE|STAFF\\s+OF|OFFICE\\s+OF)\\s+'\n",
    "    text = re.sub(prefixes, '', text, flags=re.IGNORECASE)\n",
    "    suffixes = r'(\\s+JR|\\s+SR|\\s+III|\\s+II|\\s+IV|\\s+MD|\\s+PHD|\\s+ESQ)$'\n",
    "    text = re.sub(suffixes, '', text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "def preprocess_entity_ids(entity_ids):\n",
    "    name_mapping = {}\n",
    "    processed_entities = {}\n",
    "    ngram_index = {}\n",
    "\n",
    "    for original_name, entity_id in entity_ids.items():\n",
    "        clean_name = clean_text(original_name)\n",
    "        entity_type = 'legislator' if entity_id.startswith(\"LEG_\") else 'committee'\n",
    "\n",
    "        name_mapping[clean_name] = {\n",
    "            'original': original_name,\n",
    "            'id': entity_id,\n",
    "            'type': entity_type\n",
    "        }\n",
    "\n",
    "        processed_entities[original_name] = {\n",
    "            'clean_name': clean_name,\n",
    "            'tokens': set(clean_name.split()),\n",
    "            'entity_type': entity_type,\n",
    "            'id': entity_id\n",
    "        }\n",
    "        tokens = clean_name.split()\n",
    "        for token in tokens:\n",
    "            if len(token) >= 3:\n",
    "                if token not in ngram_index:\n",
    "                    ngram_index[token] = []\n",
    "                ngram_index[token].append(original_name)\n",
    "        if len(tokens) >= 2:\n",
    "            for i in range(len(tokens) - 1):\n",
    "                bigram = f\"{tokens[i]} {tokens[i+1]}\"\n",
    "                if bigram not in ngram_index:\n",
    "                    ngram_index[bigram] = []\n",
    "                ngram_index[bigram].append(original_name)\n",
    "\n",
    "    return {\n",
    "        'name_mapping': name_mapping,\n",
    "        'processed_entities': processed_entities,\n",
    "        'ngram_index': ngram_index,\n",
    "        'legislator_names': [name for name, eid in entity_ids.items() if eid.startswith(\"LEG_\")],\n",
    "        'committee_names': [name for name, eid in entity_ids.items() if eid.startswith(\"COM_\")]\n",
    "    }\n",
    "\n",
    "def get_candidates_by_ngrams(text, ngram_index):\n",
    "    cleaned = clean_text(text)\n",
    "    tokens = cleaned.split()\n",
    "\n",
    "    candidates = {}\n",
    "\n",
    "    for token in tokens:\n",
    "        if len(token) >= 3 and token in ngram_index:\n",
    "            for candidate in ngram_index[token]:\n",
    "                candidates[candidate] = candidates.get(candidate, 0) + 1\n",
    "\n",
    "    if len(tokens) >= 2:\n",
    "        for i in range(len(tokens) - 1):\n",
    "            bigram = f\"{tokens[i]} {tokens[i+1]}\"\n",
    "            if bigram in ngram_index:\n",
    "                for candidate in ngram_index[bigram]:\n",
    "                    candidates[candidate] = candidates.get(candidate, 0) + 3\n",
    "\n",
    "    return sorted(candidates.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_score(text1, text2):\n",
    "    clean1 = clean_text(text1)\n",
    "    clean2 = clean_text(text2)\n",
    "\n",
    "    if not clean1 or not clean2:\n",
    "        return 0\n",
    "\n",
    "    if clean1 == clean2:\n",
    "        return 100\n",
    "\n",
    "    tokens1 = set(clean1.split())\n",
    "    tokens2 = set(clean2.split())\n",
    "\n",
    "    intersection = tokens1.intersection(tokens2)\n",
    "    jaccard = len(intersection) / (len(tokens1) + len(tokens2) - len(intersection)) if (len(tokens1) + len(tokens2) - len(intersection)) > 0 else 0\n",
    "    subsequence_score = 0\n",
    "    if clean1 in clean2 or clean2 in clean1:\n",
    "        subsequence_score = 30\n",
    "\n",
    "    fuzzy_score = fuzz.token_set_ratio(clean1, clean2) * 0.7  # FUZZY SCORE\n",
    "\n",
    "    final_score = (jaccard * 25) + subsequence_score + fuzzy_score # final score\n",
    "\n",
    "    return min(final_score, 100)\n",
    "\n",
    "def extract_referenced_names(position_text):\n",
    "    if not position_text or not isinstance(position_text, str):\n",
    "        return []\n",
    "    referenced_names = []\n",
    "    position_lower = position_text.lower()\n",
    "    # bulk regex search\n",
    "    patterns = [\n",
    "        r'(?:staff|aide|assist\\w*|chief|counsel|direct\\w*)(?:\\s+\\w+)?\\s+(?:to|for|of|with)\\s+(?:sen\\w*|rep\\w*|assembl\\w*|congress\\w*)?\\s+([A-Za-z\\s\\.\\-]+?)(?:$|,|\\s+\\(|\\s+[A-Z]{2})',\n",
    "        r'(?:sen\\w*|rep\\w*|assembl\\w*|congress\\w*)\\s+([A-Za-z\\s\\.\\-]+?)(?:\\'s?)?\\s+(?:staff|office|aide|assist\\w*|chief)',\n",
    "        r'(?:office|staff)\\s+(?:of|for)\\s+(?:sen\\w*|rep\\w*|assembl\\w*|congress\\w*)?\\s+([A-Za-z\\s\\.\\-]+?)(?:$|,|\\s+\\(|\\s+[A-Z]{2})',\n",
    "        r'(?:sen\\w*|rep\\w*|assembl\\w*|congress\\w*)\\s+([A-Za-z\\s\\.\\-]{2,30})(?:$|,|\\s+\\(|\\s+[A-Z]{2})',\n",
    "        r'\\b([A-Za-z\\s\\.\\-]{2,30})\\s+\\([A-Z]{2}\\)',\n",
    "        r'\\b(?:senator|representative|congressman|chairperson|chairman|assembl\\w*)\\s+([A-Za-z\\s\\.\\-]{2,30})\\b'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        matches = re.finditer(pattern, position_lower, re.IGNORECASE)\n",
    "        for match in matches:\n",
    "            name = match.group(1).strip()\n",
    "            if name and len(name) > 2:\n",
    "                if any(term not in name.lower() for term in ['staff', 'office', 'committee']):\n",
    "                    start, end = match.span(1)\n",
    "                    original_case = position_text[start:end].strip()\n",
    "                    if original_case and len(original_case) > 2 and original_case not in referenced_names:\n",
    "                        referenced_names.append(original_case)\n",
    "\n",
    "    if not referenced_names: # NER if no matches found\n",
    "        try:\n",
    "            doc = nlp(position_text)\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == \"PERSON\" and len(ent.text) > 2:\n",
    "                    if ent.text not in referenced_names:\n",
    "                        referenced_names.append(ent.text)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return referenced_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46309/46309 [02:29<00:00, 310.25it/s]\n"
     ]
    }
   ],
   "source": [
    "result_df = df_lob.copy()\n",
    "entity_data = preprocess_entity_ids(entity_ids)\n",
    "name_mapping = entity_data['name_mapping']\n",
    "ngram_index = entity_data['ngram_index']\n",
    "legislator_names = entity_data['legislator_names']\n",
    "committee_names = entity_data['committee_names']\n",
    "\n",
    "GENERIC_LEGISLATOR_TITLES = ['assemblymember', 'senator', 'assemblyman', 'assemblywoman']\n",
    "GOV_DEPT_INDICATORS = ['ca department', 'ca dept', 'california department', 'california dept','department of', 'dept. of', 'dept of', 'agency', 'bureau', 'division of', 'state of california', 'state board', 'state commission']\n",
    "result_df['MATCHED_NAME'] = None\n",
    "result_df['ENTITY_ID'] = None\n",
    "result_df['ENTITY_TYPE'] = None\n",
    "result_df['MATCH_METHOD'] = None\n",
    "result_df['CONFIDENCE'] = None\n",
    "\n",
    "for idx, row in tqdm(result_df.iterrows(), total=len(result_df)):\n",
    "    bene_name = str(row['BENE_NAME']) if pd.notna(row['BENE_NAME']) else \"\"\n",
    "    bene_position = str(row['BENE_POSIT']) if pd.notna(row['BENE_POSIT']) else \"\"\n",
    "    if not bene_name.strip() and not bene_position.strip():\n",
    "        continue\n",
    "    combined_text = f\"{bene_name} {bene_position}\".lower()\n",
    "    if any(indicator in combined_text for indicator in GOV_DEPT_INDICATORS):\n",
    "        continue\n",
    "\n",
    "\n",
    "    position_is_generic = bene_position.strip().lower() in GENERIC_LEGISLATOR_TITLES\n",
    "    for field_name, field_value in [('BENE_NAME', bene_name),\n",
    "                                   ('BENE_POSIT', bene_position if not position_is_generic else \"\")]:\n",
    "        if not field_value.strip():\n",
    "            continue\n",
    "\n",
    "        clean_value = clean_text(field_value)\n",
    "        if clean_value in name_mapping:\n",
    "            entity_info = name_mapping[clean_value]\n",
    "            result_df.at[idx, 'MATCHED_NAME'] = entity_info['original']\n",
    "            result_df.at[idx, 'ENTITY_ID'] = entity_info['id']\n",
    "            result_df.at[idx, 'ENTITY_TYPE'] = entity_info['type']\n",
    "            result_df.at[idx, 'MATCH_METHOD'] = f'exact_{field_name.lower()}'\n",
    "            result_df.at[idx, 'CONFIDENCE'] = 'high'\n",
    "            break\n",
    "    if pd.notna(result_df.at[idx, 'MATCHED_NAME']):\n",
    "        continue\n",
    "    all_referenced_names = []\n",
    "    if not position_is_generic:\n",
    "        all_referenced_names.extend(extract_referenced_names(bene_position))\n",
    "    all_referenced_names.extend(extract_referenced_names(bene_name))\n",
    "\n",
    "    for ref_name in all_referenced_names:\n",
    "        clean_ref = clean_text(ref_name)\n",
    "        if clean_ref in name_mapping:\n",
    "            entity_info = name_mapping[clean_ref]\n",
    "            result_df.at[idx, 'MATCHED_NAME'] = entity_info['original']\n",
    "            result_df.at[idx, 'ENTITY_ID'] = entity_info['id']\n",
    "            result_df.at[idx, 'ENTITY_TYPE'] = entity_info['type']\n",
    "            result_df.at[idx, 'MATCH_METHOD'] = 'reference_exact'\n",
    "            result_df.at[idx, 'CONFIDENCE'] = 'high'\n",
    "            break\n",
    "\n",
    "    if pd.notna(result_df.at[idx, 'MATCHED_NAME']):\n",
    "        continue\n",
    "\n",
    "    position_has_legislator = any(term in combined_text for term in ['senator', 'representative', 'rep ', 'sen ', 'assemblymember', 'assemblyman', 'assemblywoman', 'assembly member'])\n",
    "    position_has_committee = any(term in combined_text for term in ['committee', 'commission', 'board', 'task force', 'caucus'])\n",
    "    search_pool = None\n",
    "\n",
    "    if position_has_legislator:\n",
    "        search_pool = legislator_names\n",
    "    elif position_has_committee:\n",
    "        search_pool = committee_names\n",
    "\n",
    "    candidates = []\n",
    "    if bene_name.strip():\n",
    "        candidates.extend(get_candidates_by_ngrams(bene_name, ngram_index))\n",
    "\n",
    "    if bene_position.strip() and not position_is_generic:\n",
    "        candidates.extend(get_candidates_by_ngrams(bene_position, ngram_index))\n",
    "\n",
    "    seen = set()\n",
    "    unique_candidates = [(name, score) for name, score in candidates\n",
    "                         if not (name in seen or seen.add(name))]\n",
    "\n",
    "    if search_pool:\n",
    "        unique_candidates = [(name, score) for name, score in unique_candidates if name in search_pool]\n",
    "\n",
    "    top_candidates = unique_candidates[:10] if unique_candidates else []\n",
    "\n",
    "    if top_candidates:\n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        best_method = None\n",
    "\n",
    "        for candidate_name, _ in top_candidates:\n",
    "            if bene_name.strip():\n",
    "                name_score = calculate_similarity_score(bene_name, candidate_name)\n",
    "\n",
    "                if name_score > best_score and name_score >= 75:\n",
    "                    best_score = name_score\n",
    "                    best_match = candidate_name\n",
    "                    best_method = \"fuzzy_name\"\n",
    "            if bene_position.strip() and not position_is_generic:\n",
    "                position_score = calculate_similarity_score(bene_position, candidate_name)\n",
    "                if position_score > best_score and position_score >= 85:\n",
    "                    best_score = position_score\n",
    "                    best_match = candidate_name\n",
    "                    best_method = \"fuzzy_position\"\n",
    "            if bene_name.strip() and bene_position.strip():\n",
    "                combined_text = f\"{bene_name} {bene_position}\"\n",
    "                combined_score = calculate_similarity_score(combined_text, candidate_name)\n",
    "\n",
    "                if combined_score > best_score and combined_score >= 70:\n",
    "                    best_score = combined_score\n",
    "                    best_match = candidate_name\n",
    "                    best_method = \"fuzzy_combined\"\n",
    "\n",
    "        if best_match:\n",
    "            confidence = \"high\" if best_score >= 90 else \"medium\" if best_score >= 75 else \"low\"\n",
    "\n",
    "            result_df.at[idx, 'MATCHED_NAME'] = best_match\n",
    "            result_df.at[idx, 'ENTITY_ID'] = entity_ids[best_match]\n",
    "            result_df.at[idx, 'ENTITY_TYPE'] = 'legislator' if entity_ids[best_match].startswith('LEG_') else 'committee'\n",
    "            result_df.at[idx, 'MATCH_METHOD'] = best_method\n",
    "            result_df.at[idx, 'CONFIDENCE'] = confidence\n",
    "            continue\n",
    "\n",
    "    for field_name, field_value in [('BENE_NAME', bene_name),\n",
    "                                   ('BENE_POSIT', bene_position if not position_is_generic else \"\")]:\n",
    "        if not field_value.strip():\n",
    "            continue\n",
    "\n",
    "        clean_value = clean_text(field_value)\n",
    "        search_list = search_pool if search_pool else list(entity_ids.keys())\n",
    "\n",
    "        name_match = process.extractOne(\n",
    "            clean_value,\n",
    "            search_list,\n",
    "            scorer=fuzz.token_sort_ratio,\n",
    "            score_cutoff=85\n",
    "        )\n",
    "\n",
    "        if name_match:\n",
    "            match, score = name_match\n",
    "            result_df.at[idx, 'MATCHED_NAME'] = match\n",
    "            result_df.at[idx, 'ENTITY_ID'] = entity_ids[match]\n",
    "            result_df.at[idx, 'ENTITY_TYPE'] = 'legislator' if entity_ids[match].startswith('LEG_') else 'committee'\n",
    "            result_df.at[idx, 'MATCH_METHOD'] = f'direct_fuzzy_{field_name.lower()}'\n",
    "            result_df.at[idx, 'CONFIDENCE'] = 'high' if score > 90 else 'medium'\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "ben_name_positions_dict = result_df.loc[result_df['CONFIDENCE'].notna(), ['BENE_NAME', 'BENE_POSIT', 'MATCHED_NAME']].set_index(['BENE_NAME', 'BENE_POSIT']).to_dict()['MATCHED_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb['clean_beneficiary'] = lb[['BENE_NAME', 'BENE_POSIT']].apply(lambda x: ben_name_positions_dict.get(tuple(x), None), axis=1)\n",
    "lb.to_csv('calaccess/lobbying_clean2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditure_assembly = pd.read_csv('calaccess/expenditure_assembly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly['target_name'] = assembly['Last'] + ', ' + assembly['First']\n",
    "expenditure_assembly['year'] = expenditure_assembly['DateRange'].apply(lambda x: int(x.split('-')[0]))\n",
    "expenditure_assembly['term'] = expenditure_assembly['year'].apply(lambda x: f\"{x}-{x+1}\" if x % 2 != 0 else f\"{x-1}-{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_names(_names, expenditure_df):\n",
    "    expenditure_names = expenditure_df['TargetCandidateName'].unique()\n",
    "    name_mapping = {}\n",
    "    for exp_name in expenditure_names:\n",
    "        best_match = process.extractOne(\n",
    "            exp_name,\n",
    "            _names,\n",
    "            scorer=fuzz.token_sort_ratio,\n",
    "            score_cutoff=90\n",
    "        )\n",
    "\n",
    "        if best_match:\n",
    "            name_mapping[exp_name] = best_match[0]\n",
    "        else:\n",
    "            name_mapping[exp_name] = None\n",
    "\n",
    "    return name_mapping\n",
    "\n",
    "name_mapping = match_names(assembly['target_name'].unique(), expenditure_assembly)\n",
    "expenditure_assembly['matched_target_name'] = expenditure_assembly['TargetCandidateName'].map(name_mapping)\n",
    "merged_df = pd.merge(\n",
    "    expenditure_assembly,\n",
    "    assembly,\n",
    "    left_on='matched_target_name',\n",
    "    right_on='target_name',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('calaccess/expend_assembly_matched.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditure_senate = pd.read_csv('calaccess/expenditure_senator.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "senate_name_mapping = match_names(senate['Name'].unique(), expenditure_senate)\n",
    "expenditure_senate['matched_target_name'] = expenditure_senate['TargetCandidateName'].map(senate_name_mapping)\n",
    "merged_senate_df = pd.merge(\n",
    "    expenditure_senate,\n",
    "    senate,\n",
    "    left_on='matched_target_name',\n",
    "    right_on='Name',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_senate_df.to_csv('calaccess/expend_senate_matched.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/jkjxx5pj447bytbqv8pkw9nh0000gn/T/ipykernel_99337/2005777650.py:1: DtypeWarning: Columns (30,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined = pd.read_csv('ca_leg/legislation_data/combined_table.csv')\n"
     ]
    }
   ],
   "source": [
    "combined = pd.read_csv('ca_leg/legislation_data/combined_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "motions = pd.read_csv('ca_leg/legislation_data/bill_motion_tbl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "motion_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "motion_text",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "12d7bc43-6e83-4d5d-8a8a-4d264e032284",
       "rows": [
        [
         "0",
         "33445",
         "Assembly 3rd Reading AB3004 Committee on Budget (Oropeza)",
         "2013"
        ],
        [
         "1",
         "33446",
         "Assembly 3rd Reading AB3006 Committee on Budget (Oropeza)",
         "2013"
        ],
        [
         "2",
         "33447",
         "Assembly 3rd Reading AB3008 Committee on Budget (Oropeza) By Peace",
         "2013"
        ],
        [
         "3",
         "33448",
         "Assembly 3rd Reading AB3009 Committee on Budget (Oropeza)",
         "2013"
        ],
        [
         "4",
         "33450",
         "W/O REF. TO FILE AB3010 Committee on Budget (Oropeza)",
         "2013"
        ],
        [
         "5",
         "33451",
         "W/O REF. TO FILE AB3011 Committee on Budget (Oropeza) Amend by Peace",
         "2013"
        ],
        [
         "6",
         "33452",
         "Senate 3rd Reading SB1832 Committee on B. & F.R. (Peace)",
         "2013"
        ],
        [
         "7",
         "33453",
         "Senate 3rd Reading SB1834 Committee on B. & F.R. (Peace)",
         "2013"
        ],
        [
         "8",
         "33455",
         "AB 601 Leach  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "9",
         "33456",
         "AB 693 Longville  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "10",
         "33457",
         "AB 1336 Koretz  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "11",
         "33458",
         "AB 1509 Runner  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "12",
         "33459",
         "AB 1863 HIGHER ED.  Concurrence in Senate Amendments By Alquist",
         "2013"
        ],
        [
         "13",
         "33460",
         "AB 1909 Cohn  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "14",
         "33461",
         "AB 1933 Reyes  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "15",
         "33462",
         "AB 1934 Corbett  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "16",
         "33463",
         "AB 2105 La Suer  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "17",
         "33465",
         "AB 2299 Bates  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "18",
         "33466",
         "AB 2346 Dickerson  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "19",
         "33467",
         "AB 2417 La Suer  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "20",
         "33468",
         "AB 2456 Jackson  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "21",
         "33469",
         "AB 2493 Pacheco,Robert  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "22",
         "33470",
         "AB 2526 Dickerson  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "23",
         "33471",
         "AB 2647 Liu  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "24",
         "33472",
         "AB 3008 BUDGET  Concurrence in Senate Amendments By Oropeza",
         "2013"
        ],
        [
         "25",
         "33473",
         "AB 3030 Corbett  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "26",
         "33474",
         "ACR 81 Hollingsworth  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "27",
         "33481",
         "SB 2086 REV.& TAX.  Consent Calendar Second Day  Regular Session",
         "2013"
        ],
        [
         "28",
         "33508",
         "AB 1493 Pavley  Motion to Reconsider  By Wyman",
         "2013"
        ],
        [
         "29",
         "33509",
         "AB 1753 Migden  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "30",
         "33510",
         "AB 1912 Kehoe  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "31",
         "33511",
         "AB 1964 Diaz  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "32",
         "33512",
         "AB 2182 Campbell,J  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "33",
         "33513",
         "AB 2846 Frommer  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "34",
         "33514",
         "AB 3011 BUDGET  Concurrence in Senate Amendments By Oropeza",
         "2013"
        ],
        [
         "35",
         "33525",
         "AB 57 Wright  Concurrence- Urgency Added",
         "2013"
        ],
        [
         "36",
         "33526",
         "AB 1714 Canciamilla  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "37",
         "33270",
         "SB 2052 Sher  Consent Calendar Second Day  Regular Session",
         "2013"
        ],
        [
         "38",
         "33271",
         "Senate 3rd Reading SCR84 Costa",
         "2013"
        ],
        [
         "39",
         "33273",
         "Unfinished Business SJR25 Scott",
         "2013"
        ],
        [
         "40",
         "33300",
         "AB 137 Reyes  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "41",
         "33301",
         "Consent Calendar 2nd AB601 Leach",
         "2013"
        ],
        [
         "42",
         "33302",
         "AB 670 Strom-Martin  Concurrence in Senate Amendments",
         "2013"
        ],
        [
         "43",
         "33303",
         "SPECIAL CONSENT CALE AB1138 Pescetti",
         "2013"
        ],
        [
         "44",
         "33304",
         "SPECIAL CONSENT CALE AB1458 Kelley",
         "2013"
        ],
        [
         "45",
         "33305",
         "SPECIAL CONSENT CALE AB1509 Runner",
         "2013"
        ],
        [
         "46",
         "33306",
         "SPECIAL CONSENT CALE AB1749 Longville",
         "2013"
        ],
        [
         "47",
         "33307",
         "SPECIAL CONSENT CALE AB1752 Migden",
         "2013"
        ],
        [
         "48",
         "33308",
         "Consent Calendar 2nd AB1784 Harman",
         "2013"
        ],
        [
         "49",
         "33309",
         "SPECIAL CONSENT CALE AB1863 Committee on Higher Ed (Alquist)",
         "2013"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 588234
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motion_id</th>\n",
       "      <th>motion_text</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33445</td>\n",
       "      <td>Assembly 3rd Reading AB3004 Committee on Budge...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33446</td>\n",
       "      <td>Assembly 3rd Reading AB3006 Committee on Budge...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33447</td>\n",
       "      <td>Assembly 3rd Reading AB3008 Committee on Budge...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33448</td>\n",
       "      <td>Assembly 3rd Reading AB3009 Committee on Budge...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33450</td>\n",
       "      <td>W/O REF. TO FILE AB3010 Committee on Budget (O...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588229</th>\n",
       "      <td>124034</td>\n",
       "      <td>Special Consent #34 AB2249 Niello</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588230</th>\n",
       "      <td>124035</td>\n",
       "      <td>AB 2260 HIGHER ED.  Concurrence in Senate Amen...</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588231</th>\n",
       "      <td>124036</td>\n",
       "      <td>AB 2323 HUFF  Concurrence in Senate Amendments</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588232</th>\n",
       "      <td>124037</td>\n",
       "      <td>AB 2343 CABALLERO  Concurrence in Senate Amend...</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588233</th>\n",
       "      <td>124038</td>\n",
       "      <td>Special Consent #34 AB2357 Duvall</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588234 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        motion_id                                        motion_text  year\n",
       "0           33445  Assembly 3rd Reading AB3004 Committee on Budge...  2013\n",
       "1           33446  Assembly 3rd Reading AB3006 Committee on Budge...  2013\n",
       "2           33447  Assembly 3rd Reading AB3008 Committee on Budge...  2013\n",
       "3           33448  Assembly 3rd Reading AB3009 Committee on Budge...  2013\n",
       "4           33450  W/O REF. TO FILE AB3010 Committee on Budget (O...  2013\n",
       "...           ...                                                ...   ...\n",
       "588229     124034                  Special Consent #34 AB2249 Niello  2025\n",
       "588230     124035  AB 2260 HIGHER ED.  Concurrence in Senate Amen...  2025\n",
       "588231     124036     AB 2323 HUFF  Concurrence in Senate Amendments  2025\n",
       "588232     124037  AB 2343 CABALLERO  Concurrence in Senate Amend...  2025\n",
       "588233     124038                  Special Consent #34 AB2357 Duvall  2025\n",
       "\n",
       "[588234 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ca_leg_etl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
