{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, datetime, json, pickle, re\n",
    "from pathlib import Path\n",
    "from torch_geometric.transforms import ToUndirected, RemoveIsolatedNodes\n",
    "from pathlib import Path\n",
    "import torch, numpy as np, pandas as pd\n",
    "import pyarrow as pa, pyarrow.parquet as pq\n",
    "\n",
    "DATA_PATH = Path(\"../../../data3.pt\")\n",
    "EXPORT_PATH = Path(\"../../shiny/data\")\n",
    "OUT_PATH = EXPORT_PATH\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "FLOAT = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- identify and map topic labels to all dfs\n",
    "- change column names to fit app\n",
    "- add more data to the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../node_id_map.json', 'r') as f:\n",
    "        node_id_map = json.load(f)\n",
    "\n",
    "with open('../../../bill_labels_updated.json', 'r') as f:\n",
    "    topic_cluster_labels_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = Path(\"../..\")\n",
    "\n",
    "embeddings = torch.load(OUT_DIR / \"node_embeddings.pt\", map_location=DEVICE)\n",
    "preds = torch.load(OUT_DIR / \"predictions.pt\", map_location=DEVICE)\n",
    "\n",
    "\n",
    "bill_logits = preds[\"bill_logits\"].softmax(-1)\n",
    "bill_success_p = preds[\"success_logit\"].sigmoid()\n",
    "actor_align = preds[\"actor_align\"]\n",
    "actor_influence = preds[\"actor_influence\"]\n",
    "K_TOPICS = bill_logits.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_normalize_timestamps(timestamps, eps=1e-8):\n",
    "    timestamps = torch.nan_to_num(timestamps, nan=0.0, posinf=1e4, neginf=-1e4)\n",
    "    p5 = torch.quantile(timestamps, 0.05)\n",
    "    p95 = torch.quantile(timestamps, 0.95)\n",
    "\n",
    "    if (p95 - p5) < eps:\n",
    "        return torch.zeros_like(timestamps)\n",
    "\n",
    "    timestamps = torch.clamp(timestamps, p5, p95)\n",
    "    normalized = (timestamps - p5) / (p95 - p5)\n",
    "    return torch.nan_to_num(normalized, nan=0.0)\n",
    "\n",
    "def safe_standardize_time_format(time_data):\n",
    "    times = []\n",
    "    for t in time_data:\n",
    "        try:\n",
    "            if isinstance(t, (int, float)) and 1900 <= t  and t <= 2100:\n",
    "                td = datetime.datetime(int(t), 6, 15).timestamp()\n",
    "            elif (isinstance(t, str) or (isinstance(t, float))) and (float(t) < 2100 and float(t) > 1900):\n",
    "                td = datetime.datetime(int(float(t)), 6, 15).timestamp()\n",
    "            elif float(t) > 0 and float(t) < 1990:\n",
    "                td = t\n",
    "            elif float(t) > 17000000.0:\n",
    "                td = float(t)\n",
    "            elif isinstance(t, datetime.datetime):\n",
    "                td = t.timestamp()\n",
    "            else:\n",
    "                td = float(t) * 1e9\n",
    "        except:\n",
    "            td = datetime.datetime(2000, 6, 15).timestamp()\n",
    "        times.append(td)\n",
    "    return torch.tensor(times, dtype=torch.float32)\n",
    "\n",
    "def pull_timestamps(data):\n",
    "    timestamp_edges = [\n",
    "        ('donor', 'donated_to', 'legislator_term'),\n",
    "        ('legislator_term', 'rev_donated_to', 'donor'),\n",
    "        ('lobby_firm', 'lobbied', 'legislator_term'),\n",
    "        ('lobby_firm', 'lobbied', 'committee'),\n",
    "        ('committee', 'rev_lobbied', 'lobby_firm'),\n",
    "        ('legislator_term', 'rev_lobbied', 'lobby_firm'),\n",
    "        ('bill_version', 'rev_voted_on', 'legislator_term'),\n",
    "        ('legislator_term', 'voted_on', 'bill_version'),\n",
    "    ]\n",
    "    timestamp_nodes = ['legislator_term', 'bill_version', 'bill']\n",
    "\n",
    "    for et in timestamp_edges:\n",
    "        if hasattr(data[et], 'edge_attr') and data[et].edge_attr is not None and len(data[et].edge_attr.size()) > 1:\n",
    "            if data[et].edge_attr.size(1) > 1:\n",
    "                edge_attr = data[et].edge_attr\n",
    "                ts_col = edge_attr[:, -1]\n",
    "                if ts_col.abs().max() > 1e8 or ts_col.min() < 0:\n",
    "                    ts_col = safe_standardize_time_format(ts_col.tolist()).to(edge_attr.device)\n",
    "                data[et].timestamp = safe_normalize_timestamps(ts_col)\n",
    "                data[et].time = data[et].timestamp\n",
    "                data[et].edge_attr = edge_attr[:, :-1]\n",
    "\n",
    "    for nt in timestamp_nodes:\n",
    "        if hasattr(data[nt], 'x') and data[nt].x is not None:\n",
    "            try:\n",
    "                if len(data[nt].x.size()) > 1:\n",
    "                    if data[nt].x.size(1) > 1:\n",
    "                        x = data[nt].x\n",
    "                        ts_col = x[:, -1]\n",
    "                        if ts_col.abs().max() > 1e8 or ts_col.min() < 0:\n",
    "                            ts_col = safe_standardize_time_format(ts_col.tolist()).to(x.device)\n",
    "                        if nt in timestamp_nodes or ts_col.abs().max() > 1e6:\n",
    "                            data[nt].timestamp = safe_normalize_timestamps(ts_col)\n",
    "                            data[nt].time = data[nt].timestamp\n",
    "                            data[nt].x = x[:, :-1]\n",
    "            except:\n",
    "                pass\n",
    "    return data\n",
    "def clean_features(data):\n",
    "    for nt in data.node_types:\n",
    "        x = data[nt].x\n",
    "        x = torch.as_tensor(x, dtype=torch.float32)\n",
    "        x = torch.nan_to_num(x.float(), nan=0.0, posinf=1e4, neginf=-1e4)\n",
    "        mean = x.mean(0, keepdim=True)\n",
    "        std = x.std(0, keepdim=True).clamp(min=1e-5)\n",
    "        x = ((x - mean) / std).clamp(-10, 10)\n",
    "        data[nt].x = x\n",
    "        data[nt].x_mean = mean\n",
    "        data[nt].x_std = std\n",
    "    data = pull_timestamps(data)\n",
    "    return data\n",
    "\n",
    "def compute_controversiality(data):\n",
    "    edge_type = ('legislator_term', 'voted_on', 'bill_version')\n",
    "    if edge_type not in data.edge_index_dict:\n",
    "        raise ValueError(\"Missing 'voted_on' edges in data.\")\n",
    "\n",
    "    ei = data[edge_type].edge_index\n",
    "    ea = data[edge_type].edge_attr\n",
    "\n",
    "    vote_signal = ea[:, 0]\n",
    "\n",
    "    src_nodes = ei[0]\n",
    "    tgt_nodes = ei[1]\n",
    "\n",
    "    num_bills = data['bill_version'].num_nodes\n",
    "    device = tgt_nodes.device\n",
    "\n",
    "    yes_votes = torch.zeros(num_bills, device=device)\n",
    "    no_votes = torch.zeros(num_bills, device=device)\n",
    "\n",
    "    yes_votes.index_add_(0, tgt_nodes, (vote_signal > 0).float())\n",
    "    no_votes.index_add_(0, tgt_nodes, (vote_signal < 0).float())\n",
    "\n",
    "    total_votes = yes_votes + no_votes + 1e-6\n",
    "\n",
    "    yes_ratio = yes_votes / total_votes\n",
    "    no_ratio = no_votes / total_votes\n",
    "\n",
    "    controversy = 4 * yes_ratio * no_ratio\n",
    "    controversy = controversy.clamp(0, 1)\n",
    "    data['bill_version'].controversy = controversy\n",
    "\n",
    "    return data\n",
    "\n",
    "def load_and_preprocess_data(path='../../../data3.pt'):\n",
    "    full_data = torch.load(path, weights_only=False)\n",
    "    for nt in full_data.node_types:\n",
    "        if hasattr(full_data[nt], 'x') and full_data[nt].x is not None:\n",
    "            flat = torch.as_tensor(full_data[nt].x).flatten(start_dim=1)\n",
    "            full_data[nt].x = flat\n",
    "            full_data[nt].num_nodes = flat.size(0)\n",
    "\n",
    "    for edge_type, edge_index in full_data.edge_index_dict.items():\n",
    "        src_type, _, dst_type = edge_type\n",
    "        max_src_idx = edge_index[0].max().item() if edge_index.size(1) > 0 else -1\n",
    "        max_dst_idx = edge_index[1].max().item() if edge_index.size(1) > 0 else -1\n",
    "        if max_src_idx >= full_data[src_type].num_nodes:\n",
    "            print(f\"Fixing {src_type} node count: {full_data[src_type].num_nodes} -> {max_src_idx + 1}\")\n",
    "            full_data[src_type].num_nodes = max_src_idx + 1\n",
    "\n",
    "        if max_dst_idx >= full_data[dst_type].num_nodes:\n",
    "            print(f\"Fixing {dst_type} node count: {full_data[dst_type].num_nodes} -> {max_dst_idx + 1}\")\n",
    "            full_data[dst_type].num_nodes = max_dst_idx + 1\n",
    "    full_data['bill'].y[np.where(full_data['bill'].y < 0)[0]] = 0\n",
    "    full_data['bill'].y = torch.as_tensor(full_data['bill'].y, dtype=torch.float32)\n",
    "\n",
    "    data = ToUndirected(merge=False)(full_data)\n",
    "    del full_data\n",
    "    gc.collect()\n",
    "    data = RemoveIsolatedNodes()(data)\n",
    "    data = compute_controversiality(clean_features(data))\n",
    "\n",
    "    for nt in data.node_types:\n",
    "        ids = torch.arange(data[nt].num_nodes, device='mps')\n",
    "        data[nt].node_id = ids\n",
    "    for store in data.stores:\n",
    "        for key, value in store.items():\n",
    "            if isinstance(value, torch.Tensor) and value.dtype == torch.float64:\n",
    "                store[key] = value.float()\n",
    "\n",
    "    return data\n",
    "\n",
    "data = load_and_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "key1 = data['bill'].n_id.tolist()\n",
    "key2 = data['bill'].node_id.tolist()\n",
    "key = {k1: k2 for k1, k2 in zip(key1, key2)}\n",
    "cluster_bill = {}\n",
    "nids = []\n",
    "for bill_nid, lab in topic_cluster_labels_dict.items():\n",
    "        if bill_nid in key:\n",
    "            cluster_bill[key[bill_nid]] = lab\n",
    "            nids.append(key[bill_nid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_ts = pickle.loads(open('../../../bill_dates_map.pkl', 'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_ids = {v: k for k, v in node_id_map['bill_version'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2b_edge = tuple([et for et in data.edge_types\n",
    "                if et[0] == \"bill_version\" and et[2] == \"bill\"])[0]\n",
    "src, dst = data[v2b_edge].edge_index.numpy()\n",
    "\n",
    "bv_df = pd.DataFrame({\"bill_version\": src, \"bill_id\": data['bill'].n_id[dst]})\n",
    "bv_df['bill_version_id'] = bv_df['bill_version'].map(bv_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_dates = pd.DataFrame(bv_ts).T.reset_index().rename(columns={'index': 'bill_id'})\n",
    "bill_dates = bill_dates.loc[bill_dates['bill_id'].isin(bv_df['bill_id'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "controversy_df = pd.DataFrame({\n",
    "    'controversy': data['bill_version'].controversy[bv_df['bill_version'].unique()].numpy(),\n",
    "    'bill_version': bv_df['bill_version'].unique()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_df = pd.DataFrame({\n",
    "    'bill_id': data['bill'].n_id,\n",
    "    'outcome': data['bill'].y\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bills = bv_df.merge(controversy_df, on='bill_version', how='left').merge(outcome_df, on='bill_id', how='left')\n",
    "bills['topic_cluster'] = bills['bill_id'].map(topic_cluster_labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_dates['longevity'] = bill_dates['Last_action'] - bill_dates['First_action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_df = bills.groupby('bill_id').agg({'outcome': 'max', 'controversy': 'max', 'topic_cluster': 'max'}).merge(bill_dates[['bill_id', 'longevity']], on='bill_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../bill_labels_updated.json', 'r') as f:\n",
    "    bill_subjects = np.array(list(json.load(f).keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../bill_labels_updated.json', 'r') as f:\n",
    "    bill_labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_originals = pickle.load(open('../../../subjects_original.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../bill_subjects.json', 'r') as f:\n",
    "    bill_subjects_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "so = {k: subject_originals[v] for k, v in bill_subjects_dict.items() if v in subject_originals}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = bill_df.loc[bill_df['topic_cluster'].notna()].copy()\n",
    "topics['term'] = topics['bill_id'].apply(lambda x: x[:4]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df = topics.groupby(['term', 'topic_cluster']).agg({'outcome': lambda x: len(x.loc[x == 1]) / len(x), 'controversy': lambda x: np.mean(x.loc[x > 0]), 'bill_id': 'nunique', 'longevity': 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_topics = bills[['bill_version', 'topic_cluster']].loc[bills['topic_cluster'].notna()].drop_duplicates().set_index('bill_version').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_cluster = torch.full(\n",
    "    (data[\"bill_version\"].num_nodes,),\n",
    "    -1, dtype=torch.long)\n",
    "\n",
    "for bv_id, topic_id in bv_topics['topic_cluster'].items():\n",
    "    bv_cluster[bv_id] = int(topic_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_to_leg = data.edge_index_dict[('legislator', 'samePerson', 'legislator_term')]\n",
    "leg_of_lt, lt_idx = lt_to_leg\n",
    "\n",
    "leg_align = actor_align[\"legislator\"]\n",
    "leg_topic_prob = torch.zeros(\n",
    "    data['legislator_term'].num_nodes, K_TOPICS, dtype=FLOAT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_cols(K):\n",
    "    return [f\"topic_{k}\" for k in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def legislator_term_topic_df(id_name_map):\n",
    "    K = actor_align[\"legislator\"].size(1)\n",
    "    leg_infl = actor_influence[\"legislator\"]\n",
    "\n",
    "    infl_term = torch.zeros(data['legislator_term'].num_nodes, dtype=FLOAT)\n",
    "    infl_term.index_copy_(0, lt_idx, leg_infl[leg_of_lt])\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        leg_topic_prob.numpy(),\n",
    "        columns=[f\"topic_{k}\" for k in range(K)]\n",
    "    )\n",
    "    df[\"influence\"] = infl_term.numpy()\n",
    "    df[\"legislator_term\"] = range(len(df))\n",
    "    df[\"name\"] = df[\"legislator_term\"].map(id_name_map)\n",
    "    return df, infl_term.numpy()\n",
    "\n",
    "leg_topics_df, infl_term = legislator_term_topic_df(node_id_map[\"legislator_term\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_topic_df(nt):\n",
    "    prob = actor_align[nt]\n",
    "    infl = actor_influence[nt]\n",
    "    df = pd.DataFrame(prob.numpy(), columns=topic_cols(K_TOPICS))\n",
    "    df[nt] = np.arange(len(df))\n",
    "    df[\"name\"] = data[nt].n_id\n",
    "    df[\"influence\"] = infl.numpy()\n",
    "    return df\n",
    "\n",
    "donor_df = actor_topic_df(\"donor\")\n",
    "lobby_df = actor_topic_df(\"lobby_firm\")\n",
    "comm_df = actor_topic_df(\"committee\")\n",
    "leg_df = actor_topic_df(\"legislator\")\n",
    "lt_df = pd.DataFrame(leg_topic_prob.numpy(), columns=topic_cols(K_TOPICS))\n",
    "lt_df[\"influence\"] = infl_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LEG = data['legislator'].num_nodes\n",
    "N_LT = data['legislator_term'].num_nodes\n",
    "N_BILL = data['bill'].num_nodes\n",
    "N_COMM = data['committee'].num_nodes\n",
    "N_LOB = data['lobby_firm'].num_nodes\n",
    "N_DON = data['donor'].num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_don, _ = data.edge_index_dict[('donor','donated_to','legislator_term')]\n",
    "don_out = torch.zeros(N_DON)\n",
    "don_out.index_add_(0, src_don,\n",
    "                   data[('donor','donated_to','legislator_term')].edge_attr[:,0].abs())\n",
    "donor_df[\"total_spent\"] = don_out.numpy()\n",
    "\n",
    "src_lo1, _ = data.edge_index_dict[('lobby_firm','lobbied','legislator_term')]\n",
    "src_lo2, _ = data.edge_index_dict[('lobby_firm','lobbied','committee')]\n",
    "\n",
    "lob_out = torch.zeros(N_LOB)\n",
    "for src_lo, et in [(src_lo1, ('lobby_firm','lobbied','legislator_term')),\n",
    "                   (src_lo2, ('lobby_firm','lobbied','committee'))]:\n",
    "    lob_out.index_add_(0, src_lo,\n",
    "        data[et].edge_attr[:,0].abs())\n",
    "lobby_df[\"total_spent\"] = lob_out.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "don_src, don_dst = data.edge_index_dict[('donor','donated_to','legislator_term')]\n",
    "lob_src1, lob_dst1 = data.edge_index_dict[('lobby_firm','lobbied','legislator_term')]\n",
    "\n",
    "lt_in = torch.zeros(N_LT)\n",
    "lt_in.index_add_(0, don_dst,\n",
    "    data[('donor','donated_to','legislator_term')].edge_attr[:,0].abs())\n",
    "donations = lt_in.clone()\n",
    "lt_in.index_add_(0, lob_dst1,\n",
    "    data[('lobby_firm','lobbied','legislator_term')].edge_attr[:,0].abs())\n",
    "\n",
    "leg_in = torch.zeros(N_LEG)\n",
    "leg_in.index_add_(0, leg_of_lt, lt_in[lt_idx])\n",
    "don_in = torch.zeros(N_LEG)\n",
    "don_in.index_add_(0, leg_of_lt, donations[lt_idx])\n",
    "leg_df[\"total_received\"] = leg_in.numpy()\n",
    "leg_df[\"total_donations\"] = don_in.numpy()\n",
    "leg_df['total_lobbying'] = leg_df['total_received'] - leg_df['total_donations']\n",
    "\n",
    "_, com_dst = data.edge_index_dict[('lobby_firm','lobbied','committee')]\n",
    "com_in = torch.zeros(N_COMM)\n",
    "com_in.index_add_(0, com_dst,\n",
    "    data[('lobby_firm','lobbied','committee')].edge_attr[:,0].abs())\n",
    "comm_df[\"total_received\"] = com_in.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_year(ts_tensor):\n",
    "    return pd.to_datetime(ts_tensor.cpu().numpy(), unit=\"s\").year.astype(np.int16)\n",
    "\n",
    "def money_by_topic(edge_key, src_df):\n",
    "    src_idx, dst_idx = data.edge_index_dict[edge_key]\n",
    "    dollars  = data[edge_key].edge_attr[:,0].abs().cpu()\n",
    "\n",
    "    prob_src = torch.from_numpy(src_df[topic_cols(K_TOPICS)].to_numpy())\n",
    "    infl_src = torch.from_numpy(src_df[\"influence\"].to_numpy())\n",
    "\n",
    "    w = prob_src[src_idx] * infl_src[src_idx,None]\n",
    "    topic_dollars = torch.zeros(K_TOPICS)\n",
    "    topic_dollars.index_add_(0, torch.arange(K_TOPICS).repeat(len(w)),\n",
    "                             (w*dollars[:,None]).flatten())\n",
    "    return topic_dollars.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = pd.read_csv('../../../sampled_labels - sampled_labels.csv')\n",
    "big_labels = {row['cluster']: row['Label'] for _, row in sl.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic_0',\n",
       " 'topic_1',\n",
       " 'topic_2',\n",
       " 'topic_3',\n",
       " 'topic_4',\n",
       " 'topic_5',\n",
       " 'topic_6',\n",
       " 'topic_7',\n",
       " 'topic_8',\n",
       " 'topic_9',\n",
       " 'topic_10',\n",
       " 'topic_11',\n",
       " 'topic_12',\n",
       " 'topic_13',\n",
       " 'topic_14',\n",
       " 'topic_15',\n",
       " 'topic_16',\n",
       " 'topic_17',\n",
       " 'topic_18',\n",
       " 'topic_19',\n",
       " 'topic_20',\n",
       " 'topic_21',\n",
       " 'topic_22',\n",
       " 'topic_23',\n",
       " 'topic_24',\n",
       " 'topic_25',\n",
       " 'topic_26',\n",
       " 'topic_27',\n",
       " 'topic_28',\n",
       " 'topic_29',\n",
       " 'topic_30',\n",
       " 'topic_31',\n",
       " 'topic_32',\n",
       " 'topic_33',\n",
       " 'topic_34',\n",
       " 'topic_35',\n",
       " 'topic_36',\n",
       " 'topic_37',\n",
       " 'topic_38',\n",
       " 'topic_39',\n",
       " 'topic_40',\n",
       " 'topic_41',\n",
       " 'topic_42',\n",
       " 'topic_43',\n",
       " 'topic_44',\n",
       " 'topic_45',\n",
       " 'topic_46',\n",
       " 'topic_47',\n",
       " 'topic_48',\n",
       " 'topic_49',\n",
       " 'topic_50',\n",
       " 'topic_51',\n",
       " 'topic_52',\n",
       " 'topic_53',\n",
       " 'topic_54',\n",
       " 'topic_55',\n",
       " 'topic_56',\n",
       " 'topic_57',\n",
       " 'topic_58',\n",
       " 'topic_59',\n",
       " 'topic_60',\n",
       " 'topic_61',\n",
       " 'topic_62',\n",
       " 'topic_63',\n",
       " 'topic_64',\n",
       " 'topic_65',\n",
       " 'topic_66',\n",
       " 'topic_67',\n",
       " 'topic_68',\n",
       " 'topic_69',\n",
       " 'topic_70',\n",
       " 'topic_71',\n",
       " 'topic_72',\n",
       " 'topic_73',\n",
       " 'topic_74',\n",
       " 'topic_75',\n",
       " 'topic_76',\n",
       " 'topic_77',\n",
       " 'topic_78',\n",
       " 'topic_79',\n",
       " 'topic_80',\n",
       " 'topic_81',\n",
       " 'topic_82',\n",
       " 'topic_83',\n",
       " 'topic_84',\n",
       " 'topic_85',\n",
       " 'topic_86',\n",
       " 'topic_87',\n",
       " 'topic_88',\n",
       " 'topic_89',\n",
       " 'topic_90',\n",
       " 'topic_91',\n",
       " 'topic_92',\n",
       " 'topic_93',\n",
       " 'topic_94',\n",
       " 'topic_95',\n",
       " 'topic_96',\n",
       " 'topic_97',\n",
       " 'topic_98',\n",
       " 'topic_99',\n",
       " 'topic_100',\n",
       " 'topic_101',\n",
       " 'topic_102',\n",
       " 'topic_103',\n",
       " 'topic_104',\n",
       " 'topic_105',\n",
       " 'topic_106',\n",
       " 'topic_107',\n",
       " 'topic_108',\n",
       " 'topic_109',\n",
       " 'topic_110',\n",
       " 'topic_111',\n",
       " 'topic_112',\n",
       " 'topic_113',\n",
       " 'topic_114',\n",
       " 'topic_115',\n",
       " 'topic_116',\n",
       " 'topic_117',\n",
       " 'topic_118',\n",
       " 'topic_119',\n",
       " 'topic_120',\n",
       " 'topic_121',\n",
       " 'topic_122',\n",
       " 'topic_123',\n",
       " 'topic_124',\n",
       " 'topic_125']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_cols(K_TOPICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "125",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33mtop_topics\u001b[39m\u001b[33m'\u001b[39m] = topics\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43madd_top_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdonor_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36madd_top_n\u001b[39m\u001b[34m(df, n)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_top_n\u001b[39m(df, n=\u001b[32m5\u001b[39m):\n\u001b[32m      2\u001b[39m     top = (\n\u001b[32m      3\u001b[39m         df[topic_cols(K_TOPICS)]\n\u001b[32m      4\u001b[39m           .apply(\u001b[38;5;28;01mlambda\u001b[39;00m r: r.nlargest(n).index.str[\u001b[32m6\u001b[39m:], axis=\u001b[32m1\u001b[39m)\n\u001b[32m      5\u001b[39m     )\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     topics = \u001b[43mtop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mbig_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33mtop_topics\u001b[39m\u001b[33m'\u001b[39m] = topics\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36madd_top_n.<locals>.<lambda>\u001b[39m\u001b[34m(r)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_top_n\u001b[39m(df, n=\u001b[32m5\u001b[39m):\n\u001b[32m      2\u001b[39m     top = (\n\u001b[32m      3\u001b[39m         df[topic_cols(K_TOPICS)]\n\u001b[32m      4\u001b[39m           .apply(\u001b[38;5;28;01mlambda\u001b[39;00m r: r.nlargest(n).index.str[\u001b[32m6\u001b[39m:], axis=\u001b[32m1\u001b[39m)\n\u001b[32m      5\u001b[39m     )\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     topics = top.apply(\u001b[38;5;28;01mlambda\u001b[39;00m r: [\u001b[43mbig_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m r])\n\u001b[32m      7\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33mtop_topics\u001b[39m\u001b[33m'\u001b[39m] = topics\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[31mKeyError\u001b[39m: 125"
     ]
    }
   ],
   "source": [
    "def add_top_n(df, n=5):\n",
    "    top = (\n",
    "        df[topic_cols(K_TOPICS)]\n",
    "          .apply(lambda r: r.nlargest(n).index.str[6:], axis=1)\n",
    "    )\n",
    "    topics = top.apply(lambda r: [big_labels[int(t)] for t in r])\n",
    "    df['top_topics'] = topics\n",
    "    return df\n",
    "add_top_n(donor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for _df in (donor_df, lobby_df, comm_df, leg_df):\n",
    "    add_top_n(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "legislators = pickle.load(open('../../../legislators.pkl', 'rb'))\n",
    "\n",
    "leg_ids = {v: k for k, v in node_id_map['legislator_term'].items()}\n",
    "\n",
    "def leg_term_to_name(leg_term_id):\n",
    "    if isinstance(leg_term_id, str):\n",
    "        num = int(leg_term_id.split('_')[0])\n",
    "        return legislators.get(num, None)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def leg_term_to_term(leg_term_id):\n",
    "    if isinstance(leg_term_id, str):\n",
    "        a = leg_term_id.split('_')[1]\n",
    "        return int(a.split('-')[0]) if a else None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "leg_df['legislator'] = leg_df['name'].astype(int).map(leg_ids).apply(leg_term_to_name)\n",
    "leg_df['term'] = leg_df['name'].astype(int).map(leg_ids).apply(leg_term_to_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians = pd.read_csv('../../../ca_leg/legislation_data/politicians.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix = politicians.loc[politicians['District No.'].isna(), ['full_name', 'Term']].drop_duplicates()\n",
    "fix['District No.'] = [51, 58, 8, 58, 58, 29, 39, 48, 43, 48, 10, 43, 48, 48, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in fix.iterrows():\n",
    "    politicians.loc[(politicians['full_name'] == row['full_name']) & (politicians['Term'] == row['Term']), 'District No.'] = row['District No.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol = politicians[['District No.', 'Term', 'full_name', 'chamber', 'Party']].drop_duplicates()\n",
    "pol['term'] = pol['Term'].apply(lambda x: x.split('-')[0]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfund = pol.merge(leg_df, left_on=['full_name', 'term'], right_on=['legislator', 'term'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import tempfile, zipfile, pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_zip(zip_path, crs=3857):\n",
    "    tmp = tempfile.TemporaryDirectory()\n",
    "    with zipfile.ZipFile(zip_path) as zf:\n",
    "        zf.extractall(tmp.name)\n",
    "    shp = next(pathlib.Path(tmp.name).rglob(\"*.shp\"))\n",
    "    gdf = gpd.read_file(shp).set_crs(epsg=crs)\n",
    "    gdf = gdf.to_crs(epsg=3857)\n",
    "    return gdf, tmp\n",
    "\n",
    "def district_cycle(year):\n",
    "    if year <= 2012: return \"2001\"\n",
    "    if year <= 2022: return \"2011\"\n",
    "    return \"current\"\n",
    "\n",
    "counties_gdf, _ = read_zip('../data/ca_counties.zip')\n",
    "counties_gdf = counties_gdf[['COUNTYFP', 'NAMELSAD', 'geometry']]\n",
    "counties_gdf['county_area'] = counties_gdf.geometry.area\n",
    "counties_gdf['county_id'] = counties_gdf['COUNTYFP'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('../data')\n",
    "\n",
    "asm11_zip = data_dir / '2011_assembly_state_shp.zip'\n",
    "sen11_zip = data_dir / '2011_senate_state_shp.zip'\n",
    "asmcur_zip = data_dir / '2021_AD_Final_shp.zip'\n",
    "sencur_zip = data_dir / '2021_SD_Final_shp.zip'\n",
    "\n",
    "dist_info = [\n",
    "    (asm11_zip, \"assembly\", \"2011\", 4019),\n",
    "    (sen11_zip, \"senate\",   \"2011\", 4019),\n",
    "    (asmcur_zip, \"assembly\",\"current\", 4269),\n",
    "    (sencur_zip, \"senate\",  \"current\", 4269)\n",
    "]\n",
    "\n",
    "weight_records = []\n",
    "tmps = []\n",
    "for zp, house, cycle, crs in dist_info:\n",
    "    gdf, tmp = read_zip(zp, crs)\n",
    "    tmps.append(tmp)\n",
    "    gdf = gdf.rename(columns={gdf.columns[0]: \"district_id\"})[[\"district_id\", \"geometry\"]]\n",
    "    gdf[\"house\"] = house\n",
    "    gdf[\"cycle\"] = cycle\n",
    "    gdf[\"dist_area\"] = gdf.geometry.area\n",
    "\n",
    "    inter = gpd.overlay(gdf, counties_gdf, how=\"intersection\")\n",
    "    inter[\"fragment_area\"] = inter.geometry.area\n",
    "\n",
    "    weight_records.append(\n",
    "        inter[[\"house\", \"cycle\", \"district_id\", \"county_id\", \"fragment_area\", 'county_area', 'dist_area']].reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "weights = pd.concat(weight_records, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights['weight'] = weights['fragment_area'] / weights['county_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfund['District No.'] = lfund['District No.'].astype(str).apply(lambda x: re.sub(r'\\s', '', x)).astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltopic_ = lfund.groupby(['District No.', 'Term', 'chamber'])[[f'topic_{i}' for i in range(K_TOPICS)]].sum().reset_index()\n",
    "ltopic_['cycle'] = ltopic_['Term'].apply(lambda x: '2011' if int(x.split('-')[0]) <= 2012 else 'current')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfund_ = lfund.groupby(['Term', 'District No.', 'chamber']).agg({\n",
    "    'total_donations': 'sum',\n",
    "    'total_lobbying': 'sum',\n",
    "    'total_received': 'sum',\n",
    "}).reset_index()\n",
    "lfund_['cycle'] = lfund_['Term'].apply(lambda x: '2011' if int(x.split('-')[0]) <= 2012 else 'current')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_funds = lfund_.merge(weights, left_on=['cycle', 'District No.', 'chamber'], right_on=['cycle', 'district_id', 'house'], how='left')\n",
    "\n",
    "reg_funds['total_donations'] *= reg_funds['weight']\n",
    "reg_funds['total_lobbying'] *= reg_funds['weight']\n",
    "reg_funds['total_received'] *= reg_funds['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_funds_ = reg_funds.groupby(['county_id', 'house']).agg({\n",
    "    'total_donations': 'sum',\n",
    "    'total_lobbying': 'sum',\n",
    "    'total_received': 'sum'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_funds_.to_csv(OUT_PATH / 'ca_legislator_funding.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_topics = ltopic_.merge(weights, left_on=['cycle', 'District No.', 'chamber'], right_on=['cycle', 'district_id', 'house'], how='right')\n",
    "\n",
    "for i in range(K_TOPICS):\n",
    "    reg_topics[f'topic_{i}'] *= reg_topics['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_topics_ = reg_topics.groupby(['house', 'Term', 'county_id'])[topic_cols(K_TOPICS)].sum().reset_index().merge(counties_gdf[['county_id', 'NAMELSAD']], on='county_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_topics_ = add_top_n(reg_topics_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Voting and Elections',\n",
       " 1: 'Health Care',\n",
       " 2: 'Epidemiology and Medical Research',\n",
       " 3: 'Grants for Public Resources',\n",
       " 4: 'Public Transportation',\n",
       " 5: 'Sales and Use Taxes',\n",
       " 6: 'Civil Rights',\n",
       " 7: 'In-Home Supportive Services',\n",
       " 8: 'Sex Offenders and Sexual Assault',\n",
       " 9: 'Education',\n",
       " 10: 'Marine Resources',\n",
       " 11: 'Water Resources',\n",
       " 12: 'Investigative Consumer Reporting Agencies',\n",
       " 13: 'State, Public, and Personal Records',\n",
       " 14: 'Peace Officers',\n",
       " 15: 'Agriculture',\n",
       " 16: 'Memorial Highways',\n",
       " 17: 'Military',\n",
       " 18: 'Consumer Affairs',\n",
       " 19: 'Gambling and the State Lottery',\n",
       " 20: 'Pesticides and Pest Control',\n",
       " 21: 'Mental Health',\n",
       " 22: 'Income Taxes',\n",
       " 23: 'Controlled Substances and Substance Abuse',\n",
       " 24: 'Economic Development',\n",
       " 25: 'Student Health',\n",
       " 26: 'Housing',\n",
       " 27: 'Real Estate',\n",
       " 28: 'Monuments and Memorials',\n",
       " 29: \"Public Employees' Retirement\",\n",
       " 30: 'Fire Prevention and Safety',\n",
       " 31: 'Regional Agencies',\n",
       " 32: 'Emergency Services and Preparedness',\n",
       " 33: 'Tribal Affairs',\n",
       " 34: 'Holidays',\n",
       " 35: 'Judicial Procedure',\n",
       " 36: 'Residential Care Facilities and Protections for the Elderly',\n",
       " 37: 'Alcoholic Beverages',\n",
       " 38: 'Public Safety',\n",
       " 39: 'State and Local Government',\n",
       " 40: 'Small and Disadvantaged Business Enterprises',\n",
       " 41: 'Bridges and Tolls',\n",
       " 42: 'Harbors and Ports',\n",
       " 43: 'Liability',\n",
       " 44: 'Forestry',\n",
       " 45: 'Event Anniversaries',\n",
       " 46: 'Child Development and Welfare',\n",
       " 47: 'Coastal Resources',\n",
       " 48: 'Public Utilities',\n",
       " 49: 'Healing Arts',\n",
       " 50: 'Postsecondary Professional Education',\n",
       " 51: 'School Athletics and Physical Education',\n",
       " 52: 'Miscellaneous',\n",
       " 53: 'Cause Awareness',\n",
       " 54: 'Criminal Procedure',\n",
       " 55: 'Immigration, Refugees, and Human Trafficking',\n",
       " 56: 'State Boards',\n",
       " 57: 'Budgeting',\n",
       " 58: 'Insurance',\n",
       " 59: 'Energy Resources',\n",
       " 60: 'Primary Education',\n",
       " 61: 'Child Nutrition',\n",
       " 62: 'Air Pollution',\n",
       " 63: 'Primary Education',\n",
       " 64: 'Tobacco',\n",
       " 65: 'Correctional Facilities',\n",
       " 66: 'State Funds and Trusts',\n",
       " 67: 'Personal Information and Privacy',\n",
       " 68: 'Electricity',\n",
       " 69: 'Animal Welfare',\n",
       " 70: 'Pharmacology',\n",
       " 71: 'History and Special Groups',\n",
       " 72: 'Redevelopment',\n",
       " 73: 'Public Postsecondary Education',\n",
       " 74: 'Environmental Quality',\n",
       " 75: 'Driving and Vehicles',\n",
       " 76: 'Civil Actions',\n",
       " 77: 'Contracts and Construction Standards',\n",
       " 78: 'Clinical Professions',\n",
       " 79: 'Property RIghts',\n",
       " 80: 'Global Warming and Greenhouse Gas',\n",
       " 81: 'Local Public Employee Organizations',\n",
       " 82: 'Extraordinary Sessions',\n",
       " 83: 'Hazardous Waste and Toxic Substances',\n",
       " 84: 'Mobilehomes',\n",
       " 85: 'Miscellaneous',\n",
       " 86: 'Arbitration and Conflicts of Interest',\n",
       " 87: 'Fishing and Marine Wildlife',\n",
       " 88: 'Foster Care',\n",
       " 89: 'Land Use and Conservation',\n",
       " 90: \"Veterans' Affairs\",\n",
       " 91: \"Public Employees' Benefits and Compensation\",\n",
       " 92: 'Food Labeling and Safety',\n",
       " 93: 'Unemployment and Spousal Support',\n",
       " 94: 'Protections for Children',\n",
       " 95: 'Violent Crimes and Gun Safety',\n",
       " 96: 'Property Tax',\n",
       " 97: 'State Agencies and Commissions',\n",
       " 98: 'Health Coverage',\n",
       " 99: 'Public Districts',\n",
       " 100: 'Banking Consumer Protections',\n",
       " 101: 'Developmental Services',\n",
       " 102: 'Teachers',\n",
       " 103: 'Cannabis',\n",
       " 104: 'Waste Management and Recycling',\n",
       " 105: 'Wildlife Conservation',\n",
       " 106: 'State and Regional Parks',\n",
       " 107: 'Licensing',\n",
       " 108: 'Fines, Penalties, and Sanctions',\n",
       " 109: 'Data Privacy and Cybersecurity',\n",
       " 110: 'Professional Training and Licensure',\n",
       " 111: 'Rights and Protections for Persons with Disabilities'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_topics_[['house', 'Term', 'county_id', 'NAMELSAD', 'top_topics']].to_csv(\n",
    "    OUT_PATH / 'ca_legislator_topics.csv', index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ei = data[(\"legislator_term\",\"wrote\",\"bill_version\")].edge_index.numpy()\n",
    "ea = data[(\"legislator_term\",\"wrote\",\"bill_version\")].edge_attr.numpy()\n",
    "author_edge = pd.DataFrame({\"legterm_id\": ei[0], \"bill_id\": ei[1], \"type\": ea[:,0]})\n",
    "author_edge['date'] = data[\"bill_version\"].time.numpy()[author_edge.bill_id]\n",
    "author_edge.loc[author_edge.date == 0, 'date'] = datetime.datetime(2000, 6, 15).timestamp()\n",
    "author_edge['date'] = pd.to_datetime(author_edge['date'], unit='s')\n",
    "\n",
    "eib = data[('bill_version','is_version', 'bill')].edge_index.numpy()\n",
    "eib = pd.DataFrame({\"src\": eib[0], \"dst\": eib[1], 'outcome': data['bill'].y[eib[1]]})\n",
    "eib['src'] = eib['src'].astype(int)\n",
    "eib['dst'] = eib['dst'].astype(int)\n",
    "author_edge['bill_id'] = author_edge['bill_id'].astype(int)\n",
    "\n",
    "author_edge = author_edge.merge(eib, left_on='bill_id', right_on='src', how='inner')\n",
    "author_edge['outcome'] = (author_edge['outcome'] == 1).astype(int)\n",
    "author_levels = {1: 'COAUTHOR', 2: 'PRINCIPAL_COAUTHOR', 3: 'LEAD_AUTHOR'}\n",
    "author_edge['author_type'] = author_edge['type'].map(author_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "ve = data[('bill_version', 'rev_voted_on', 'legislator_term')].edge_index.numpy()\n",
    "va = data[('bill_version', 'rev_voted_on', 'legislator_term')].edge_attr.numpy()\n",
    "vote_edge = pd.DataFrame({'bill_version': ve[0], 'legislator_term': ve[1], 'vote_signal': va[:, 0]})\n",
    "vote_edge = vote_edge.merge(eib, left_on='bill_version', right_on='src', how='left').merge(bv_df, on='bill_version', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_edge['full_name'] = vote_edge['legislator_term'].map(leg_ids).apply(leg_term_to_name)\n",
    "vote_edge['term'] = vote_edge['legislator_term'].map(leg_ids).apply(leg_term_to_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = vote_edge.groupby('bill_id').agg({'outcome': 'max', 'vote_signal': lambda x: (x > 0).sum() / len(x)})\n",
    "signals.loc[(signals['outcome'] == 0.0) & (signals['vote_signal'] == 1.0), 'vote_signal'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = author_edge.merge(bv_df, left_on='bill_id', right_on='bill_version', how='left').groupby('legterm_id').agg({\n",
    "    'outcome': 'mean',\n",
    "    'author_type': lambda x: sum(x == 'LEAD_AUTHOR'),\n",
    "    'bill_version': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "a3['full_name'] = a3['legterm_id'].map(leg_ids).apply(leg_term_to_name)\n",
    "a3['term'] = a3['legterm_id'].map(leg_ids).apply(leg_term_to_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4 = a3.merge(lfund, on=['full_name', 'term'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4[['outcome', 'author_type', 'bill_version', 'top_topics',  'full_name', 'term', 'total_donations', 'total_lobbying', 'total_received', 'Party', 'chamber']].copy().to_csv(OUT_PATH / 'legislator_terms.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "don = donor_df[['name', 'influence', 'total_spent', 'top_topics']].copy()\n",
    "don['type'] = 'donor'\n",
    "lob = lobby_df[['name', 'influence', 'total_spent', 'top_topics']].copy()\n",
    "lob['type'] = 'lobby_firm'\n",
    "donor_lobby = pd.concat([don, lob], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_lobby.to_csv(OUT_PATH / 'donor_lobby_topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_edge['bill'] = data['bill'].n_id[author_edge['dst'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = author_edge.groupby('bill').agg({'date': 'max'}).reset_index().merge(author_edge, on=['bill', 'date'], how='inner').groupby('bill').agg({\n",
    "    'legterm_id': lambda x: ', '.join(x.astype(str).unique())}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terms_to_names(terms):\n",
    "    term_names = []\n",
    "    for t in terms.split(', '):\n",
    "        l = leg_ids.get(int(t.strip()), None)\n",
    "        if l is not None:\n",
    "            term_names.append(leg_term_to_name(l))\n",
    "    return ', '.join([n for n in term_names if n is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors['authors'] = authors['legterm_id'].apply(terms_to_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = bill_df.merge(authors, left_on='bill_id', right_on='bill', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "b['longevity'] = b['longevity'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi = b.merge(bv_df.groupby('bill_id')['bill_version_id'].nunique().reset_index(), on='bill_id', how='left').merge(bill_dates[['bill_id', 'First_action']], on='bill_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi['term'] = bi['bill_id'].apply(lambda x: x[:4]).astype(int)\n",
    "bi['First_action'] = bi['First_action'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "bil = bi.merge(signals, on='bill_id', how='left')\n",
    "bil['vote_signal'] = bil['vote_signal'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.write_table(pa.Table.from_pandas(bil), OUT_PATH / 'bills.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = bi.groupby(['topic_cluster', 'term']).agg({\n",
    "    'outcome': 'mean',\n",
    "    'controversy': 'mean',\n",
    "    'longevity': 'mean',\n",
    "    'bill_id': 'nunique',\n",
    "    'bill_version_id': 'mean'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lfund.groupby(['chamber', 'term', 'Party'])[topic_cols(K_TOPICS)].mean().reset_index()\n",
    "f = add_top_n(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ = f.pivot_table(\n",
    "    index='term',\n",
    "    columns='Party',\n",
    "    values=topic_cols(K_TOPICS),\n",
    "    aggfunc='mean'\n",
    ")\n",
    "f_.columns = [f\"{col[0]}_{col[1]}\" for col in f_.columns]\n",
    "\n",
    "f_ = f_[[c for c in f_.columns if not c.endswith('_I')]]\n",
    "f_ = f_.fillna(0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partisan_split(row):\n",
    "    splits = {}\n",
    "    for t in topic_cols(K_TOPICS):\n",
    "        d = row[f\"{t}_D\"]\n",
    "        r = row[f\"{t}_R\"]\n",
    "        splits[t] = d - r\n",
    "    return splits\n",
    "\n",
    "f_[[f\"{t}_split\" for t in topic_cols(K_TOPICS)]] = f_.apply(partisan_split, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = f_.melt(\n",
    "    id_vars=['term'],\n",
    "    value_vars=[f\"{t}_split\" for t in topic_cols(K_TOPICS)],\n",
    "    var_name='topic',\n",
    "    value_name='partisan_split'\n",
    ")\n",
    "fg['topic_cluster'] = fg['topic'].apply(lambda x: re.search(r'_(\\d+)', x).group(1) if '_' in x else x).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ = t.merge(fg[['term', 'topic_cluster', 'partisan_split']], on=['term', 'topic_cluster'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_.to_csv(OUT_PATH / 'topics_agg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "committee_ids = pickle.load(open('../../../committees.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_df['name'] = comm_df['committee'].map(committee_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
