{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "56de9958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import re, json, ast, pathlib, zipfile, tempfile, datetime as _dt, warnings, torch, os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, deque\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8d001b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_votes = pd.read_csv('ca_leg/legislation_data/bill_summary_vote_tbl.csv')\n",
    "bill_history = pd.read_csv('ca_leg/legislation_data/bill_history_tbl.csv', dtype={'action_status': str, 'primary_location': str, 'secondary_location': str, 'end_status': str})\n",
    "authors = pd.read_csv('ca_leg/legislation_data/authors.csv')\n",
    "history = pd.read_csv('ca_leg/legislation_data/history.csv')\n",
    "versions = pd.read_csv('ca_leg/legislation_data/bill_versions.csv')\n",
    "bill_votes = pd.read_csv('ca_leg/legislation_data/bill_detail_vote_tbl.csv', parse_dates=['session_date'])\n",
    "bill_summary = pd.read_csv('ca_leg/legislation_data/bill_summary_vote_tbl.csv')\n",
    "bill_motions = pd.read_csv('ca_leg/legislation_data/bill_motion_tbl.csv')\n",
    "locations = pd.read_csv('ca_leg/legislation_data/committee_codes.csv')\n",
    "politicians = pd.read_csv('ca_leg/legislation_data/politicians.csv')\n",
    "lobbying = pd.read_csv('calaccess/lobbying_clean2.csv', dtype={'PAYEE_NAMS': str, 'BAKREF_TID': str})\n",
    "expend_assembly = pd.read_csv('calaccess/expend_assembly_matched.csv', dtype={'TargetPropositionName': str})\n",
    "expend_senate = pd.read_csv('calaccess/expend_senate_matched.csv', dtype={'TargetPropositionName': str})\n",
    "digests = pd.read_csv('ca_leg/legislation_data/digest.csv')\n",
    "hearings = pd.read_csv('ca_leg/legislation_data/committee_hearing_tbl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b534fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_votes['vote_date_time'] = pd.to_datetime(bill_votes['vote_date_time']).apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "bill_votes['legislator_name'] = bill_votes['legislator_name'].apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b423fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_KEYWORDS = [\"Assembly Third Reading\",\"Assembly 3rd reading\",\"senate 3rd reading\",\"Senate Third Reading\",\"Concurrence - Urgency Added\",\"Concurrence in Senate Amendments\",\"Do pass as amended, and re-refer\",\"Do pass as amended, but re-refer\",\"Do pass as amended\",\"Do pass and be re-referred\",\"Concurrence\",\"Consent Calendar\",\"Urgency Clause\",\"Special Consent\",\"Motion to Reconsider\",\"Do pass\",\"Reconsideration\",\"Committee amendments\",\"W/O REF. TO FILE\",\"Be re-referred to the Committee\",\"Lay on the Table\",\"Amend by\",\"Unfinished Business\",\"Placed on Appropriations Suspense File\"]\n",
    "\n",
    "def extract_action(motion_text):\n",
    "    if not isinstance(motion_text, str) or motion_text is None:\n",
    "        return None\n",
    "    motion = motion_text.upper()\n",
    "    action = next((act for act in ACTION_KEYWORDS if act.upper() in motion), None)\n",
    "    if action != 'Reconsideration' and 'RECONSIDER' in motion:\n",
    "        if action is not None:\n",
    "            action += ' Reconsideration'\n",
    "        else:\n",
    "            action = 'Reconsideration'\n",
    "    return action if action else None\n",
    "\n",
    "bill_motions['simplified_motion'] = bill_motions['motion_text'].apply(extract_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "68367bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_coms = {}\n",
    "for i, row in locations.iterrows():\n",
    "    if row['committee_code'].startswith('CZ'):\n",
    "        continue\n",
    "    name = row['committee_name']\n",
    "    if row['committee_code'].startswith('CS'):\n",
    "        if name.startswith('Sen.'):\n",
    "            cname = re.sub(r'Sen. ', 'senate ', name).lower()\n",
    "        elif name.startswith('Senate '):\n",
    "            cname = name.lower()\n",
    "        else:\n",
    "            cname = 'senate ' + name.lower()\n",
    "    elif row['committee_code'].startswith('CX'):\n",
    "        if name.lower().startswith('assembly'):\n",
    "            cname = name.lower()\n",
    "        else:\n",
    "            cname = 'assembly ' + name.lower()\n",
    "    if re.search(r'x\\d$', cname) is not None:\n",
    "        cname = re.sub(r'x(?=\\d$)', 'no. ', cname)\n",
    "    clean_coms[row['committee_code']] = cname\n",
    "\n",
    "leg_committees = [f\"{row['chamber']} {row['committee_clean']}\".lower() for _, row in politicians[['committee_clean', 'chamber']].drop_duplicates().iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c42a3915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_committees(_names, clean_coms, threshold=92):\n",
    "    clean_c = list(clean_coms.values())\n",
    "    clean_codes = list(clean_coms.keys())\n",
    "    name_mapping = {}\n",
    "    for i, clean in enumerate(clean_c):\n",
    "        code = clean_codes[i]\n",
    "        matches = []\n",
    "        matches.append(process.extractOne(clean, _names, scorer=fuzz.token_sort_ratio, score_cutoff=threshold))\n",
    "        matches.append(process.extractOne(clean, _names, scorer=fuzz.partial_ratio, score_cutoff=threshold))\n",
    "        valid_matches = [m for m in matches if m is not None]\n",
    "        if len(valid_matches) > 0:\n",
    "            best_match = max(valid_matches, key=lambda x: x[1])\n",
    "            name_mapping[code] = best_match[0]\n",
    "        else:\n",
    "            fall_back = process.extractOne(clean, _names, scorer=fuzz.token_sort_ratio, score_cutoff=threshold - 8)\n",
    "            if fall_back is not None:\n",
    "                name_mapping[code] = fall_back[0]\n",
    "            else:\n",
    "                name_mapping[code] = None\n",
    "    return name_mapping\n",
    "\n",
    "committee_matches = match_committees(leg_committees, clean_coms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7e35bc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations['committee_clean'] = locations['committee_code'].map(committee_matches)\n",
    "locations.loc[locations['committee_name'] == 'EDUCATION X5', 'committee_clean'] = 'Budget and Fiscal Review: Education'\n",
    "locations.loc[locations['committee_code'] == 'CX12', 'committee_clean'] = 'Budget No. 1 on Health and Human Services'\n",
    "locations.loc[locations['committee_code'] == 'CS68', 'committee_clean'] = 'Budget No. 3 - Health and Human Services'\n",
    "locations.loc[locations['committee_code'] == 'CS66', 'committee_clean'] = 'Senate Veterans Affairs'\n",
    "locations.loc[locations['committee_code'] == 'CS56', 'committee_clean'] = 'Senate Public Employment and Retirement'\n",
    "locations.loc[locations['committee_code'] == 'CS62', 'committee_clean'] = 'Senate Budget and Fiscal Review'\n",
    "locations.loc[locations['committee_code'] == 'CX23', 'committee_clean'] = 'Assembly Utilities and Commerce'\n",
    "\n",
    "motion_codes = {row['motion_id']: row['simplified_motion'] for _, row in bill_motions.iterrows()}\n",
    "summary_votes['motion_text'] = summary_votes['motion_id'].map(motion_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1144bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_bill_id(id):\n",
    "    front, end = id[:4], id[4:]\n",
    "    if re.search(r'\\d{4}$', front):\n",
    "        return f\"{front}{int(front) + 1}{end}\"\n",
    "    else:\n",
    "        return id\n",
    "\n",
    "versions['ID'] = versions['bill_id'].apply(lambda x: repair_bill_id(x))\n",
    "bill_vers = versions.loc[versions['bill_id'].str.startswith('2')].copy()\n",
    "for i, row in bill_vers.iterrows():\n",
    "    tail = f\"{row['VersionNum']}{row['MeasureState']}\"\n",
    "    repaired = repair_bill_id(re.sub(tail, '', row['bill_id']))\n",
    "    end = int(repaired[-4:])\n",
    "    bill_vers.loc[i, 'bill_ID'] = f\"{repaired[:-4]}{end}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8776b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_parties = {row['full_name']: row['Party'] for _, row in politicians[['full_name', 'Party']].drop_duplicates().iterrows()}\n",
    "bill_ids = list(set(bill_votes.loc[bill_votes['bill_id'].str.startswith('2'), 'bill_id'].unique().tolist() + summary_votes.loc[summary_votes['bill_id'].str.startswith('2'), 'bill_id'].unique().tolist()))\n",
    "bill_id_codes = {row['bill_id']: row['bill_ID'] for _, row in bill_vers.drop_duplicates(subset=['bill_id', 'bill_ID']).iterrows()}\n",
    "history['bill_ID'] = history['bill_id'].map(bill_id_codes)\n",
    "history['Date'] = pd.to_datetime(history['Date'])\n",
    "\n",
    "introduction_dates = {}\n",
    "for v, group in history.loc[history['bill_ID'].isin(bill_ids)].groupby('bill_ID'):\n",
    "    introduction_dates[v] = {'Dates': group['Date'].unique().tolist(), 'Actions': group.sort_values('Date', ascending=True).drop_duplicates(subset=['Action', 'Date'])['Action'].tolist()}\n",
    "\n",
    "version_id_mapping = {i: list(group.values) for i, group in bill_vers.groupby('bill_ID')['ID']}\n",
    "version_id_mapping2 = {i: list(group.values) for i, group in bill_vers.groupby('bill_ID')['bill_id']}\n",
    "bv2b = {v: k for k, val in version_id_mapping2.items() for v in val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "787897a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_ranges = {}\n",
    "for k, v in introduction_dates.items():\n",
    "    first, last = min(v['Dates']), max(v['Dates'])\n",
    "    date_ranges[k] = {'First_action': first, 'Last_action': last}\n",
    "\n",
    "outcomes = history.loc[history['bill_ID'].notna()].sort_values('Date', ascending=False).groupby('bill_ID').first().reset_index()[['bill_ID', 'Action']]\n",
    "outcomes.loc[outcomes['Action'].isin(['CHAPTERED', 'ENROLLED', 'FILED', 'APPROVED']), 'Outcome'] = 1\n",
    "outcomes.loc[outcomes['Action'] == 'VETOED', 'Outcome'] = -1\n",
    "outcomes.loc[outcomes['Outcome'].isna(), 'Outcome'] = 0\n",
    "outcome = outcomes.set_index('bill_ID')['Outcome'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9d7d28e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_bill_ids = {}\n",
    "for i in summary_votes.loc[summary_votes['bill_id'].isin(bill_ids)].groupby(['year', 'motion_id'])['bill_id'].value_counts().index:\n",
    "    year, motion_id, bill_id = i\n",
    "    if (year, motion_id) not in vote_bill_ids.keys():\n",
    "        vote_bill_ids[(year, motion_id)] = [bill_id]\n",
    "    else:\n",
    "        vote_bill_ids[(year, motion_id)].append(bill_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5757f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_vers_dig = bill_vers.merge(digests, on='bill_id', how='inner')\n",
    "features = {row['ID']: {'digest': row['DigestText'], 'MeasureState': row['MeasureState'], 'VoteRequired': row['VoteRequired'] if row['VoteRequired'] is not None else 'No', 'VersionNum': row['VersionNum'] if row['VersionNum'] is not None else 'No', 'LocalProgram': row['LocalProgram'] if row['LocalProgram'] is not None else 'No', 'FiscalCommittee': row['FiscalCommittee'] if row['FiscalCommittee'] is not None else 'No', 'TaxLevy': row['TaxLevy'] if row['TaxLevy'] is not None else 'No', 'Urgency': row['Urgency'] if row['Urgency'] is not None else 'No'} for _, row in bill_vers_dig.iterrows()}\n",
    "\n",
    "committee_codes = {v.lower(): k for k, v in enumerate(politicians['committee_clean'].unique().tolist())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bb7f4ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_votes['chamber'] = bill_votes['location_code'].apply(lambda x: 'assembly' if x == 'AFLOOR' or str(x).startswith('CX') else 'senate' if x == 'SFLOOR' or str(x).startswith('CS') else 'full')\n",
    "bill_votes['vote_date_time'] = pd.to_datetime(bill_votes['vote_date_time'])\n",
    "bill_votes['term'] = bill_votes['vote_date_time'].apply(lambda x: f\"{x.year}-{x.year + 1}\" if x.year % 2 == 1 else f\"{x.year - 1}-{x.year}\" if x.year % 2 == 0 and x < pd.Timestamp(year=x.year, month=11, day=2) else f\"{x.year + 1}-{x.year + 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6c4dda9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_locations = authors.loc[(authors['House'] == 'UNKNOWN') & (authors['bill_id'].map(bill_id_codes).isin(bill_ids)), ['bill_id', 'Name']].drop_duplicates()\n",
    "for i, row in author_locations.iterrows():\n",
    "    if 'AB' in row['bill_id']:\n",
    "        author_locations.loc[i, 'name'] = 'Assembly ' + row['Name']\n",
    "    elif 'SB' in row['bill_id']:\n",
    "        author_locations.loc[i, 'name'] = 'Senate ' + row['Name']\n",
    "    else:\n",
    "        author_locations.loc[i, 'name'] = 'Joint ' + row['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b0efa0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_strings(source_list, target_list):\n",
    "    def preprocess_name(name):\n",
    "        if not isinstance(name, str):\n",
    "            return \"\"\n",
    "        name = name.lower()\n",
    "        name = re.sub(r'\\(.*?\\)', '', name)\n",
    "        name = re.sub(r'committee on', '', name)\n",
    "        name = re.sub(r'[^a-z\\s]', ' ', name)\n",
    "        name = re.sub(r'\\s+', ' ', name).strip()\n",
    "        return name\n",
    "    clean_source = [preprocess_name(c) for c in source_list]\n",
    "    clean_target = [preprocess_name(c) for c in target_list]\n",
    "    keywords = [\"education\",\"health\",\"finance\",\"budget\",\"transportation\",\"judiciary\",\"environment\",\"agriculture\",\"energy\",\"labor\",\"housing\",\"veterans affairs\",\"public safety\",\"insurance\",\"banking\",\"public health\",\"small business\",\"redistricting\",\"public utilities\",\"natural resources\",\"water\",\"technology\",\"communications\",\"elections\",\"government\",\"appropriations\",\"rules\",\"ethics\",\"criminal justice\",\"environmental protection\",\"college and university\",\"human services\",\"reproductive health\",\"mental health\",\"technology\",\"aggriculture\",\"urban development\",\"renewable energy\",\"gun violence\",\"commerce\",\"privacy\",\"cybersecurity\",\"infrastructure\",\"disaster preparedness\",\"prisons\",\"aging\"]\n",
    "    def get_committee_keywords(name):\n",
    "        return set(kw for kw in keywords if kw in name)\n",
    "    target_keywords = [get_committee_keywords(name) for name in clean_target]\n",
    "    def calculate_similarity(source_idx, target_idx):\n",
    "        source = clean_source[source_idx]\n",
    "        target = clean_target[target_idx]\n",
    "        if not source or not target:\n",
    "            return 0\n",
    "        if source == target:\n",
    "            return 100\n",
    "        token_sort = fuzz.token_sort_ratio(source, target)\n",
    "        token_set = fuzz.token_set_ratio(source, target)\n",
    "        partial = fuzz.partial_ratio(source, target)\n",
    "        source_kw = get_committee_keywords(source)\n",
    "        keyword_overlap = len(source_kw.intersection(target_keywords[target_idx]))\n",
    "        keyword_bonus = min(20, keyword_overlap * 10)\n",
    "        weighted_score = (token_sort * 0.3) + (token_set * 0.5) + (partial * 0.2) + keyword_bonus\n",
    "        return weighted_score\n",
    "    matches = {}\n",
    "    for i, source in enumerate(source_list):\n",
    "        scores = [calculate_similarity(i, j) for j in range(len(target_list))]\n",
    "        if not scores or max(scores) < 60:\n",
    "            matches[source] = None\n",
    "        else:\n",
    "            best_idx = np.argmax(scores)\n",
    "            confidence = scores[best_idx]\n",
    "            if confidence >= 60:\n",
    "                matches[source] = target_list[best_idx]\n",
    "            else:\n",
    "                matches[source] = None\n",
    "    return matches\n",
    "\n",
    "author_com_matches = fuzzy_strings(author_locations['name'].unique().tolist(), leg_committees)\n",
    "author_locations['name'] = author_locations['name'].map(author_com_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7148acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sponsors = authors.loc[authors['bill_id'].map(bill_id_codes).isin(bill_ids)]\n",
    "sponsors['term'] = sponsors['bill_id'].apply(lambda x: f\"{x[:4]}-{int(x[:4]) + 1}\" if int(x[:4]) % 2 == 1 else f\"{int(x[:4]) - 1}-{x[:4]}\" if int(x[:4]) % 2 == 0 and int(x[:4]) < 2009 else f\"{x[:4]}-{int(x[:4]) + 1}\")\n",
    "\n",
    "lob = lobbying.loc[lobbying['clean_beneficiary'].notna(), ['FIRM_NAME', 'EXPN_DSCR', 'clean_beneficiary', 'EXPN_DATE', 'BENE_AMT']]\n",
    "lob['EXPN_DATE'] = pd.to_datetime(lob['EXPN_DATE'])\n",
    "lob['term'] = lob['EXPN_DATE'].apply(lambda x: f\"{x.year}-{x.year + 1}\" if x.year % 2 == 1 else f\"{x.year - 1}-{x.year}\" if x.year % 2 == 0 and x < pd.Timestamp(year=x.year, month=11, day=2) else f\"{x.year}-{x.year + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8fd6877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in politicians.loc[politicians['full_name'].apply(lambda x: isinstance(x, float)), ['Term', 'Last', 'chamber']].drop_duplicates().iterrows():\n",
    "    term, last = row['Term'], row['Last']\n",
    "    a = politicians.loc[(politicians['Last'] == last) & (politicians['Term'] == term) & (politicians['full_name'].apply(lambda x: isinstance(x, str)))]\n",
    "    if len(a) > 0:\n",
    "        politicians.loc[(politicians['Term'] == term) & (politicians['Last'] == last) & (politicians['chamber'] == row['chamber']), 'full_name'] = a['full_name'].values[0]\n",
    "        continue\n",
    "    else:\n",
    "        a = politicians.loc[(politicians['Last'] == last) & (politicians['full_name'].apply(lambda x: isinstance(x, str)))]\n",
    "    if len(a) > 0:\n",
    "        politicians.loc[(politicians['Term'] == term) & (politicians['Last'] == last) & (politicians['chamber'] == row['chamber']), 'full_name'] = a['full_name'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c50d9eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_names_terms = {}\n",
    "for _, row in politicians[['full_name', 'Term', 'chamber']].drop_duplicates().iterrows():\n",
    "    if ',' in row['full_name']:\n",
    "        name = row['full_name'].split(',')[1].strip() + ' ' + row['full_name'].split(',')[0].strip()\n",
    "    else:\n",
    "        name = row['full_name']\n",
    "    pol_names_terms[(row['full_name'].lower(), row['Term'])] = {'chamber': row['chamber'], 'name': name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ce1c79a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "expend_assembly = expend_assembly.rename(columns={'term': 'Term'})\n",
    "expend_assembly['chamber'] = 'assembly'\n",
    "expend_senate = expend_senate.rename(columns={'term': 'Term'})\n",
    "expend_senate['chamber'] = 'senate'\n",
    "\n",
    "campaign_contributions = pd.concat([expend_assembly.loc[expend_assembly['matched_target_name'].notna(), ['ExpenderName', 'Amount', 'matched_target_name', 'Term', 'chamber', 'DateEnd']].drop_duplicates(subset=['ExpenderName', 'Amount', 'matched_target_name', 'DateEnd']), expend_senate.loc[expend_senate['matched_target_name'].notna(), ['ExpenderName', 'Amount', 'matched_target_name', 'Term', 'chamber', 'DateEnd']].drop_duplicates(subset=['ExpenderName', 'Amount', 'matched_target_name', 'DateEnd'])])\n",
    "campaign_contributions['DateEnd'] = pd.to_datetime(campaign_contributions['DateEnd'])\n",
    "sponsors['bill_ID'] = sponsors['bill_id'].apply(repair_bill_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f786305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = history.merge(bill_votes, left_on=['bill_ID', 'Date'], right_on=['bill_id', 'vote_date_time'], how='inner').rename(columns={'bill_id_x': 'bill_version'}).drop('bill_id_y', axis=1)\n",
    "voting['bv_id'] = voting['bill_version'].apply(repair_bill_id)\n",
    "\n",
    "voting_places = {}\n",
    "for i, row in voting.groupby(['motion_id', 'term', 'chamber', 'Date']).agg({'legislator_name': lambda x: list(x)}).iterrows():\n",
    "    motion_id, term, chamber, date = i\n",
    "    g = politicians.loc[(politicians['chamber'] == chamber) & (politicians['Term'] == term) & (politicians['Last'].isin(row['legislator_name']))]\n",
    "    voting_places[(motion_id, term, chamber, date)] = {'most_common_committee': g.groupby('committee_clean').size().sort_values(ascending=False).head(1).index[0] if len(g) > 0 else None}\n",
    "voting['voting_place'] = voting.apply(lambda row: voting_places.get((row['motion_id'], row['term'], row['chamber'], row['Date']), {}).get('most_common_committee', None), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "cebf2422",
   "metadata": {},
   "outputs": [],
   "source": [
    "hear = hearings[['bill_id', 'location_code']].merge(locations[['committee_code', 'committee_clean']], left_on='location_code', right_on='committee_code', how='left')[['bill_id', 'committee_clean']].drop_duplicates()\n",
    "hear['year'] = hear['bill_id'].apply(lambda x: int(x[:4]))\n",
    "\n",
    "positions = {p: 'Democratic Alternate' if re.search(r'Democratic\\s*Alternate', p) is not None else 'Vice Chair' if re.search(r'V\\s*i\\s*c\\s*e\\s*-*\\s*C\\s*h\\s*a\\s*i\\s*r\\s*', p) is not None else 'Co-Chair' if re.search(r'Co\\s*-\\s*Chair', p) is not None else 'Chair' if re.search(r'Cha\\s*i\\s*r', p) is not None else 'Republican Alternate' if re.search(r'\\s*Republican\\s*Alternate', p) is not None else p for p in politicians['position'].unique()}\n",
    "vnums = bill_vers.set_index('ID')['VersionNum'].to_dict()\n",
    "vid_map = {v: k for k, val in version_id_mapping.items() for v in val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "69f26aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_dt(s):\n",
    "    return pd.to_datetime(s, errors='coerce')\n",
    "\n",
    "def _canon_name(n):\n",
    "    n = re.sub(r'[^\\w\\s]', ' ', str(n)).lower()\n",
    "    n = re.sub(r'\\s+', ' ', n).strip()\n",
    "    return n\n",
    "\n",
    "def _infer_origin_chamber_from_bill_id(bill_id):\n",
    "    s = str(bill_id)\n",
    "    if 'AB' in s: return 'assembly'\n",
    "    if 'SB' in s: return 'senate'\n",
    "    return None\n",
    "\n",
    "def _term_from_date(ts):\n",
    "    if pd.isna(ts): return np.nan\n",
    "    y = ts.year\n",
    "    if y % 2 == 1:\n",
    "        return f\"{y}-{y+1}\"\n",
    "    else:\n",
    "        if ts.month < 11:\n",
    "            return f\"{y-1}-{y}\"\n",
    "        return f\"{y+1}-{y+2}\"\n",
    "\n",
    "def _tokenize(s):\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r'[^a-z0-9\\s]', ' ', s)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return [t for t in s.split(' ') if t]\n",
    "\n",
    "def _jaccard(a_set, b_set):\n",
    "    if not a_set and not b_set: return 1.0\n",
    "    i = len(a_set & b_set)\n",
    "    u = len(a_set | b_set)\n",
    "    return i / u if u else 0.0\n",
    "\n",
    "def read_zip(zip_path, crs=3857):\n",
    "    tmp = tempfile.TemporaryDirectory()\n",
    "    with zipfile.ZipFile(zip_path) as zf:\n",
    "        zf.extractall(tmp.name)\n",
    "    shp = next(pathlib.Path(tmp.name).rglob(\"*.shp\"))\n",
    "    gdf = gpd.read_file(shp).set_crs(epsg=crs)\n",
    "    gdf = gdf.to_crs(epsg=3857)\n",
    "    return gdf, tmp\n",
    "\n",
    "def district_cycle(year):\n",
    "    if year <= 2012: return \"2001\"\n",
    "    if year <= 2022: return \"2011\"\n",
    "    return \"current\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a7cbfa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = pd.read_csv('E-4_2010-2020-Internet-Version.csv', skiprows=1).iloc[:, :12]\n",
    "for c in populations.columns:\n",
    "    populations[c] = populations[c].astype(str)\n",
    "\n",
    "for c in populations.iloc[:, 1:].columns:\n",
    "    populations[c] = populations[c].apply(lambda x: re.sub(r'[^0-9]', '', x)).astype(int)\n",
    "\n",
    "pops = {}\n",
    "for _, row in populations.iterrows():\n",
    "    county = f'{row[\"COUNTY\"].strip()} County'\n",
    "    pops[county] = np.mean(row.iloc[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "75f6d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "counties_gdf, _ = read_zip('dashboard/backend/data/ca_counties.zip')\n",
    "counties_gdf = counties_gdf[['COUNTYFP', 'NAMELSAD', 'geometry']]\n",
    "counties_gdf['county_area_m2'] = counties_gdf.geometry.area\n",
    "counties_gdf['county_id'] = counties_gdf['COUNTYFP'].astype(int)\n",
    "counties_gdf['population'] = counties_gdf['NAMELSAD'].map(pops).astype('float64')\n",
    "counties_gdf['pop_density_per_m2'] = counties_gdf['population'] / counties_gdf['county_area_m2']\n",
    "data_dir = pathlib.Path('dashboard/backend/data')\n",
    "asm11_zip = data_dir / '2011_assembly_state_shp.zip'\n",
    "sen11_zip = data_dir / '2011_senate_state_shp.zip'\n",
    "asmcur_zip = data_dir / '2021_AD_Final_shp.zip'\n",
    "sencur_zip = data_dir / '2021_SD_Final_shp.zip'\n",
    "dist_info = [(asm11_zip, \"assembly\", \"2011\", 4019),(sen11_zip, \"senate\", \"2011\", 4019),(asmcur_zip, \"assembly\",\"current\", 4269),(sencur_zip, \"senate\",  \"current\", 4269)]\n",
    "weight_records = []\n",
    "tmps = []\n",
    "for zp, house, cycle, crs in dist_info:\n",
    "    gdf, tmp = read_zip(zp, crs)\n",
    "    tmps.append(tmp)\n",
    "    gdf = gdf.rename(columns={gdf.columns[0]: \"district_id\"})[[\"district_id\", \"geometry\"]]\n",
    "    gdf[\"house\"] = house\n",
    "    gdf[\"cycle\"] = cycle\n",
    "    gdf = gdf.to_crs(3857)\n",
    "    gdf['dist_area_m2'] = gdf.geometry.area\n",
    "    inter = gpd.overlay(gdf, counties_gdf, how=\"intersection\")\n",
    "    inter = inter[['house', 'cycle', 'district_id', 'COUNTYFP', 'NAMELSAD', 'geometry', 'dist_area_m2', 'county_area_m2', 'population', 'pop_density_per_m2']]\n",
    "    inter['fragment_area_m2'] = inter.geometry.area\n",
    "    inter['est_overlay_pop'] = inter['pop_density_per_m2'] * inter[\"fragment_area_m2\"]\n",
    "\n",
    "    inter[\"pop_denominator\"] = inter.groupby([\"house\",\"cycle\",\"district_id\"])[\"est_overlay_pop\"].transform(\"sum\")\n",
    "\n",
    "    inter[\"area_denominator\"] = inter.groupby([\"house\",\"cycle\",\"district_id\"])[\"fragment_area_m2\"].transform(\"sum\")\n",
    "    inter[\"w_area\"] = np.where(inter[\"area_denominator\"] > 0,\n",
    "                               inter[\"fragment_area_m2\"] / inter[\"area_denominator\"],\n",
    "                               np.nan)\n",
    "\n",
    "    inter[\"w_pop\"] = inter[\"est_overlay_pop\"] / inter[\"pop_denominator\"]\n",
    "    bad = ~np.isfinite(inter[\"w_pop\"]) | (inter[\"w_pop\"] < 0)\n",
    "    inter.loc[bad, \"w_pop\"] = inter.loc[bad, \"w_area\"]\n",
    "    inter[\"district_share_in_county_area\"] = inter[\"fragment_area_m2\"] / inter[\"dist_area_m2\"]\n",
    "    inter[\"district_share_in_county_pop\"] = inter[\"w_pop\"]\n",
    "\n",
    "    weight_records.append(\n",
    "        inter[[\n",
    "            \"house\",\"cycle\",\"district_id\",\"COUNTYFP\",\"NAMELSAD\",\n",
    "            \"fragment_area_m2\",\"dist_area_m2\",\"county_area_m2\",\n",
    "            \"population\",\"pop_density_per_m2\",\"est_overlay_pop\",\n",
    "            \"w_pop\",\"w_area\",\"district_share_in_county_pop\",\"district_share_in_county_area\"\n",
    "        ]].reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "weights = pd.concat(weight_records, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d1817d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix = politicians.loc[politicians['District No.'].isna(), ['full_name', 'Term']].drop_duplicates()\n",
    "fix['District No.'] = [78, 30, 26, 30, 30, 29, 29, 22, 29, 22, 36, 29, 22, 22, 6]\n",
    "for i, row in fix.iterrows():\n",
    "    politicians.loc[(politicians['full_name'] == row['full_name']) & (politicians['Term'] == row['Term']), 'District No.'] = row['District No.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e44d16f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lob['clean_beneficiary'] = lob['clean_beneficiary'].apply(lambda x: x.strip().lower() if isinstance(x, str) else x)\n",
    "lobb = lob.groupby(['clean_beneficiary', 'term']).agg({'BENE_AMT': 'sum'}).reset_index().rename(columns={'BENE_AMT': 'AMOUNT'})\n",
    "exp_as = expend_assembly[['Amount', 'year', 'matched_target_name']].drop_duplicates().groupby(['matched_target_name', 'year']).agg({'Amount': 'sum'}).reset_index().rename(columns={'year': 'term'})\n",
    "exp_sen = expend_senate.groupby(['matched_target_name', 'year']).agg({'Amount': 'sum'}).reset_index().rename(columns={\"year\": 'term'})\n",
    "politicians['lower'] = politicians['full_name'].str.lower()\n",
    "def name_swap(name):\n",
    "    return re.sub(r'\\,', '', name.lower()).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "924b9bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians['name2'] = politicians['full_name'].apply(name_swap)\n",
    "politicians.loc[politicians['name2'].isin([p for p in politicians['lower'].unique() if p in lobb['clean_beneficiary'].unique()]), 'name2'] = politicians.loc[politicians['name2'].isin([p for p in politicians['lower'].unique() if p in lobb['clean_beneficiary'].unique()]), 'lower']\n",
    "pl = politicians[['Party', 'District No.', 'Seat No.', 'Term', 'full_name', 'chamber', 'name2']].drop_duplicates().merge(lobb, left_on=['Term', 'name2'], right_on=['term', 'clean_beneficiary'], how='left').rename(columns={'AMOUNT': 'total_lobbying'})\n",
    "exp_as['name2'] = exp_as['matched_target_name'].apply(lambda x: re.sub(r'\\,', '', x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a98ca903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _term_year(x):\n",
    "    m = re.search(r'(\\d{4})', str(x))\n",
    "    return int(m.group(1)) if m else np.nan\n",
    "\n",
    "don_as = expend_assembly[['ExpenderName','matched_target_name','Amount','year']].dropna(subset=['ExpenderName','matched_target_name','Amount']).rename(columns={'year':'Term'})\n",
    "don_as['amount'] = pd.to_numeric(don_as['Amount'], errors='coerce').fillna(0.0)\n",
    "don_as['name2'] = don_as['matched_target_name'].astype(str).apply(name_swap)\n",
    "don_as['kind'] = 'Donations'\n",
    "\n",
    "don_sen = expend_senate[['ExpenderName','matched_target_name','Amount','year']].dropna(subset=['ExpenderName','matched_target_name','Amount']).rename(columns={'year':'Term'})\n",
    "don_sen['amount'] = pd.to_numeric(don_sen['Amount'], errors='coerce').fillna(0.0)\n",
    "don_sen['name2'] = don_sen['matched_target_name'].astype(str).apply(name_swap)\n",
    "don_sen['kind'] = 'Donations'\n",
    "\n",
    "don_all = pd.concat([don_as, don_sen], ignore_index=True)\n",
    "pol_key = politicians[['name2','Term','chamber','District No.']].drop_duplicates()\n",
    "pol_key['term'] = pol_key['Term'].apply(lambda x: x.split('-')[0]).astype(int)\n",
    "don_all['term'] = don_all['Term'].apply(lambda x: x - 1 if x % 2 == 0 else x).astype(int)\n",
    "don_m = don_all.merge(pol_key, on=['name2','term'], how='left').dropna(subset=['District No.','chamber'])\n",
    "don_m['district_id'] = don_m['District No.'].astype(float).astype(int).astype(str)\n",
    "don_m['house'] = don_m['chamber'].str.lower()\n",
    "don_m['term_year'] = don_m['term'].apply(_term_year).astype('Int64')\n",
    "don_m['name'] = don_m['ExpenderName'].astype(str)\n",
    "don_g = don_m.groupby(['house','district_id','term','term_year','kind','name'], dropna=False, as_index=False)['amount'].sum()\n",
    "don_g = don_g.rename(columns={'term':'term'})\n",
    "don_g['donations'] = don_g['amount']\n",
    "don_g['lobbying'] = 0.0\n",
    "don_g['total'] = don_g['donations']\n",
    "\n",
    "lob2 = lob[['clean_beneficiary','term','BENE_AMT']].dropna(subset=['clean_beneficiary','term','BENE_AMT']).copy()\n",
    "lob2['amount'] = pd.to_numeric(lob2['BENE_AMT'], errors='coerce').fillna(0.0)\n",
    "lob2['name2'] = lob2['clean_beneficiary'].astype(str).apply(name_swap)\n",
    "lob2['term'] = lob2['term'].apply(lambda x: int(x.split('-')[0])).astype(int)\n",
    "lob2['kind'] = 'Lobbying'\n",
    "lob_m = lob2.merge(pol_key, on=['name2','term'], how='left').dropna(subset=['District No.','chamber'])\n",
    "lob_m['district_id'] = lob_m['District No.'].apply(lambda x: re.sub(r' ', '', str(x))).astype(float).astype(int).astype(str)\n",
    "lob_m['house'] = lob_m['chamber'].str.lower()\n",
    "lob_m['term_year'] = lob_m['term'].apply(_term_year).astype('Int64')\n",
    "lob_m['name'] = 'All lobby firms'\n",
    "lob_g = lob_m.groupby(['house','district_id','term','term_year','kind','name'], dropna=False, as_index=False)['amount'].sum()\n",
    "lob_g['lobbying'] = lob_g['amount']\n",
    "lob_g['donations'] = 0.0\n",
    "lob_g['total'] = lob_g['lobbying']\n",
    "\n",
    "district_funders_time = pd.concat([don_g[['house','district_id','term','term_year','kind','name','donations','lobbying','total']], lob_g[['house','district_id','term','term_year','kind','name','donations','lobbying','total']]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "44c9c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl['term'] = pl['Term'].apply(lambda x: int(x.split('-')[-1]))\n",
    "exp_as.loc[exp_as['term'] % 2 == 1, 'term'] = exp_as.loc[exp_as['term'] % 2 == 1, 'term'] + 1\n",
    "exp_sen.loc[exp_sen['term'] % 2 == 1, 'term'] = exp_sen.loc[exp_sen['term'] % 2 == 1, 'term'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2aca3911",
   "metadata": {},
   "outputs": [],
   "source": [
    "pld = pl.merge(exp_as, on=['term', 'name2'], how='left').rename(columns={'Amount': 'total_donations_'})\n",
    "exp_sen['name2'] = exp_sen['matched_target_name'].apply(lambda x: re.sub(r'\\,', '', x.lower()))\n",
    "pldd = pld.merge(exp_sen, on=['term', 'name2'], how='left')\n",
    "pldd['total_donations_'] = pldd[['total_donations_', 'Amount']].sum(skipna=True, axis=1)\n",
    "pldd = pldd.rename(columns={'total_donations_': 'total_donations'})\n",
    "pldd['total_received'] = pldd['total_donations'] + pldd['total_lobbying']\n",
    "for c in ['total_donations', 'total_lobbying', 'total_received']:\n",
    "    pldd[c] = pldd[c].fillna(0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e994322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfund = pldd.copy()\n",
    "lfund['District No.'] = lfund['District No.'].astype(str).apply(lambda x: re.sub(r'\\s', '', x)).astype(float).astype(int)\n",
    "lfund_ = lfund.groupby(['Term', 'District No.', 'chamber']).agg({'total_donations': 'sum','total_lobbying': 'sum','total_received': 'sum'}).reset_index()\n",
    "lfund_['District No.'] = lfund_['District No.'].astype(float)\n",
    "lfund_['cycle'] = lfund_['Term'].apply(lambda x: '2011' if int(x.split('-')[0]) <= 2012 else 'current')\n",
    "reg_funds = lfund_.merge(weights, left_on=['cycle', 'District No.', 'chamber'], right_on=['cycle', 'district_id', 'house'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9bc3bb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_funds['total_donations'] *= reg_funds['w_pop']\n",
    "reg_funds['total_lobbying'] *= reg_funds['w_pop']\n",
    "reg_funds['total_received'] *= reg_funds['w_pop']\n",
    "reg_funds['county_id'] = reg_funds['COUNTYFP'].astype(int)\n",
    "reg_funds_ = reg_funds.groupby(['county_id', 'house']).agg({'total_donations': 'sum','total_lobbying': 'sum','total_received': 'sum'}).reset_index()\n",
    "co_cal = reg_funds_.merge(counties_gdf, on='county_id', how='left')\n",
    "ca_legislator_funding = gpd.GeoDataFrame(co_cal, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2ab0eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_map = {'AYE':1,'YES':1,'NOE':-1,'NO':-1}\n",
    "voting['vote_num'] = voting['vote_code'].str.upper().map(vote_map).fillna(0).astype(int)\n",
    "motion_dict = bill_motions.set_index('motion_id')['motion_text'].to_dict()\n",
    "roll_cols = ['bill_ID','bill_version','Date','motion_id','chamber','voting_place']\n",
    "roll = (voting.groupby(roll_cols, dropna=False).agg(yes=('vote_num', lambda x: int((np.array(x)>0).sum())), no=('vote_num', lambda x: int((np.array(x)<0).sum())), total=('vote_num','count')).reset_index())\n",
    "roll['pass'] = (roll['yes'] > roll['no'])\n",
    "bill_votes['vote_num'] = bill_votes['vote_code'].str.upper().map(vote_map).fillna(0).astype(int)\n",
    "bill_votes['Date'] = pd.to_datetime(bill_votes['vote_date_time']).dt.date\n",
    "roll_cols2 = ['bill_id','Date','motion_id','chamber','location_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ad9e2545",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_roll = (bill_votes.groupby(roll_cols2, dropna=False).agg(yes=('vote_num', lambda x: int((np.array(x)>0).sum())), no=('vote_num', lambda x: int((np.array(x)<0).sum())), total=('vote_num','count')).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "cdc258f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_roll = (bill_votes.groupby(roll_cols2, dropna=False).agg(yes=('vote_num', lambda x: int((np.array(x)>0).sum())), no=('vote_num', lambda x: int((np.array(x)<0).sum())), total=('vote_num','count')).reset_index())\n",
    "summary_roll['pass'] = (summary_roll['yes'] > summary_roll['no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a5c31749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/jkjxx5pj447bytbqv8pkw9nh0000gn/T/ipykernel_33174/2733824867.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stages_df = roll.groupby('bill_ID', group_keys=False).apply(_stage_timing).reset_index()\n"
     ]
    }
   ],
   "source": [
    "def _stage_timing(group):\n",
    "    g = group.sort_values('Date')\n",
    "    intro = g['Date'].min()\n",
    "    is_committee = ~(g['voting_place'].isin(['Assembly Floor','Senate Floor']))\n",
    "    comm_ref = g.loc[is_committee, 'Date'].min() if is_committee.any() else pd.NaT\n",
    "    first_read = g['Date'].min() if not g.empty else pd.NaT\n",
    "    second_read = pd.NaT\n",
    "    if pd.notna(first_read):\n",
    "        _after1 = g[(g['Date'] > first_read) & (is_committee)]\n",
    "        if not _after1.empty:\n",
    "            second_read = _after1['Date'].min()\n",
    "    third_read = pd.NaT\n",
    "    if pd.notna(second_read):\n",
    "        _after2 = g[(g['Date'] > second_read)]\n",
    "        if not _after2.empty:\n",
    "            third_read = _after2['Date'].min()\n",
    "    is_floor = summary_roll.loc[(summary_roll['bill_id'] == g['bill_ID'].iloc[0]) & (summary_roll['location_code'].isin(['AFLOOR','SFLOOR']))]\n",
    "    asm_floor_pass = pd.NaT\n",
    "    sen_floor_pass = pd.NaT\n",
    "    if not is_floor.empty:\n",
    "        asm_floor_data = is_floor[(is_floor['location_code'] == 'AFLOOR') & (is_floor['pass'])]\n",
    "        if not asm_floor_data.empty:\n",
    "            asm_floor_pass = asm_floor_data['Date'].min()\n",
    "        sen_floor_data = is_floor[(is_floor['location_code'] == 'SFLOOR') & (is_floor['pass'])]\n",
    "        if not sen_floor_data.empty:\n",
    "            sen_floor_pass = sen_floor_data['Date'].min()\n",
    "    return pd.Series({'intro': intro, 'comm_ref': comm_ref, 'first_read': first_read, 'second_read': second_read, 'third_read': third_read, 'asm_floor_pass': asm_floor_pass, 'sen_floor_pass': sen_floor_pass})\n",
    "\n",
    "stages_df = roll.groupby('bill_ID', group_keys=False).apply(_stage_timing).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "740b0fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bill_labels_updated.json', 'r') as f:\n",
    "    bill_labels = json.load(f)\n",
    "\n",
    "outcomes = (history.dropna(subset=['bill_ID']).sort_values('Date', ascending=False).groupby('bill_ID').first().reset_index()[['bill_ID','Action', 'bill_id']])\n",
    "outcomes.loc[outcomes['Action'].isin(['CHAPTERED','ENROLLED','FILED','APPROVED']),'Outcome'] = 1\n",
    "outcomes.loc[outcomes['Action'].isin(['VETOED']),'Outcome'] = -1\n",
    "outcomes.loc[outcomes['bill_id'].str.endswith('ENR'), 'Outcome'] = 1\n",
    "outcomes['Outcome'] = outcomes['Outcome'].fillna(0).astype(int)\n",
    "y_df = outcomes[['bill_ID','Outcome']].rename(columns={'Outcome':'outcome'})\n",
    "\n",
    "first_last = (history.dropna(subset=['bill_ID']).groupby('bill_ID')['Date'].agg(First_action='min', Last_action='max').reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e832b6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/jkjxx5pj447bytbqv8pkw9nh0000gn/T/ipykernel_33174/2715825013.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_digest_stats)\n"
     ]
    }
   ],
   "source": [
    "dig = digests[['bill_id','DigestText']].copy()\n",
    "dig['bill_ID'] = dig['bill_id'].map(bv2b)\n",
    "ver = versions[['bill_id','VersionNum']].copy()\n",
    "ver['bill_ID'] = ver['bill_id'].map(bv2b)\n",
    "dv = (ver.merge(dig, on=['bill_id','bill_ID'], how='inner').dropna(subset=['DigestText']))\n",
    "def _digest_stats(df):\n",
    "    df = df.sort_values('VersionNum')\n",
    "    toks = [set(_tokenize(t)) for t in df['DigestText']]\n",
    "    sims=[]\n",
    "    for i in range(1,len(toks)):\n",
    "        sims.append(_jaccard(toks[i-1], toks[i]))\n",
    "    return pd.Series({'n_versions': len(df), 'median_sim': float(np.median(sims)) if sims else np.nan})\n",
    "amendment_churn = (\n",
    "    dv.groupby('bill_ID')\n",
    "      .apply(_digest_stats)\n",
    "      .reset_index()\n",
    ")\n",
    "amendment_churn['topic'] = amendment_churn['bill_ID'].map(bill_labels)\n",
    "amendment_churn = amendment_churn.loc[amendment_churn['topic'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a129fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = voting[['legislator_name','vote_code','location_code']].copy()\n",
    "vc['is_floor'] = vc['location_code'].isin(['AFLOOR','SFLOOR'])\n",
    "vc['yes'] = vc['vote_code'].str.upper().isin(['AYE','YES']).astype(int)\n",
    "leg_comm = vc[~vc['is_floor']].groupby('legislator_name')['yes'].mean().rename('comm_yes')\n",
    "leg_floor = vc[vc['is_floor']].groupby('legislator_name')['yes'].mean().rename('floor_yes')\n",
    "committee_floor_drift = (pd.concat([leg_comm, leg_floor], axis=1).reset_index())\n",
    "committee_floor_drift['drift'] = committee_floor_drift['floor_yes'] - committee_floor_drift['comm_yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1297e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = pd.concat([\n",
    "    expend_assembly[['ExpenderName','Amount','matched_target_name','Term','DateEnd']].dropna(subset=['ExpenderName','Amount','matched_target_name']),\n",
    "    expend_senate  [['ExpenderName','Amount','matched_target_name','Term','DateEnd']].dropna(subset=['ExpenderName','Amount','matched_target_name'])\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6afbb322",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt = voting[['legislator_name','vote_code','vote_date_time']].copy()\n",
    "pol_last_names = politicians[['Last', 'full_name']].dropna().drop_duplicates()\n",
    "pol_last_names['canon'] = pol_last_names['full_name'].apply(_canon_name)\n",
    "pln_map = dict(zip(pol_last_names['Last'].str.lower(), pol_last_names['canon']))\n",
    "\n",
    "vt['canon'] = vt['legislator_name'].apply(_canon_name).map(pln_map)\n",
    "vt['term'] = vt['vote_date_time'].apply(_term_from_date)\n",
    "vt['yes'] = vt['vote_code'].str.upper().isin(['AYE','YES']).astype(int)\n",
    "leg_term_rate = vt.groupby(['canon','term'])['yes'].mean().reset_index().rename(columns={'yes':'yes_rate'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0f87b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "don = ca.copy()\n",
    "don['canon'] = don['matched_target_name'].apply(_canon_name)\n",
    "fund = (don.groupby(['canon','Term'])['Amount'].sum().reset_index().rename(columns={'Term':'term','Amount':'funding'}))\n",
    "ft = fund.merge(leg_term_rate, on=['canon','term'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "04ce9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft2 = politicians[['Party', 'name2']].drop_duplicates().merge(ft, left_on='name2', right_on='canon', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bc5b0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _quartiles(g):\n",
    "    if g.empty: return pd.Series({'yes_rate_top':np.nan,'yes_rate_bottom':np.nan,'delta':np.nan,'n_top':0,'n_bottom':0})\n",
    "    q = g['funding'].quantile([0.25,0.75]).values\n",
    "    low = g[g['funding']<=q[0]]; high = g[g['funding']>=q[1]]\n",
    "    return pd.Series({'yes_rate_top': float(high['yes_rate'].mean()) if not high.empty else np.nan, 'yes_rate_bottom': float(low['yes_rate'].mean()) if not low.empty else np.nan, 'delta': float((high['yes_rate'].mean() - low['yes_rate'].mean())) if (not high.empty and not low.empty) else np.nan, 'n_top': int(high.shape[0]), 'n_bottom': int(low.shape[0])})\n",
    "money_vote_alignment = ft.groupby('term').apply(_quartiles, include_groups=False).reset_index()\n",
    "money_vote_party_alignment = ft2.groupby(['term','Party']).apply(_quartiles, include_groups=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "aaf9a98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/jkjxx5pj447bytbqv8pkw9nh0000gn/T/ipykernel_33174/3274793717.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  signals = (roll.groupby('bill_ID').apply(lambda g: float(np.mean((g['yes']/(g['total'].replace(0, np.nan))) >= 0.5))).reset_index().rename(columns={0:'vote_signal'}))\n"
     ]
    }
   ],
   "source": [
    "bill_dates_df = first_last.copy()\n",
    "bill_dates_df['longevity_days'] = (bill_dates_df['Last_action'] - bill_dates_df['First_action']).dt.days\n",
    "signals = (roll.groupby('bill_ID').apply(lambda g: float(np.mean((g['yes']/(g['total'].replace(0, np.nan))) >= 0.5))).reset_index().rename(columns={0:'vote_signal'}))\n",
    "n_versions = (versions.assign(bill_ID=lambda d: d['bill_id'].map(bv2b)).dropna(subset=['bill_ID']).groupby('bill_ID')['VersionNum'].nunique().reset_index().rename(columns={'VersionNum':'bill_version_count'}))\n",
    "y_df['topic'] = y_df['bill_ID'].map(bill_labels)\n",
    "y_df2 = y_df.loc[y_df['topic'].notna()].copy()\n",
    "bills_table = (y_df2.merge(bill_dates_df[['bill_ID','First_action','longevity_days', 'Last_action']], on='bill_ID', how='left').merge(signals, on='bill_ID', how='left').merge(amendment_churn[['bill_ID','n_versions','median_sim']], on='bill_ID', how='left').merge(n_versions, on='bill_ID', how='left'))\n",
    "bills_table['First_action'] = pd.to_datetime(bills_table['First_action']).dt.strftime('%Y-%m-%d')\n",
    "bills_table['Last_action'] = pd.to_datetime(bills_table['Last_action']).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4a36037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = voting[['bill_ID','legislator_name','vote_code','chamber','term', 'location_code', 'Date']].copy()\n",
    "vv['last'] = vv['legislator_name'].str.lower().str.strip()\n",
    "vv['yes'] = vv['vote_code'].str.upper().isin(['AYE','YES']).astype(int)\n",
    "legislators_last_names = {}\n",
    "for _, row in politicians[['chamber', 'Last', 'Term', 'full_name']].drop_duplicates().iterrows():\n",
    "    legislators_last_names[(row['chamber'], row['Last'].lower(), row['Term'])] = row['full_name']\n",
    "def _resolve_full_name(row):\n",
    "    return legislators_last_names.get((row['chamber'], row['last'], row['term']), np.nan)\n",
    "vv['full_name'] = vv.apply(_resolve_full_name, axis=1)\n",
    "vv['party'] = vv['full_name'].map(leg_parties)\n",
    "vv['topic'] = vv['bill_ID'].map(bill_labels)\n",
    "vv = vv.loc[vv['topic'].notna()]\n",
    "vv_major = vv[vv['party'].isin(['D','R'])].copy()\n",
    "rc = (vv_major.groupby(['bill_ID','term','topic','party'])['yes'].mean().unstack('party').reset_index().rename(columns={'D':'yes_D','R':'yes_R'}))\n",
    "for c in ['yes_D','yes_R']:\n",
    "    if c not in rc.columns: rc[c] = np.nan\n",
    "rc['polarization'] = (rc['yes_D'] - rc['yes_R']).abs()\n",
    "rc['party_line_split'] = np.where(((rc['yes_D']>0.5) & (rc['yes_R']<0.5)) | ((rc['yes_D']<0.5) & (rc['yes_R']>0.5)), 1, 0)\n",
    "topic_controversy = (rc.groupby(['topic','term']).agg(n_rollcalls=('bill_ID','nunique'), mean_polarization=('polarization','mean'), median_polarization=('polarization','median'), party_line_share=('party_line_split','mean'), dem_yes_rate=('yes_D','mean'), rep_yes_rate=('yes_R','mean')).reset_index())\n",
    "rollcall_party_splits = rc[['bill_ID','term','topic','yes_D','yes_R','polarization','party_line_split']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "68730d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv2 = vv.copy()\n",
    "vv2['canon'] = vv2['legislator_name'].apply(_canon_name)\n",
    "vv2['any_vote'] = 1\n",
    "_weight_col = 'yes'\n",
    "topic_votes = (vv2.dropna(subset=['topic']).groupby(['canon','term','topic'])[_weight_col].sum().reset_index(name='topic_votes'))\n",
    "total_votes = (vv2.groupby(['canon','term'])[_weight_col].sum().reset_index(name='total_votes'))\n",
    "weights_topics = (topic_votes.merge(total_votes, on=['canon','term'], how='left'))\n",
    "weights_topics['topic_share'] = np.where(weights_topics['total_votes']>0, weights_topics['topic_votes']/weights_topics['total_votes'], 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e63a9fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (expend_assembly, expend_senate):\n",
    "    df['year'] = df['Term'].str.extract(r'^(\\d{4})').astype(int)\n",
    "    df['term'] = np.where((df['year']%2==0), df['year']-1, df['year'])\n",
    "    df['term'] = df['term'].astype(int).astype(str) + '-' + (df['term']+1).astype(int).astype(str)\n",
    "    df['canon'] = df['matched_target_name'].apply(_canon_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4b76878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "don_by_leg_term = (pd.concat([expend_assembly, expend_senate], ignore_index=True).groupby(['canon','term'])['Amount'].sum().reset_index().rename(columns={'Amount':'donations'}))\n",
    "lb2 = lobbying[['clean_beneficiary','EXPN_DATE','BENE_AMT']].dropna().copy()\n",
    "lb2['EXPN_DATE'] = pd.to_datetime(lb2['EXPN_DATE'], errors='coerce')\n",
    "lb2['term'] = lb2['EXPN_DATE'].apply(lambda x: np.nan if pd.isna(x) else (f\"{x.year-1}-{x.year}\" if (x.year%2==0 and x.month<11) else f\"{x.year+1}-{x.year+2}\" if (x.year%2==0) else f\"{x.year}-{x.year+1}\"))\n",
    "lb2['canon'] = lb2['clean_beneficiary'].apply(_canon_name)\n",
    "lob_by_leg_term = (lb2.groupby(['canon','term'])['BENE_AMT'].sum().reset_index().rename(columns={'BENE_AMT':'lobbying'}))\n",
    "fund_leg_term = (don_by_leg_term.merge(lob_by_leg_term, on=['canon','term'], how='outer').fillna({'donations':0.0,'lobbying':0.0}))\n",
    "fund_leg_term['total_received'] = fund_leg_term['donations'] + fund_leg_term['lobbying']\n",
    "weights_topics['canon'] = weights_topics['canon'].map(pln_map)\n",
    "alloc = (weights_topics.merge(fund_leg_term, on=['canon','term'], how='left').fillna({'donations':0.0,'lobbying':0.0,'total_received':0.0}))\n",
    "alloc['donations_topic'] = alloc['donations'] * alloc['topic_share']\n",
    "alloc['lobbying_topic']  = alloc['lobbying']  * alloc['topic_share']\n",
    "alloc['total_topic'] = alloc['total_received'] * alloc['topic_share']\n",
    "topic_funding_by_term = (alloc.groupby(['topic','term']).agg(total_donations=('donations_topic','sum'), total_lobbying=('lobbying_topic','sum'), total_received=('total_topic','sum')).reset_index())\n",
    "topic_funding_by_leg = (alloc.groupby(['canon','term','topic']).agg(donations=('donations_topic','sum'), lobbying=('lobbying_topic','sum'), total=('total_topic','sum')).reset_index())\n",
    "don_leg_term = (pd.concat([expend_assembly, expend_senate], ignore_index=True).assign(canon=lambda d: d['matched_target_name'].apply(_canon_name)).rename(columns={'Amount':'donation'}))\n",
    "don_alloc = (don_leg_term.merge(weights_topics[['canon','term','topic','topic_share']], on=['canon','term'], how='left').fillna({'topic_share':0.0}))\n",
    "don_alloc['donation_topic'] = don_alloc['donation'] * don_alloc['topic_share']\n",
    "donor_topic_by_term = (don_alloc.groupby(['ExpenderName','topic','term'])['donation_topic'].sum().reset_index().rename(columns={'donation_topic':'donations_allocated'}))\n",
    "for _df in (topic_funding_by_term, topic_funding_by_leg, donor_topic_by_term):\n",
    "    _df['term'] = _df['term'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a5749d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_roll_with_bill = summary_roll.copy()\n",
    "summary_roll_with_bill = summary_roll_with_bill.dropna(subset=['bill_id'])\n",
    "floor_only = summary_roll_with_bill[summary_roll_with_bill['location_code'].isin(['AFLOOR','SFLOOR'])].copy()\n",
    "floor_only['Date'] = pd.to_datetime(floor_only['Date'])\n",
    "last_floor = floor_only.sort_values('Date').groupby('bill_id').tail(1)[['bill_id','yes','no','total','Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "79423b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_floor = vv[vv['location_code'].isin(['AFLOOR','SFLOOR'])].copy().rename(columns={'bill_ID':'bill_id'})\n",
    "vv_floor['Date'] = pd.to_datetime(vv_floor['Date'])\n",
    "vv_floor = vv_floor.merge(last_floor[['bill_id','Date']], on=['bill_id','Date'], how='inner')\n",
    "vv_floor_major = vv_floor[vv_floor['party'].isin(['D','R'])]\n",
    "bill_party_rates = vv_floor_major.groupby(['bill_id','party'])['yes'].mean().unstack('party').reset_index().rename(columns={'D':'yes_D_last','R':'yes_R_last'})\n",
    "bill_party_rates[['yes_D_last','yes_R_last']] = bill_party_rates[['yes_D_last','yes_R_last']].astype(float)\n",
    "\n",
    "closest_vote = summary_roll_with_bill.copy()\n",
    "closest_vote['diff'] = (closest_vote['yes'] - closest_vote['no']).abs()\n",
    "closest_vote = closest_vote.sort_values(['bill_id','diff'])\n",
    "closest_pick = closest_vote.groupby('bill_id').head(1)[['bill_id','yes','no','total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b2045080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/jkjxx5pj447bytbqv8pkw9nh0000gn/T/ipykernel_33174/1283415855.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  mean_yes_ratio_versions = roll.groupby('bill_ID').apply(lambda g: float(np.nanmean((g['yes']/g['total'].replace(0,np.nan)).values)) if len(g)>0 else np.nan).reset_index().rename(columns={0:'mean_yes_ratio_versions'})\n"
     ]
    }
   ],
   "source": [
    "def _entropy_row(r):\n",
    "    y = float(r['yes']); n = float(r['no']); t = float(r['total'])\n",
    "    if t<=0: return 0.0\n",
    "    a = max(t - y - n, 0.0)\n",
    "    p = np.array([y,t - y - n,n], dtype=np.float64)/t\n",
    "    p = p[p>0]\n",
    "    return float(-(p*np.log(p)).sum())\n",
    "closest_pick['controversiality'] = 1 - (closest_pick['yes'] - closest_pick['no']).abs()/closest_pick['total'].replace(0,np.nan)\n",
    "closest_pick['vote_entropy'] = closest_pick.apply(_entropy_row, axis=1)\n",
    "\n",
    "mean_yes_ratio_versions = roll.groupby('bill_ID').apply(lambda g: float(np.nanmean((g['yes']/g['total'].replace(0,np.nan)).values)) if len(g)>0 else np.nan).reset_index().rename(columns={0:'mean_yes_ratio_versions'})\n",
    "\n",
    "bill_term = first_last[['bill_ID','First_action']].copy()\n",
    "bill_term['term'] = _safe_dt(bill_term['First_action']).apply(_term_from_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "12f9ddb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/jkjxx5pj447bytbqv8pkw9nh0000gn/T/ipykernel_33174/3790113527.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  bt['primary_authors'] = bt.groupby('bill_ID', group_keys=False).apply(_primary_authors).reset_index(level=0, drop=True)\n"
     ]
    }
   ],
   "source": [
    "bt = bills_table[['bill_ID', 'Last_action']].drop_duplicates()\n",
    "bt['Last_action'] = pd.to_datetime(bt['Last_action'])\n",
    "bt = bt.merge(history, left_on=['bill_ID', 'Last_action'], right_on=['bill_ID', 'Date'], how='left')\n",
    "bt = bt.merge(authors[['bill_id', 'Contribution', 'Name']], on='bill_id', how='inner')\n",
    "\n",
    "author_type_map = {\n",
    "    'LEAD_AUTHOR': 'LEAD_AUTHOR',\n",
    "    'PRINCIPAL_COAUTHOR': 'PRINCIPAL_COAUTHOR',\n",
    "    'COAUTHOR': 'COAUTHOR',\n",
    "    'data=\"COAUTHOR\"': 'COAUTHOR',\n",
    "    'data=\"LEAD_AUTHOR\"': 'LEAD_AUTHOR',\n",
    "    'data=\"PRINCIPAL_COAUTHOR\"': 'PRINCIPAL_COAUTHOR',\n",
    "    'nan': 'AUTHOR'\n",
    "}\n",
    "author_levels = {\n",
    "    'AUTHOR': 1,\n",
    "    'COAUTHOR': 1,\n",
    "    'PRINCIPAL_COAUTHOR': 2,\n",
    "    'LEAD_AUTHOR': 3\n",
    "}\n",
    "\n",
    "bt['author_type'] = bt['Contribution'].map(author_type_map).fillna('AUTHOR')\n",
    "bt['author_level'] = bt['author_type'].map(author_levels).fillna(0).astype(int)\n",
    "def _primary_authors(g):\n",
    "    g = g.sort_values('author_level', ascending=False)\n",
    "    primary = g[g['author_level'] == g['author_level'].max()]\n",
    "    return list(set(primary['Name'].tolist()))\n",
    "\n",
    "bt['primary_authors'] = bt.groupby('bill_ID', group_keys=False).apply(_primary_authors).reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "75d9d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_author_df = bt[['bill_ID', 'primary_authors']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "98602fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_insights = pd.DataFrame({'bill_ID': list(bill_labels.keys())})\n",
    "bill_insights = bill_insights.merge(pd.DataFrame({'bill_ID': list(version_id_mapping2.keys()), 'bill_id_raw': [version_id_mapping2[k][0] if len(version_id_mapping2[k])>0 else np.nan for k in version_id_mapping2.keys()]}), on='bill_ID', how='left')\n",
    "bill_insights['topic'] = bill_insights['bill_ID'].map(bill_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "dbc3e756",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_floor['bill_ID'] = last_floor['bill_id']\n",
    "closest_pick['bill_ID'] = closest_pick['bill_id']\n",
    "bill_party_rates['bill_ID'] = bill_party_rates['bill_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "6a8da7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_insights = bill_insights.merge(lead_author_df, on='bill_ID', how='left').merge(mean_yes_ratio_versions, on='bill_ID', how='left').merge(bill_party_rates, on='bill_ID', how='left').merge(last_floor[['bill_ID','yes','no','total']], on='bill_ID', how='left').merge(closest_pick[['bill_ID','controversiality','vote_entropy']], on='bill_ID', how='left').merge(bill_term[['bill_ID','term']], on='bill_ID', how='left')\n",
    "bill_insights['bill_polarization'] = (bill_insights['yes_D_last'] - bill_insights['yes_R_last']).abs()\n",
    "bill_insights['bill_party_line'] = np.where(((bill_insights['yes_D_last']>0.5) & (bill_insights['yes_R_last']<0.5)) | ((bill_insights['yes_D_last']<0.5) & (bill_insights['yes_R_last']>0.5)), 1, 0)\n",
    "bill_insights = bill_insights.rename(columns={'controversiality':'bill_controversiality','vote_entropy':'bill_vote_entropy'})\n",
    "bill_insights = bill_insights[['bill_ID','bill_id_raw','topic','term','primary_authors','mean_yes_ratio_versions','bill_polarization','bill_party_line','bill_controversiality','bill_vote_entropy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ddd8fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_partisanship_summary = (bill_insights.groupby(['topic','term']).agg(mean_polarization=('bill_polarization','mean'), party_line_share=('bill_party_line','mean'), controversiality_index=('bill_controversiality','median'), vote_entropy=('bill_vote_entropy','median'), n_bills=('bill_ID','nunique')).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "24abe8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = voting[['Date', 'bill_ID', 'voting_place', 'chamber']].drop_duplicates().rename(columns={'bill_ID': 'bill_id'})\n",
    "votes['committee_clean'] = votes['chamber'] + ' ' + votes['voting_place']\n",
    "hear_month = hear.copy().merge(votes, on=['bill_id', 'committee_clean'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d86b4a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "hear_month['month'] = pd.to_datetime(hear_month['Date']).dt.to_period('M').astype(str)\n",
    "hear_month = hear_month.dropna(subset=['committee_clean','month'])\n",
    "\n",
    "mload = hear_month.groupby(['committee_clean','month'])['bill_id'].nunique().reset_index(name='hearings')\n",
    "committee_workload_median = mload.groupby('committee_clean')['hearings'].median().reset_index().rename(columns={'committee_clean':'committee','hearings':'median_monthly_hearings'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0007907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = Path(\"dashboard/backend/data/outs\").glob(\"*.parquet\")\n",
    "dfs = {}\n",
    "for f in files:\n",
    "    df = pd.read_parquet(f)\n",
    "    dfs[f.name.replace('.parquet','')] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "cd30603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pickle, datetime\n",
    "from torch_geometric.transforms import ToUndirected, RemoveIsolatedNodes\n",
    "\n",
    "legislators = pickle.load(open('legislators.pkl', 'rb'))\n",
    "\n",
    "def leg_term_to_name(leg_term_id):\n",
    "    if isinstance(leg_term_id, str):\n",
    "        num = int(leg_term_id.split('_')[0])\n",
    "        return legislators.get(num, None)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def leg_term_to_term(leg_term_id):\n",
    "    if isinstance(leg_term_id, str):\n",
    "        a = leg_term_id.split('_')[1]\n",
    "        return int(a.split('-')[0]) if a else None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "with open('node_id_map.json', 'r') as f:\n",
    "    node_id_map = json.load(f)\n",
    "\n",
    "leg_ids = {v: k for k, v in node_id_map['legislator_term'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "bccdff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('data4.pt', map_location='cpu', weights_only=False)\n",
    "data = ToUndirected()(data)\n",
    "data = RemoveIsolatedNodes()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f20c4902",
   "metadata": {},
   "outputs": [],
   "source": [
    "ei = data[(\"legislator_term\",\"wrote\",\"bill_version\")].edge_index.numpy()\n",
    "ea = data[(\"legislator_term\",\"wrote\",\"bill_version\")].edge_attr.numpy()\n",
    "author_edge = pd.DataFrame({\"legterm_id\": ei[0], \"bill_id\": ei[1], \"type\": ea[:,0]})\n",
    "\n",
    "eib = data[('bill_version','is_version', 'bill')].edge_index.numpy()\n",
    "eib = pd.DataFrame({\"src\": eib[0], \"dst\": eib[1], 'outcome': data['bill'].y[eib[1]]})\n",
    "eib['src'] = eib['src'].astype(int)\n",
    "eib['dst'] = eib['dst'].astype(int)\n",
    "author_edge['bill_id'] = author_edge['bill_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7dc34bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_ids = {v: k for k, v in node_id_map['bill_version'].items()}\n",
    "bids = {v: k for k, v in node_id_map['bill'].items()}\n",
    "v2b_edge = tuple([et for et in data.edge_types\n",
    "                if et[0] == \"bill_version\" and et[2] == \"bill\"])[0]\n",
    "src, dst = data[v2b_edge].edge_index.numpy()\n",
    "d = [bids.get(s, None) for s in dst]\n",
    "\n",
    "bv_df = pd.DataFrame({\"bill_version\": src, \"bill_id\": d})\n",
    "bv_df['bill_version_id'] = bv_df['bill_version'].map(bv_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "7b4e00a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_edge = author_edge.merge(eib, left_on='bill_id', right_on='src', how='inner')\n",
    "author_edge['outcome'] = (author_edge['outcome'] == 1).astype(int)\n",
    "author_levels = {1: 'COAUTHOR', 2: 'PRINCIPAL_COAUTHOR', 3: 'LEAD_AUTHOR'}\n",
    "author_edge['author_type'] = author_edge['type'].map(author_levels)\n",
    "\n",
    "ve = data[('bill_version', 'rev_voted_on', 'legislator_term')].edge_index.numpy()\n",
    "va = data[('bill_version', 'rev_voted_on', 'legislator_term')].edge_attr.numpy()\n",
    "vote_edge = pd.DataFrame({'bill_version': ve[0], 'legislator_term': ve[1], 'vote_signal': va[:, 0]})\n",
    "vote_edge = vote_edge.merge(eib, left_on='bill_version', right_on='src', how='left').merge(bv_df, on='bill_version', how='left')\n",
    "vote_edge['full_name'] = vote_edge['legislator_term'].map(leg_ids).apply(leg_term_to_name)\n",
    "vote_edge['term'] = vote_edge['legislator_term'].map(leg_ids).apply(leg_term_to_term)\n",
    "signals = vote_edge.groupby('bill_id').agg({'outcome': 'max', 'vote_signal': lambda x: (x > 0).sum() / len(x)})\n",
    "signals.loc[(signals['outcome'] == 0.0) & (signals['vote_signal'] == 1.0), 'vote_signal'] = 0.0\n",
    "a3 = author_edge.merge(bv_df, left_on='bill_id', right_on='bill_version', how='left').groupby('legterm_id').agg({\n",
    "    'outcome': 'mean',\n",
    "    'author_type': lambda x: sum(x == 'LEAD_AUTHOR'),\n",
    "    'bill_version': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "a3['full_name'] = a3['legterm_id'].map(leg_ids).apply(leg_term_to_name)\n",
    "a3['term'] = a3['legterm_id'].map(leg_ids).apply(leg_term_to_term)\n",
    "lfund['term'] = (lfund['term'] - 1).astype(float)\n",
    "\n",
    "a4 = a3.merge(lfund, on=['full_name', 'term'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "7dfbbcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = dfs['leginflu_v10_overall_influence']\n",
    "d1l = d1.loc[d1['actor_type'] == 'legislator_term']\n",
    "a5 = a4.merge(d1l, left_on='legterm_id', right_on='actor_idx', how='left')\n",
    "leg_terms = a5[['outcome', 'author_type', 'bill_version', 'full_name', 'term', 'Party', 'chamber', 'total_lobbying', 'total_donations', 'influence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "3c55ce40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/jkjxx5pj447bytbqv8pkw9nh0000gn/T/ipykernel_33174/1889222426.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  district_legislator_topic_alignment = pd.concat([dist_align, overall], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "lt = topic_funding_by_leg.copy()\n",
    "if 'topic_weight' not in lt.columns:\n",
    "    for c in ['alignment','weight','share','prob']:\n",
    "        if c in lt.columns:\n",
    "            lt = lt.rename(columns={c:'topic_weight'})\n",
    "            break\n",
    "    if 'topic_weight' not in lt.columns:\n",
    "        lt['topic_weight'] = 1.0\n",
    "lt['lower'] = lt['canon'].astype(str).apply(name_swap)\n",
    "lt['Term'] = lt['term'].astype(str)\n",
    "lk = politicians[['name2','Term','chamber','District No.']].drop_duplicates().rename(columns={'name2':'lower'})\n",
    "lm = lt.merge(lk, on=['lower','Term'], how='left').dropna(subset=['District No.','chamber'])\n",
    "lm['district_id'] = lm['District No.'].apply(lambda x: re.sub(r' ', '', str(x))).astype(float).astype(int).astype(str)\n",
    "lm['house'] = lm['chamber'].str.lower()\n",
    "lm['term_year'] = lm['Term'].apply(_term_year).astype('Int64')\n",
    "dist_align = lm.groupby(['house','district_id','Term','term_year','topic'], dropna=False, as_index=False)['topic_weight'].mean().rename(columns={'Term':'term','topic_weight':'topic_weight_mean'})\n",
    "overall = lm.groupby(['house','district_id','topic'], dropna=False, as_index=False)['topic_weight'].mean()\n",
    "overall['term'] = 'Overall'\n",
    "overall['term_year'] = pd.NA\n",
    "overall = overall.rename(columns={'topic_weight':'topic_weight_mean'})\n",
    "district_legislator_topic_alignment = pd.concat([dist_align, overall], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "411cc2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bills_table = bills_table.merge(bill_vers[['bill_ID', 'GeneralSubject', 'Urgency', 'VoteRequired', 'LocalProgram', 'TaxLevy']], on='bill_ID', how='inner').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7472c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_topics = lobbying[['FIRM_NAME','clean_beneficiary','EXPN_DATE','BENE_AMT']].dropna(subset=['FIRM_NAME','clean_beneficiary','EXPN_DATE','BENE_AMT']).copy()\n",
    "lb_topics['EXPN_DATE'] = pd.to_datetime(lb_topics['EXPN_DATE'], errors='coerce')\n",
    "lb_topics = lb_topics[lb_topics['EXPN_DATE'].notna()]\n",
    "lb_topics['term'] = lb_topics['EXPN_DATE'].apply(_term_from_date)\n",
    "lb_topics = lb_topics[lb_topics['term'].notna()]\n",
    "lb_topics['canon'] = lb_topics['clean_beneficiary'].apply(_canon_name)\n",
    "lb_topics['BENE_AMT'] = pd.to_numeric(lb_topics['BENE_AMT'], errors='coerce').fillna(0.0)\n",
    "lb_topics = lb_topics.merge(weights_topics[['canon','term','topic','topic_share']], on=['canon','term'], how='left')\n",
    "lb_topics = lb_topics[lb_topics['topic_share'].notna()]\n",
    "lb_topics['alloc'] = lb_topics['BENE_AMT'] * lb_topics['topic_share']\n",
    "lobby_firm_topic_by_term = lb_topics.groupby(['FIRM_NAME','topic','term'], as_index=False)['alloc'].sum().rename(columns={'alloc':'lobby_allocated'})\n",
    "\n",
    "def _cycle_from_year(y):\n",
    "    return '2011' if y <= 2012 else 'current'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9b608dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "don_gc = don_g.copy()\n",
    "don_gc['district_id'] = don_gc['district_id'].apply(lambda x: re.sub(r' ', '', str(x))).astype(float).astype(int)\n",
    "don_gc['base_year'] = pd.to_numeric(don_gc['term_year'].fillna(don_gc['term']), errors='coerce')\n",
    "don_gc = don_gc[don_gc['base_year'].notna()]\n",
    "don_gc['cycle'] = don_gc['base_year'].apply(_cycle_from_year)\n",
    "don_gc = don_gc.merge(\n",
    "    weights[['house','cycle','district_id','COUNTYFP','w_pop']],\n",
    "    on=['house','cycle','district_id'],\n",
    "    how='inner'\n",
    ")\n",
    "don_gc['county_id'] = don_gc['COUNTYFP'].astype(int)\n",
    "don_gc['amount_weighted'] = don_gc['total'] * don_gc['w_pop']\n",
    "donor_county = (\n",
    "    don_gc.groupby(['county_id','name'], as_index=False)['amount_weighted']\n",
    "         .sum()\n",
    "         .rename(columns={'name':'funder','amount_weighted':'total_amount'})\n",
    ")\n",
    "donor_county['kind'] = 'Donor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "cfac71c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_key2 = pol_key[['name2','term','chamber','District No.']].drop_duplicates().rename(columns={'term':'term_start'})\n",
    "lob_f = lobbying[['FIRM_NAME','clean_beneficiary','EXPN_DATE','BENE_AMT']].dropna(subset=['FIRM_NAME','clean_beneficiary','EXPN_DATE','BENE_AMT']).copy()\n",
    "lob_f['EXPN_DATE'] = pd.to_datetime(lob_f['EXPN_DATE'], errors='coerce')\n",
    "lob_f = lob_f[lob_f['EXPN_DATE'].notna()]\n",
    "lob_f['term'] = lob_f['EXPN_DATE'].apply(_term_from_date)\n",
    "lob_f = lob_f[lob_f['term'].notna()]\n",
    "lob_f['term_start'] = lob_f['term'].str.slice(0,4).astype(int)\n",
    "lob_f['name2'] = lob_f['clean_beneficiary'].astype(str).apply(name_swap)\n",
    "lob_f = lob_f.merge(pol_key2, on=['name2','term_start'], how='left')\n",
    "lob_f = lob_f.dropna(subset=['District No.','chamber'])\n",
    "lob_f['district_id'] = lob_f['District No.'].apply(lambda x: re.sub(r' ', '', str(x))).astype(float).astype(int)\n",
    "lob_f['house'] = lob_f['chamber'].str.lower()\n",
    "lob_f['amount'] = pd.to_numeric(lob_f['BENE_AMT'], errors='coerce').fillna(0.0)\n",
    "lob_f['cycle'] = lob_f['term_start'].apply(_cycle_from_year)\n",
    "lob_gc = lob_f.merge(\n",
    "    weights[['house','cycle','district_id','COUNTYFP','w_pop']],\n",
    "    on=['house','cycle','district_id'],\n",
    "    how='inner'\n",
    ")\n",
    "lob_gc['county_id'] = lob_gc['COUNTYFP'].astype(int)\n",
    "lob_gc['amount_weighted'] = lob_gc['amount'] * lob_gc['w_pop']\n",
    "lobby_county = (\n",
    "    lob_gc.groupby(['county_id','FIRM_NAME'], as_index=False)['amount_weighted']\n",
    "          .sum()\n",
    "          .rename(columns={'FIRM_NAME':'funder','amount_weighted':'total_amount'})\n",
    ")\n",
    "lobby_county['kind'] = 'Lobbying'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b6f6ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_funders = pd.concat([donor_county, lobby_county], ignore_index=True)\n",
    "county_funders = county_funders.merge(\n",
    "    counties_gdf[['county_id','NAMELSAD']],\n",
    "    on='county_id',\n",
    "    how='left'\n",
    ").rename(columns={'NAMELSAD':'county_name'})\n",
    "\n",
    "\n",
    "donor_topics = (\n",
    "    donor_topic_by_term.groupby(['ExpenderName','topic'], as_index=False)['donations_allocated']\n",
    "    .sum()\n",
    ")\n",
    "donor_topics['rank'] = donor_topics.groupby('ExpenderName')['donations_allocated'].rank(ascending=False, method='first')\n",
    "donor_topics_top = donor_topics[donor_topics['rank'] <= 3].sort_values(['ExpenderName','rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "efa6ac73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/jkjxx5pj447bytbqv8pkw9nh0000gn/T/ipykernel_33174/1085296998.py:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['53, 3, 62' '3, 62, 42' '53, 3, 62' ... '53, 3, 62' '53, 3, 62'\n",
      " '3, 62, 18']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  county_funders.loc[mask_d, 'top_topics'] = county_funders.loc[mask_d, 'funder'].map(donor_topics_map)\n"
     ]
    }
   ],
   "source": [
    "donor_topics_top['topic'] = donor_topics_top['topic'].astype(int).astype(str)\n",
    "\n",
    "donor_topics_map = donor_topics_top.groupby('ExpenderName')['topic'].apply(lambda x: ', '.join(list(set(x)))).to_dict()\n",
    "\n",
    "lobby_topics = (\n",
    "    lobby_firm_topic_by_term.groupby(['FIRM_NAME','topic'], as_index=False)['lobby_allocated']\n",
    "    .sum()\n",
    ")\n",
    "lobby_topics['rank'] = lobby_topics.groupby('FIRM_NAME')['lobby_allocated'].rank(ascending=False, method='first')\n",
    "lobby_topics_top = lobby_topics[lobby_topics['rank'] <= 3].sort_values(['FIRM_NAME','rank'])\n",
    "lobby_topics_top['topic'] = lobby_topics_top['topic'].astype(int).astype(str)\n",
    "lobby_topics_map = lobby_topics_top.groupby('FIRM_NAME')['topic'].apply(lambda x: ', '.join(list(set(x)))).to_dict()\n",
    "\n",
    "county_funders['top_topics'] = np.nan\n",
    "mask_d = county_funders['kind'] == 'Donor'\n",
    "mask_l = county_funders['kind'] == 'Lobbying'\n",
    "county_funders.loc[mask_d, 'top_topics'] = county_funders.loc[mask_d, 'funder'].map(donor_topics_map)\n",
    "county_funders.loc[mask_l, 'top_topics'] = county_funders.loc[mask_l, 'funder'].map(lobby_topics_map)\n",
    "\n",
    "county_funders['rank_in_county'] = county_funders.groupby(['county_id','kind'])['total_amount'].rank(ascending=False, method='first')\n",
    "county_top_funders = county_funders[county_funders['rank_in_county'] <= 15].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "3a50d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name in ['route_archetypes','amendment_churn','risk_list','committee_gatekeeping','committee_workload_median','cross_chamber_friction','survival_curves','vote_similarity_edges','vote_communities','committee_floor_drift','text_lift_top_tokens','donor_portfolios_hhi','money_vote_alignment','money_event_time_curve','ca_legislator_funding','bills_table','topic_controversy','rollcall_party_splits','topic_funding_by_term','topic_funding_by_leg','donor_topic_by_term','topic_momentum','topic_funnel_obs','topic_funnel_modeled','route_baseline','bill_insights','topic_partisanship_summary','route_entropy','committee_betweenness_proxy','author_coalition_breadth']:\n",
    "    if df_name in locals():\n",
    "        df = locals()[df_name]\n",
    "        if isinstance(df, pd.DataFrame) and 'term' in df.columns:\n",
    "            locals()[df_name]['term'] = locals()[df_name]['term'].astype(str)\n",
    "\n",
    "precomp_outputs = {\n",
    "    'amendment_churn': amendment_churn,\n",
    "    'committee_workload_median': committee_workload_median,\n",
    "    'committee_floor_drift': committee_floor_drift,\n",
    "    'money_vote_alignment': money_vote_alignment,\n",
    "    'money_vote_party_alignment': money_vote_party_alignment,\n",
    "    'ca_legislator_funding_geo': ca_legislator_funding,\n",
    "    'ca_legislator_funding': reg_funds_,\n",
    "    'bills_table': bills_table,\n",
    "    'topic_controversy': topic_controversy,\n",
    "    'rollcall_party_splits': rollcall_party_splits,\n",
    "    'topic_funding_by_term': topic_funding_by_term,\n",
    "    'topic_funding_by_leg': topic_funding_by_leg,\n",
    "    'donor_topic_by_term': donor_topic_by_term,\n",
    "    'bill_insights': bill_insights,\n",
    "    'topic_partisanship_summary': topic_partisanship_summary,\n",
    "    'district_funders_time': district_funders_time,\n",
    "    'county_top_funders': county_top_funders,\n",
    "    'leg_terms': leg_terms\n",
    "}\n",
    "\n",
    "for k, v in precomp_outputs.items():\n",
    "    v.to_parquet(f'dashboard/backend/data/outs/{k}.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "fb2e9316",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_legislator_funding = pd.read_parquet('dashboard/backend/data/outs/ca_legislator_funding_geo.parquet')\n",
    "county_top_funders = pd.read_parquet('dashboard/backend/data/outs/county_top_funders.parquet')\n",
    "bills_table = pd.read_parquet('dashboard/backend/data/outs/bills_table.parquet')\n",
    "bill_insights = pd.read_parquet('dashboard/backend/data/outs/bill_insights.parquet')\n",
    "rollcall_party_splits = pd.read_parquet('dashboard/backend/data/outs/rollcall_party_splits.parquet')\n",
    "amendment_churn = pd.read_parquet('dashboard/backend/data/outs/amendment_churn.parquet')\n",
    "leg_terms = pd.read_parquet('dashboard/backend/data/outs/leg_terms.parquet')\n",
    "topic_funding_by_term = pd.read_parquet('dashboard/backend/data/outs/topic_funding_by_term.parquet')\n",
    "maps = gpd.read_file('dashboard/backend/data/ca_counties.geojson').to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "392bc8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca_legislator_funding\n",
      "\n",
      "\n",
      "county_id               int64\n",
      "house                  object\n",
      "total_donations       float64\n",
      "total_lobbying        float64\n",
      "total_received        float64\n",
      "COUNTYFP               object\n",
      "NAMELSAD               object\n",
      "geometry               object\n",
      "county_area_m2        float64\n",
      "population            float64\n",
      "pop_density_per_m2    float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "county_top_funders\n",
      "\n",
      "\n",
      "county_id           int64\n",
      "funder             object\n",
      "total_amount      float64\n",
      "kind               object\n",
      "county_name        object\n",
      "top_topics         object\n",
      "rank_in_county    float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "bills_table\n",
      "\n",
      "\n",
      "bill_ID                object\n",
      "outcome                 int64\n",
      "topic                 float64\n",
      "First_action           object\n",
      "longevity_days          int64\n",
      "Last_action            object\n",
      "vote_signal           float64\n",
      "n_versions            float64\n",
      "median_sim            float64\n",
      "bill_version_count      int64\n",
      "GeneralSubject         object\n",
      "Urgency                object\n",
      "VoteRequired           object\n",
      "LocalProgram           object\n",
      "TaxLevy                object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "bill_insights\n",
      "\n",
      "\n",
      "bill_ID                     object\n",
      "bill_id_raw                 object\n",
      "topic                        int64\n",
      "term                        object\n",
      "primary_authors             object\n",
      "mean_yes_ratio_versions    float64\n",
      "bill_polarization          float64\n",
      "bill_party_line              int64\n",
      "bill_controversiality      float64\n",
      "bill_vote_entropy          float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "rollcall_party_splits\n",
      "\n",
      "\n",
      "bill_ID              object\n",
      "term                 object\n",
      "topic               float64\n",
      "yes_D               float64\n",
      "yes_R               float64\n",
      "polarization        float64\n",
      "party_line_split      int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "amendment_churn\n",
      "\n",
      "\n",
      "bill_ID        object\n",
      "n_versions    float64\n",
      "median_sim    float64\n",
      "topic         float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "leg_terms\n",
      "\n",
      "\n",
      "outcome            float64\n",
      "author_type          int64\n",
      "bill_version         int64\n",
      "full_name           object\n",
      "term               float64\n",
      "Party               object\n",
      "chamber             object\n",
      "total_lobbying     float64\n",
      "total_donations    float64\n",
      "influence          float32\n",
      "dtype: object\n",
      "\n",
      "\n",
      "topic_funding_by_term\n",
      "\n",
      "\n",
      "topic              float64\n",
      "term                object\n",
      "total_donations    float64\n",
      "total_lobbying     float64\n",
      "total_received     float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "CA_counties.geojson\n",
      "\n",
      "\n",
      "COUNTYFP         object\n",
      "NAMELSAD         object\n",
      "county_area     float64\n",
      "county_id         int32\n",
      "geometry       geometry\n",
      "dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tables = {\n",
    "    'ca_legislator_funding': ca_legislator_funding,\n",
    "    'county_top_funders': county_top_funders,\n",
    "    'bills_table': bills_table,\n",
    "    'bill_insights': bill_insights,\n",
    "    'rollcall_party_splits': rollcall_party_splits,\n",
    "    'amendment_churn': amendment_churn,\n",
    "    'leg_terms': leg_terms,\n",
    "    'topic_funding_by_term': topic_funding_by_term,\n",
    "    'CA_counties.geojson': maps\n",
    "}\n",
    "\n",
    "for t, table in tables.items():\n",
    "    print(t)\n",
    "    print('\\n')\n",
    "    print(table.dtypes)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de09628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
