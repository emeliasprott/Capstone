{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch, datetime, hashlib, json, re, warnings, pathlib, zipfile, tempfile, pickle, unicodedata\n",
    "from torch_geometric.data import HeteroData\n",
    "import geopandas as gpd\n",
    "\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_votes = pd.read_csv('ca_leg/legislation_data/bill_summary_vote_tbl.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_history = pd.read_csv('ca_leg/legislation_data/bill_history_tbl.csv', dtype={'action_status': str, 'primary_location': str, 'secondary_location': str, 'end_status': str})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = pd.read_csv('ca_leg/legislation_data/authors.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.read_csv('ca_leg/legislation_data/history.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "versions = pd.read_csv('ca_leg/legislation_data/bill_versions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_votes = pd.read_csv('ca_leg/legislation_data/bill_detail_vote_tbl.csv', parse_dates=['session_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_summary = pd.read_csv('ca_leg/legislation_data/bill_summary_vote_tbl.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_motions = pd.read_csv('ca_leg/legislation_data/bill_motion_tbl.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = pd.read_csv('ca_leg/legislation_data/committee_codes.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians = pd.read_csv('ca_leg/legislation_data/politicians.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "lobbying = pd.read_csv('calaccess/lobbying_clean2.csv', dtype={'PAYEE_NAMS': str, 'BAKREF_TID': str})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "expend_assembly = pd.read_csv('calaccess/expend_assembly_matched.csv', dtype={'TargetPropositionName': str})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "expend_senate = pd.read_csv('calaccess/expend_senate_matched.csv', dtype={'TargetPropositionName': str})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "digests = pd.read_csv('ca_leg/legislation_data/digest.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "hearings = pd.read_csv('ca_leg/legislation_data/committee_hearing_tbl.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "disclosure = pd.read_csv('calaccess/CVR_LOBBY_DISCLOSURE_CD2.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_votes['vote_date_time'] = pd.to_datetime(bill_votes['vote_date_time']).apply(lambda x: x.strftime('%Y-%m-%d'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_votes['legislator_name'] = bill_votes['legislator_name'].apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_KEYWORDS = [\n",
    "    \"Assembly Third Reading\", \"Assembly 3rd reading\", 'senate 3rd reading', \"Senate Third Reading\",\"Concurrence - Urgency Added\", \"Concurrence in Senate Amendments\", \"Do pass as amended, and re-refer\", \"Do pass as amended, but re-refer\", \"Do pass as amended\", \"Do pass and be re-referred\",\n",
    "    \"Concurrence\", \"Consent Calendar\", \"Urgency Clause\", \"Special Consent\",\n",
    "    \"Motion to Reconsider\", \"Do pass\", \"Reconsideration\", \"Committee amendments\",\n",
    "    \"W/O REF. TO FILE\", \"Be re-referred to the Committee\",\n",
    "    \"Lay on the Table\", \"Amend by\", \"Unfinished Business\", \"Placed on Appropriations Suspense File\",\n",
    "]\n",
    "\n",
    "def extract_action(motion_text):\n",
    "    if not isinstance(motion_text, str) or motion_text is None:\n",
    "        return None\n",
    "    motion = motion_text.upper()\n",
    "\n",
    "    action = next((act for act in ACTION_KEYWORDS if act.upper() in motion), None)\n",
    "    if action != 'Reconsideration' and 'RECONSIDER' in motion:\n",
    "        if action is not None:\n",
    "            action += ' Reconsideration'\n",
    "        else:\n",
    "            action = 'Reconsideration'\n",
    "\n",
    "\n",
    "    return action if action else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_motions['simplified_motion'] = bill_motions['motion_text'].apply(extract_action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_coms = {}\n",
    "for i, row in locations.iterrows():\n",
    "    if row['committee_code'].startswith('CZ'):\n",
    "        continue\n",
    "    name = row['committee_name']\n",
    "    if row['committee_code'].startswith('CS'):\n",
    "        if name.startswith('Sen.'):\n",
    "            cname = re.sub(r'Sen. ', 'senate ', name).lower()\n",
    "        elif name.startswith('Senate '):\n",
    "            cname = name.lower()\n",
    "        else:\n",
    "            cname = 'senate ' + name.lower()\n",
    "    elif row['committee_code'].startswith('CX'):\n",
    "        if name.lower().startswith('assembly'):\n",
    "            cname = name.lower()\n",
    "        else:\n",
    "            cname = 'assembly ' + name.lower()\n",
    "    if re.search(r'x\\d$', cname) is not None:\n",
    "        cname = re.sub(r'x(?=\\d$)', 'no. ', cname)\n",
    "    clean_coms[row['committee_code']] = cname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "leg_committees = [f\"{row['chamber']} {row['committee_clean']}\".lower() for _, row in politicians[['committee_clean', 'chamber']].drop_duplicates().iterrows()]\n",
    "\n",
    "def match_committees(_names, clean_coms, threshold=92):\n",
    "    clean_c = list(clean_coms.values())\n",
    "    clean_codes = list(clean_coms.keys())\n",
    "    name_mapping = {}\n",
    "    for i, clean in enumerate(clean_c):\n",
    "        code = clean_codes[i]\n",
    "        matches = []\n",
    "        matches.append(process.extractOne(\n",
    "            clean,\n",
    "            _names,\n",
    "            scorer=fuzz.token_sort_ratio,\n",
    "            score_cutoff=threshold\n",
    "        ))\n",
    "        matches.append(process.extractOne(\n",
    "            clean,\n",
    "            _names,\n",
    "            scorer=fuzz.partial_ratio,\n",
    "            score_cutoff=threshold\n",
    "        ))\n",
    "        valid_matches = [m for m in matches if m is not None]\n",
    "        if len(valid_matches) > 0:\n",
    "            best_match = max(valid_matches, key=lambda x: x[1])\n",
    "            name_mapping[code] = best_match[0]\n",
    "        else:\n",
    "            fall_back = process.extractOne(\n",
    "                clean,\n",
    "                _names,\n",
    "                scorer=fuzz.token_sort_ratio,\n",
    "                score_cutoff=threshold - 8\n",
    "            )\n",
    "            if fall_back is not None:\n",
    "                name_mapping[code] = fall_back[0]\n",
    "            else:\n",
    "                name_mapping[code] = None\n",
    "    return name_mapping\n",
    "\n",
    "committee_matches = match_committees(leg_committees, clean_coms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations['committee_clean'] = locations['committee_code'].map(committee_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.loc[locations['committee_name'] == 'EDUCATION X5', 'committee_clean'] = 'Budget and Fiscal Review: Education'\n",
    "locations.loc[locations['committee_code'] == 'CX12', 'committee_clean'] = 'Budget No. 1 on Health and Human Services'\n",
    "locations.loc[locations['committee_code'] == 'CS68', 'committee_clean'] = 'Budget No. 3 - Health and Human Services'\n",
    "locations.loc[locations['committee_code'] == 'CS66', 'committee_clean'] = 'Senate Veterans Affairs'\n",
    "locations.loc[locations['committee_code'] == 'CS56', 'committee_clean'] = 'Senate Public Employment and Retirement'\n",
    "locations.loc[locations['committee_code'] == 'CS62', 'committee_clean'] = 'Senate Budget and Fiscal Review'\n",
    "locations.loc[locations['committee_code'] == 'CX23', 'committee_clean'] = 'Assembly Utilities and Commerce'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_codes = {\n",
    "    row['motion_id']: row['simplified_motion']\n",
    "    for _, row in bill_motions.iterrows()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_votes['motion_text'] = summary_votes['motion_id'].map(motion_codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_bill_id(id):\n",
    "    front, end = id[:4], id[4:]\n",
    "    if re.search(r'\\d{4}$', front):\n",
    "        return f\"{front}{int(front) + 1}{end}\"\n",
    "    else:\n",
    "        return id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "versions['ID'] = versions['bill_id'].apply(lambda x: repair_bill_id(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "lob_repairs = {}\n",
    "for _, row in lobbying.loc[(lobbying['FILING_ID'].isin(lobbying.loc[lobbying['FIRM_NAME'].isna(), 'FILING_ID'].drop_duplicates().tolist())) & (lobbying['FIRM_NAME'].notna()), ['FILING_ID', 'FIRM_NAME']].drop_duplicates().iterrows():\n",
    "    lob_repairs[row['FILING_ID']] = row['FIRM_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_firms = disclosure.loc[disclosure['FIRM_NAME'].isna(), ['FILING_ID', 'FILER_NAMF', 'FILER_NAML']].drop_duplicates()\n",
    "\n",
    "def firm_correction(row):\n",
    "    if row['FILER_NAMF'] == None or not isinstance(row['FILER_NAMF'], str):\n",
    "        return row['FILER_NAML']\n",
    "    elif row['FILER_NAML'] == None or not isinstance(row['FILER_NAML'], str):\n",
    "        return row['FILER_NAMF']\n",
    "    else:\n",
    "        return row['FILER_NAMF'] + ' ' + row['FILER_NAML']\n",
    "\n",
    "missed_firms['correction'] = missed_firms.apply(firm_correction, axis=1)\n",
    "\n",
    "correct_firms = {row['FILING_ID']: row['correction'] for _, row in missed_firms.iterrows()}\n",
    "\n",
    "lobbying.loc[lobbying['FIRM_NAME'].isna(), 'FIRM_NAME'] = lobbying.loc[lobbying['FIRM_NAME'].isna(), 'FILING_ID'].astype(str).map(correct_firms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_firm_name(row):\n",
    "    if pd.isna(row['FIRM_NAME']):\n",
    "        if row['FILING_ID'] in lob_repairs.keys():\n",
    "            return lob_repairs.get(row['FILING_ID'])\n",
    "        else:\n",
    "            try:\n",
    "                id = int(re.sub(r'\\s+', '', str(row['FILING_ID'])).strip())\n",
    "            except:\n",
    "                id = None\n",
    "            if id == None:\n",
    "                if not pd.isna(row['FILING_ID']):\n",
    "                    return row['FILING_ID']\n",
    "            elif str(id) in lob_repairs.keys():\n",
    "                return lob_repairs.get(str(id))\n",
    "    return row['FIRM_NAME']\n",
    "lobbying['FIRM'] = lobbying.apply(fix_firm_name, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "STOPWORDS = {\"the\", \"and\", \"of\", \"&\", \"for\", \"to\"}\n",
    "LEGAL = {\n",
    "    \"inc\", \"incorporated\", \"corp\", \"corporation\",\n",
    "    \"llc\", \"l.l.c\", \"lp\", \"l.p\", \"llp\", \"l.l.p\",\n",
    "    \"co\", \"company\", \"group\", \"partners\",\n",
    "    \"holdings\", \"association\", \"assn\", \"assoc\"\n",
    "}\n",
    "\n",
    "def clean_tokens(name):\n",
    "    if not isinstance(name, str):\n",
    "        return []\n",
    "\n",
    "    name = unicodedata.normalize(\"NFKD\", name)\n",
    "    name = name.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"[^\\w\\s]\", \" \", name).strip()\n",
    "\n",
    "    return sorted(\n",
    "        t for t in name.split()\n",
    "        if t not in STOPWORDS and t not in LEGAL\n",
    "    )\n",
    "\n",
    "def group_similar_names(canonicals, threshold=93):\n",
    "    groups = []\n",
    "    group_ids = [-1] * len(canonicals)\n",
    "    current_gid = 0\n",
    "\n",
    "    for i, name_i in tqdm(enumerate(canonicals), total=len(canonicals)):\n",
    "        if group_ids[i] != -1:\n",
    "            continue\n",
    "\n",
    "        group_ids[i] = current_gid\n",
    "\n",
    "        for j in range(i + 1, len(canonicals)):\n",
    "            if group_ids[j] != -1:\n",
    "                continue\n",
    "\n",
    "            score = fuzz.token_set_ratio(name_i, canonicals[j])\n",
    "            if score >= threshold:\n",
    "                group_ids[j] = current_gid\n",
    "\n",
    "        current_gid += 1\n",
    "\n",
    "    return group_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121019/121019 [01:34<00:00, 1279.49it/s] \n"
     ]
    }
   ],
   "source": [
    "lobbying['tokens'] = lobbying['FIRM'].apply(clean_tokens)\n",
    "lobbying['canonical'] = lobbying[\"tokens\"].apply(lambda t: \" \".join(t))\n",
    "lobbying['name_group'] = group_similar_names(lobbying['canonical'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 888/888 [00:01<00:00, 846.75it/s] \n"
     ]
    }
   ],
   "source": [
    "donor_n = pd.concat([expend_assembly['ExpenderName'], expend_senate['ExpenderName']]).drop_duplicates().to_frame()\n",
    "donor_n['tokens'] = donor_n['ExpenderName'].apply(clean_tokens)\n",
    "donor_n['canonical'] = donor_n['tokens'].apply(lambda t: \" \".join(t))\n",
    "donor_n['name_group'] = group_similar_names(donor_n['canonical'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "lob_names = {}\n",
    "for _, row in lobbying.groupby('name_group').agg({'FIRM': 'first'}).reset_index().iterrows():\n",
    "    lob_names[row['name_group']] = row['FIRM']\n",
    "lobbying['FIRM'] = lobbying['name_group'].map(lob_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "don_names = {}\n",
    "for _, row in donor_n.groupby('name_group').agg({'ExpenderName': 'first'}).reset_index().iterrows():\n",
    "    don_names[row['name_group']] = row['ExpenderName']\n",
    "\n",
    "don_name_group_map = {}\n",
    "for _, row in donor_n[['ExpenderName', 'name_group']].drop_duplicates().iterrows():\n",
    "    don_name_group_map[row['ExpenderName']] = row['name_group']\n",
    "\n",
    "expend_assembly['Expender'] = expend_assembly['ExpenderName'].apply(lambda x: don_names.get(don_name_group_map.get(x)))\n",
    "expend_senate['Expender'] = expend_senate['ExpenderName'].apply(lambda x: don_names.get(don_name_group_map.get(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_vers = versions.loc[versions['bill_id'].str.startswith('2')]\n",
    "for i, row in bill_vers.iterrows():\n",
    "    tail = f\"{row['VersionNum']}{row['MeasureState']}\"\n",
    "    repaired = repair_bill_id(re.sub(tail, '', row['bill_id']))\n",
    "    end = int(repaired[-4:])\n",
    "\n",
    "    bill_vers.loc[i, 'bill_ID'] = f\"{repaired[:-4]}{end}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in {'Horton': 'Shirley', 'Calderon': 'Ron', 'Berryhill': 'Tom', 'Stone': 'Mark', 'Rubio': 'Susan', 'Rivas': 'Robert', 'Nguyen': 'Janet'}.items():\n",
    "    politicians.loc[(politicians['full_name'].isna()) & (politicians['Last'] == k), 'full_name'] = f\"{k}, {v}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_fixes = {}\n",
    "manual = {'Steinberg, Darrell': [6, 'D'],\n",
    " 'Calderon, Ron': [30, 'D'],\n",
    " 'Stone, Mark': [29, 'D'],\n",
    " 'Rubio, Susan': [22, 'D'],\n",
    " 'Nguyen, Janet': [36, 'R'],\n",
    " 'Berryhill, Tom': [8, 'R']}\n",
    "\n",
    "for _, row in politicians.loc[politicians['District No.'].isna(), ['full_name', 'chamber', 'Term']].drop_duplicates().iterrows():\n",
    "    if politicians.loc[(politicians['chamber'] == row['chamber']) & (politicians['full_name'] == row['full_name']) & (politicians['Term'] == row['Term'])].dropna(subset='District No.').shape[0] > 0:\n",
    "        f = politicians.loc[(politicians['chamber'] == row['chamber']) & (politicians['full_name'] == row['full_name']) & (politicians['Term'] == row['Term'])].dropna(subset='District No.')\n",
    "        pol_fixes[(row['full_name'], row['chamber'], row['Term'])] = {'party': f['Party'].values[0], 'district_id': re.sub(r'\\s+', '', f['District No.'].values[0])}\n",
    "\n",
    "    else:\n",
    "        pol_fixes[(row['full_name'], row['chamber'], row['Term'])] = {'party': manual.get(row['full_name'])[1], 'district_id': manual.get(row['full_name'])[0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def party_district_fix(rows):\n",
    "    party, district = [], []\n",
    "    for _, row in rows.iterrows():\n",
    "        fix = pol_fixes.get((row['full_name'], row['chamber'], row['Term']))\n",
    "        party.append(fix['party'])\n",
    "        district.append(fix['district_id'])\n",
    "    return party, district\n",
    "\n",
    "parties, districts = party_district_fix(politicians.loc[politicians['District No.'].isna()])\n",
    "politicians.loc[politicians['District No.'].isna(), 'Party'] = parties\n",
    "politicians.loc[politicians['District No.'].isna(), 'District No.'] = districts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "legislators = {i: pol for i, pol in enumerate(politicians['full_name'].unique().tolist())}\n",
    "\n",
    "leg_parties = {row['full_name']: row['Party'] for _, row in politicians[['full_name', 'Party']].drop_duplicates().iterrows()}\n",
    "leg_occupations = {row['full_name']: row['Occupation'] for _, row in politicians[['full_name', 'Occupation']].drop_duplicates().iterrows()}\n",
    "committees = {i: com for i, com in enumerate(politicians['committee_clean'].unique().tolist())}\n",
    "lobby_firms = {i: firm for i, firm in enumerate(lobbying['FIRM'].unique().tolist())}\n",
    "\n",
    "donor_names = list(set(expend_assembly['Expender'].unique().tolist() + expend_senate['Expender'].unique().tolist()))\n",
    "donors = {i: donor for i, donor in enumerate(donor_names)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_titles = {row['bill_ID']: row['Title'] for _, row in bill_vers[['bill_ID', 'Title']].drop_duplicates().iterrows()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_subjects = {row['bill_ID']: row['GeneralSubject'] for _, row in bill_vers.loc[bill_vers['GeneralSubject'].apply(lambda x: x is not None and isinstance(x, str)), ['bill_ID', 'GeneralSubject']].drop_duplicates().iterrows()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_ids = list(set(bill_votes.loc[bill_votes['bill_id'].str.startswith('2'), 'bill_id'].unique().tolist() + summary_votes.loc[summary_votes['bill_id'].str.startswith('2'), 'bill_id'].unique().tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_id_codes = {row['bill_id']: row['bill_ID'] for _, row in bill_vers.drop_duplicates(subset=['bill_id', 'bill_ID']).iterrows()}\n",
    "history['bill_ID'] = history['bill_id'].map(bill_id_codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['Date'] = pd.to_datetime(history['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "introduction_dates = {}\n",
    "for v, group in history.loc[history['bill_ID'].isin(bill_ids)].groupby('bill_ID'):\n",
    "    introduction_dates[v] = {'Dates': group['Date'].unique().tolist(), 'Actions': group.sort_values('Date', ascending=True).drop_duplicates(subset=['Action', 'Date'])['Action'].tolist()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_id_mapping = {i: list(group.values) for i, group in bill_vers.groupby('bill_ID')['ID']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = history.loc[history['bill_ID'].notna()].sort_values('Date', ascending=False).groupby('bill_ID').first().reset_index()[['bill_ID', 'Action']]\n",
    "outcomes.loc[outcomes['Action'].isin(['CHAPTERED', 'ENROLLED', 'FILED', 'APPROVED']), 'Outcome'] = 1\n",
    "outcomes.loc[outcomes['Action'] == 'VETOED', 'Outcome'] = -1\n",
    "outcomes.loc[outcomes['Outcome'].isna(), 'Outcome'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = outcomes.set_index('bill_ID')['Outcome'].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_bill_ids = {}\n",
    "for i in summary_votes.loc[summary_votes['bill_id'].isin(bill_ids)].groupby(['year', 'motion_id'])['bill_id'].value_counts().index:\n",
    "    year, motion_id, bill_id = i\n",
    "    if (year, motion_id) not in vote_bill_ids.keys():\n",
    "        vote_bill_ids[(year, motion_id)] = [bill_id]\n",
    "    else:\n",
    "        vote_bill_ids[(year, motion_id)].append(bill_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_vers_dig = bill_vers.merge(digests, on='bill_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians.loc[(politicians['full_name'] == 'Torlakson, Tom') & (politicians['District No.'] == '6 7'), 'District No.'] = '6'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "legislators_last_names = {}\n",
    "for _, row in politicians[['chamber', 'Last', 'Term', 'full_name']].drop_duplicates().iterrows():\n",
    "    legislators_last_names[(row['chamber'], row['Last'].lower(), row['Term'])] = row['full_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {row['ID']: {\n",
    "    'digest': row['DigestText'],\n",
    "    'MeasureState': row['MeasureState'],\n",
    "    'VoteRequired': row['VoteRequired'] if row['VoteRequired'] is not None else 'No',\n",
    "    'VersionNum': row['VersionNum'] if row['VersionNum'] is not None else 'No',\n",
    "    'LocalProgram': row['LocalProgram'] if row['LocalProgram'] is not None else 'No',\n",
    "    'FiscalCommittee': row['FiscalCommittee'] if row['FiscalCommittee'] is not None else 'No',\n",
    "    'TaxLevy': row['TaxLevy'] if row['TaxLevy'] is not None else 'No',\n",
    "    'Urgency': row['Urgency'] if row['Urgency'] is not None else 'No'} for _, row in bill_vers_dig.iterrows()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "legislator_codes = {v: k for k, v in legislators.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "committee_codes = {v.lower(): k for k, v in committees.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_votes['chamber'] = bill_votes['location_code'].apply(lambda x: 'assembly' if x == 'AFLOOR' or x.startswith('CX') else 'senate' if x == 'SFLOOR' or x.startswith('CS') else 'full')\n",
    "bill_votes['vote_date_time'] = pd.to_datetime(bill_votes['vote_date_time'])\n",
    "bill_votes['term'] = bill_votes['vote_date_time'].apply(lambda x: f\"{x.year}-{x.year + 1}\" if x.year % 2 == 1  else f\"{x.year - 1}-{x.year}\" if x.year % 2 == 0 and x < pd.Timestamp(year=x.year, month=11, day=2) else f\"{x.year + 1}-{x.year + 2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_locations = authors.loc[(authors['House'] == 'UNKNOWN') & (authors['bill_id'].map(bill_id_codes).isin(bill_ids)), ['bill_id', 'Name']].drop_duplicates()\n",
    "for i, row in author_locations.iterrows():\n",
    "    if 'AB' in row['bill_id']:\n",
    "        author_locations.loc[i, 'name'] = 'Assembly ' + row['Name']\n",
    "    elif 'SB' in row['bill_id']:\n",
    "        author_locations.loc[i, 'name'] = 'Senate ' + row['Name']\n",
    "    else:\n",
    "        author_locations.loc[i, 'name'] = 'Joint ' + row['Name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def fuzzy_strings(source_list, target_list):\n",
    "    def preprocess_name(name):\n",
    "        if not isinstance(name, str):\n",
    "            return \"\"\n",
    "        name = name.lower()\n",
    "        name = re.sub(r'\\(.*?\\)', '', name)\n",
    "        name = re.sub(r'committee on', '', name)\n",
    "        name = re.sub(r'[^a-z\\s]', ' ', name)\n",
    "        name = re.sub(r'\\s+', ' ', name).strip()\n",
    "        return name\n",
    "\n",
    "    clean_source = [preprocess_name(c) for c in source_list]\n",
    "    clean_target = [preprocess_name(c) for c in target_list]\n",
    "\n",
    "    keywords = [\"education\", \"health\", \"finance\", \"budget\", \"transportation\",\n",
    "                \"judiciary\", \"environment\", \"agriculture\", \"energy\", \"labor\",\n",
    "                \"housing\", \"veterans affairs\", \"public safety\", \"insurance\", \"banking\", \"public health\", \"small business\", \"redistricting\",\n",
    "                \"public utilities\", \"natural resources\", \"water\",\n",
    "                \"technology\", \"communications\", \"elections\", \"government\",\n",
    "                \"appropriations\", \"rules\", \"ethics\", 'criminal justice', \"environmental protection\", \"college and university\", \"human services\", \"reproductive health\", \"mental health\", \"technology\", \"aggriculture\", \"urban development\", \"renewable energy\", \"gun violence\", \"commerce\", \"privacy\", \"cybersecurity\", \"infrastructure\", \"disaster preparedness\", \"prisons\", \"aging\"]\n",
    "\n",
    "    def get_committee_keywords(name):\n",
    "        return set(kw for kw in keywords if kw in name)\n",
    "\n",
    "    target_keywords = [get_committee_keywords(name) for name in clean_target]\n",
    "\n",
    "    def calculate_similarity(source_idx, target_idx):\n",
    "        source = clean_source[source_idx]\n",
    "        target = clean_target[target_idx]\n",
    "\n",
    "        if not source or not target:\n",
    "            return 0\n",
    "\n",
    "        if source == target:\n",
    "            return 100\n",
    "\n",
    "        token_sort = fuzz.token_sort_ratio(source, target)\n",
    "        token_set = fuzz.token_set_ratio(source, target)\n",
    "        partial = fuzz.partial_ratio(source, target)\n",
    "\n",
    "        source_kw = get_committee_keywords(source)\n",
    "        keyword_overlap = len(source_kw.intersection(target_keywords[target_idx]))\n",
    "        keyword_bonus = min(20, keyword_overlap * 10)\n",
    "        weighted_score = (token_sort * 0.3) + (token_set * 0.5) + (partial * 0.2) + keyword_bonus\n",
    "\n",
    "        return weighted_score\n",
    "\n",
    "    matches = {}\n",
    "    for i, source in enumerate(source_list):\n",
    "        scores = [calculate_similarity(i, j) for j in range(len(target_list))]\n",
    "\n",
    "        if not scores or max(scores) < 60:\n",
    "            matches[source] = None\n",
    "        else:\n",
    "            best_idx = np.argmax(scores)\n",
    "            confidence = scores[best_idx]\n",
    "\n",
    "            if confidence >= 60:\n",
    "                matches[source] = target_list[best_idx]\n",
    "            else:\n",
    "                matches[source] = None\n",
    "\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_com_matches = fuzzy_strings(author_locations['name'].unique().tolist(), leg_committees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_locations['name'] = author_locations['name'].map(author_com_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "sponsors = authors.loc[authors['bill_id'].map(bill_id_codes).isin(bill_ids)]\n",
    "sponsors['term'] = sponsors['bill_id'].apply(lambda x: f\"{x[:4]}-{int(x[:4]) + 1}\" if int(x[:4]) % 2 == 1 else f\"{int(x[:4]) - 1}-{x[:4]}\" if int(x[:4]) % 2 == 0 and int(x[:4]) < 2009 else f\"{x[:4]}-{int(x[:4]) + 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "lob = lobbying.loc[lobbying['clean_beneficiary'].notna(), ['FIRM', 'EXPN_DSCR', 'clean_beneficiary', 'EXPN_DATE', 'BENE_AMT']]\n",
    "lob['EXPN_DATE'] = pd.to_datetime(lob['EXPN_DATE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term(date):\n",
    "    if not isinstance(date, pd.Timestamp):\n",
    "        return None\n",
    "    year = date.year\n",
    "    if year % 2 != 1:\n",
    "        if date.month < 12:\n",
    "            return f\"{year-1}-{year}\"\n",
    "        else:\n",
    "            return f\"{year+1}-{year+2}\"\n",
    "    else:\n",
    "        return f\"{year}-{year+1}\"\n",
    "\n",
    "lob['term'] = lob['EXPN_DATE'].apply(get_term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in politicians.loc[politicians['full_name'].apply(lambda x: isinstance(x, float)), ['Term', 'Last', 'chamber']].drop_duplicates().iterrows():\n",
    "    term, last = row['Term'], row['Last']\n",
    "    a = politicians.loc[(politicians['Last'] == last) & (politicians['Term'] == term) & (politicians['full_name'].apply(lambda x: isinstance(x, str)))]\n",
    "    if len(a) > 0:\n",
    "        politicians.loc[(politicians['Term'] == term) & (politicians['Last'] == last) & (politicians['chamber'] == row['chamber']), 'full_name'] = a['full_name'].values[0]\n",
    "        continue\n",
    "    else:\n",
    "        a = politicians.loc[(politicians['Last'] == last) & (politicians['full_name'].apply(lambda x: isinstance(x, str)))]\n",
    "    if len(a) > 0:\n",
    "        politicians.loc[(politicians['Term'] == term) & (politicians['Last'] == last) & (politicians['chamber'] == row['chamber']), 'full_name'] = a['full_name'].values[0]\n",
    "    else:\n",
    "        print(last, term)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_names_terms = {}\n",
    "for _, row in politicians[['full_name', 'Term', 'chamber']].drop_duplicates().iterrows():\n",
    "    if ',' in row['full_name']:\n",
    "        name = row['full_name'].split(',')[1].strip() + ' ' + row['full_name'].split(',')[0].strip()\n",
    "    else:\n",
    "        name = row['full_name']\n",
    "    pol_names_terms[(row['full_name'].lower(), row['Term'])] = {'chamber': row['chamber'], 'name': name}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians['clean_full_name'] = politicians['full_name'].apply(lambda x: x.split(',')[1].strip() + ' ' + x.split(',')[0].strip() if ',' in x else x)\n",
    "name_fix = {}\n",
    "for _, row in politicians[['clean_full_name', 'full_name']].drop_duplicates().iterrows():\n",
    "    name_fix[row['clean_full_name']] = row['full_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "expend_assembly = expend_assembly.rename(columns={'term': 'Term'})\n",
    "expend_assembly['chamber'] = 'assembly'\n",
    "expend_senate = expend_senate.rename(columns={'term': 'Term'})\n",
    "expend_senate['chamber'] = 'senate'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_contributions = pd.concat([expend_assembly.loc[expend_assembly['matched_target_name'].notna(), ['Expender', 'Amount', 'matched_target_name', 'Term', 'chamber', 'DateEnd']].drop_duplicates(subset=['Expender', 'Amount', 'matched_target_name', 'DateEnd']), expend_senate.loc[expend_senate['matched_target_name'].notna(), ['Expender', 'Amount', 'matched_target_name', 'Term', 'chamber', 'DateEnd']].drop_duplicates(subset=['Expender', 'Amount', 'matched_target_name', 'DateEnd'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_contributions['DateEnd'] = pd.to_datetime(campaign_contributions['DateEnd'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "sponsors['bill_ID'] = sponsors['bill_id'].apply(repair_bill_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = history.merge(bill_votes, left_on=['bill_ID', 'Date'], right_on=['bill_id', 'vote_date_time'], how='inner').rename(columns={'bill_id_x': 'bill_version'}).drop('bill_id_y', axis=1)\n",
    "voting['bv_id'] = voting['bill_version'].apply(repair_bill_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_places = {}\n",
    "for i, row in voting.groupby(['motion_id', 'term', 'chamber', 'Date']).agg({'legislator_name': lambda x: list(x)}).iterrows():\n",
    "    motion_id, term, chamber, date = i\n",
    "    g = politicians.loc[(politicians['chamber'] == chamber) & (politicians['Term'] == term) & (politicians['Last'].isin(row['legislator_name']))]\n",
    "    voting_places[(motion_id, term, chamber, date)] = {\n",
    "        'most_common_committee': g.groupby('committee_clean').size().sort_values(ascending=False).head(1).index[0] if len(g) > 0 else None\n",
    "    }\n",
    "voting['voting_place'] = voting.apply(lambda row: voting_places.get((row['motion_id'], row['term'], row['chamber'], row['Date']), {}).get('most_common_committee', None), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "hear = hearings[['bill_id', 'location_code']].merge(locations[['committee_code', 'committee_clean']], left_on='location_code', right_on='committee_code', how='left')[['bill_id', 'committee_clean']].drop_duplicates()\n",
    "hear['year'] = hear['bill_id'].apply(lambda x: int(x[:4]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = {p: 'Democratic Alternate' if re.search(r'Democratic\\s*Alternate', p) is not None else 'Vice Chair' if re.search(r'V\\s*i\\s*c\\s*e\\s*-*\\s*C\\s*h\\s*a\\s*i\\s*r\\s*', p) is not None else 'Co-Chair' if re.search(r'Co\\s*-\\s*Chair', p) is not None else 'Chair' if re.search(r'Cha\\s*i\\s*r', p) is not None else 'Republican Alternate' if re.search(r'\\s*Republican\\s*Alternate', p) is not None else p for p in politicians['position'].unique()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnums = bill_vers.set_index('ID')['VersionNum'].to_dict()\n",
    "vid_map = {v: k for k, val in version_id_mapping.items() for v in val}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "sponsors['chamber'] = sponsors['House'].apply(lambda x: x.lower() if isinstance(x, str) else None)\n",
    "sponsors = sponsors.merge(politicians[['Term', 'Last', 'chamber', 'full_name']].drop_duplicates(), left_on=['chamber', 'Name', 'term'], right_on=['chamber', 'Last', 'Term'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \" \".join(text.split(',')[::-1])\n",
    "    text = unidecode(text.lower().strip())\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "pol_names_terms2 = {}\n",
    "for k, v in pol_names_terms.items():\n",
    "    pol_names_terms2[(clean_text(k[0]), k[1])] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(title):\n",
    "    if not isinstance(title, str):\n",
    "        return ''\n",
    "    title = re.sub(r'\\(.*?\\)', '', title)\n",
    "    title = re.sub(r'[^a-zA-Z0-9\\s]', ' ', title)\n",
    "    title = re.sub(r'\\s+', ' ', title).strip()\n",
    "    return title.lower()\n",
    "\n",
    "lobbying['firm'] = lobbying['FIRM'].apply(text_clean)\n",
    "lob['firm'] = lob['FIRM'].apply(text_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Pre-Computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_dt(s):\n",
    "    return pd.to_datetime(s, errors='coerce')\n",
    "\n",
    "def _canon_name(n):\n",
    "    n = re.sub(r'[^\\w\\s]', ' ', str(n)).lower()\n",
    "    n = re.sub(r'\\s+', ' ', n).strip()\n",
    "    return n\n",
    "\n",
    "def _infer_origin_chamber_from_bill_id(bill_id):\n",
    "    s = str(bill_id)\n",
    "    if 'AB' in s: return 'assembly'\n",
    "    if 'SB' in s: return 'senate'\n",
    "    return None\n",
    "\n",
    "def _term_from_date(ts):\n",
    "    if pd.isna(ts): return np.nan\n",
    "    y = ts.year\n",
    "    if y % 2 == 1:\n",
    "        return f\"{y}-{y+1}\"\n",
    "    else:\n",
    "        if ts.month < 11:\n",
    "            return f\"{y-1}-{y}\"\n",
    "        return f\"{y+1}-{y+2}\"\n",
    "\n",
    "def _tokenize(s):\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r'[^a-z0-9\\s]', ' ', s)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return [t for t in s.split(' ') if t]\n",
    "\n",
    "def _jaccard(a_set, b_set):\n",
    "    if not a_set and not b_set: return 1.0\n",
    "    i = len(a_set & b_set)\n",
    "    u = len(a_set | b_set)\n",
    "    return i / u if u else 0.0\n",
    "\n",
    "def read_zip(zip_path, crs=3857):\n",
    "    tmp = tempfile.TemporaryDirectory()\n",
    "    with zipfile.ZipFile(zip_path) as zf:\n",
    "        zf.extractall(tmp.name)\n",
    "    shp = next(pathlib.Path(tmp.name).rglob(\"*.shp\"))\n",
    "    gdf = gpd.read_file(shp).set_crs(epsg=crs)\n",
    "    gdf = gdf.to_crs(epsg=3857)\n",
    "    return gdf, tmp\n",
    "\n",
    "def district_cycle(year):\n",
    "    if year <= 2012: return \"2001\"\n",
    "    if year <= 2022: return \"2011\"\n",
    "    return \"current\"\n",
    "\n",
    "\n",
    "populations = pd.read_csv('E-4_2010-2020-Internet-Version.csv', skiprows=1).iloc[:, :12]\n",
    "for c in populations.columns:\n",
    "    populations[c] = populations[c].astype(str)\n",
    "\n",
    "for c in populations.iloc[:, 1:].columns:\n",
    "    populations[c] = populations[c].apply(lambda x: re.sub(r'[^0-9]', '', x)).astype(int)\n",
    "\n",
    "pops = {}\n",
    "for _, row in populations.iterrows():\n",
    "    county = f'{row[\"COUNTY\"].strip()} County'\n",
    "    pops[county] = np.mean(row.iloc[1:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties_gdf, _ = read_zip('dashboard/backend/ca_counties.zip')\n",
    "counties_gdf = counties_gdf[['COUNTYFP', 'NAMELSAD', 'geometry']]\n",
    "counties_gdf['county_area_m2'] = counties_gdf.geometry.area\n",
    "counties_gdf['county_id'] = counties_gdf['COUNTYFP'].astype(int)\n",
    "counties_gdf['population'] = counties_gdf['NAMELSAD'].map(pops).astype('float64')\n",
    "counties_gdf['pop_density_per_m2'] = counties_gdf['population'] / counties_gdf['county_area_m2']\n",
    "data_dir = pathlib.Path('dashboard/backend')\n",
    "asm11_zip = data_dir / '2011_assembly_state_shp.zip'\n",
    "sen11_zip = data_dir / '2011_senate_state_shp.zip'\n",
    "asmcur_zip = data_dir / '2021_AD_Final_shp.zip'\n",
    "sencur_zip = data_dir / '2021_SD_Final_shp.zip'\n",
    "dist_info = [(asm11_zip, \"assembly\", \"2011\", 4019),(sen11_zip, \"senate\", \"2011\", 4019),(asmcur_zip, \"assembly\",\"current\", 4269),(sencur_zip, \"senate\",  \"current\", 4269)]\n",
    "weight_records = []\n",
    "tmps = []\n",
    "for zp, house, cycle, crs in dist_info:\n",
    "    gdf, tmp = read_zip(zp, crs)\n",
    "    tmps.append(tmp)\n",
    "    gdf = gdf.rename(columns={gdf.columns[0]: \"district_id\"})[[\"district_id\", \"geometry\"]]\n",
    "    gdf[\"house\"] = house\n",
    "    gdf[\"cycle\"] = cycle\n",
    "    gdf = gdf.to_crs(3857)\n",
    "    gdf['dist_area_m2'] = gdf.geometry.area\n",
    "    inter = gpd.overlay(gdf, counties_gdf, how=\"intersection\")\n",
    "    inter = inter[['house', 'cycle', 'district_id', 'COUNTYFP', 'NAMELSAD', 'geometry', 'dist_area_m2', 'county_area_m2', 'population', 'pop_density_per_m2']]\n",
    "    inter['fragment_area_m2'] = inter.geometry.area\n",
    "    inter['est_overlay_pop'] = inter['pop_density_per_m2'] * inter[\"fragment_area_m2\"]\n",
    "\n",
    "    inter[\"pop_denominator\"] = inter.groupby([\"house\",\"cycle\",\"district_id\"])[\"est_overlay_pop\"].transform(\"sum\")\n",
    "\n",
    "    inter[\"area_denominator\"] = inter.groupby([\"house\",\"cycle\",\"district_id\"])[\"fragment_area_m2\"].transform(\"sum\")\n",
    "    inter[\"w_area\"] = np.where(inter[\"area_denominator\"] > 0,\n",
    "                               inter[\"fragment_area_m2\"] / inter[\"area_denominator\"],\n",
    "                               np.nan)\n",
    "\n",
    "    inter[\"w_pop\"] = inter[\"est_overlay_pop\"] / inter[\"pop_denominator\"]\n",
    "    bad = ~np.isfinite(inter[\"w_pop\"]) | (inter[\"w_pop\"] < 0)\n",
    "    inter.loc[bad, \"w_pop\"] = inter.loc[bad, \"w_area\"]\n",
    "    inter[\"district_share_in_county_area\"] = inter[\"fragment_area_m2\"] / inter[\"dist_area_m2\"]\n",
    "    inter[\"district_share_in_county_pop\"] = inter[\"w_pop\"]\n",
    "\n",
    "    weight_records.append(\n",
    "        inter[[\n",
    "            \"house\",\"cycle\",\"district_id\",\"COUNTYFP\",\"NAMELSAD\",\n",
    "            \"fragment_area_m2\",\"dist_area_m2\",\"county_area_m2\",\n",
    "            \"population\",\"pop_density_per_m2\",\"est_overlay_pop\",\n",
    "            \"w_pop\",\"w_area\",\"district_share_in_county_pop\",\"district_share_in_county_area\"\n",
    "        ]].reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "weights = pd.concat(weight_records, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_events = voting.merge(politicians[['Party', 'Term', 'Last', 'clean_full_name', \"chamber\"]], left_on=['legislator_name', 'chamber', 'term'], right_on=['Last', 'chamber', 'Term'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_events = vote_events[['Date', 'bill_ID', 'bv_id', 'chamber', 'term', 'voting_place', 'Party', 'clean_full_name', \"vote_code\", \"motion_id\", \"location_code\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_map = {\n",
    "    \"AYE\": 1, \"YES\": 1, 1: 1,\n",
    "    \"NO\": 0, 0: 0\n",
    "}\n",
    "\n",
    "vote_events['vote'] = vote_events['vote_code'].map(vote_map)\n",
    "vote_events = vote_events.dropna(subset='vote')\n",
    "vote_events['vote'] = vote_events['vote'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_topic = pd.read_parquet('dashboard/backend/data/outs/actor_topic.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "po = politicians[['Party', 'District No.', 'Term', 'Last', 'full_name', 'chamber', 'clean_full_name']].drop_duplicates().rename(columns={'Term': 'term'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lob_name_fix(row):\n",
    "    if (row['clean_beneficiary'], row['term']) in pol_names_terms.keys():\n",
    "        return pol_names_terms.get((row['clean_beneficiary'], row['term'])).get('name')\n",
    "    elif (row['clean_beneficiary'], row['term']) in pol_names_terms2.keys():\n",
    "        return pol_names_terms2.get((row['clean_beneficiary'], row['term'])).get('name')\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "lob['clean_full_name'] = lob.apply(lob_name_fix, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo = lob.merge(po, on=['clean_full_name', 'term'])[['firm', 'BENE_AMT', 'term', 'Party', 'chamber', 'full_name', 'District No.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "do = campaign_contributions.merge(po, left_on=['matched_target_name', 'Term'], right_on=['full_name', 'term'])[['Expender', 'Amount', 'Term', 'Party', 'chamber_x', 'full_name', 'District No.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [do, lo]:\n",
    "    t.columns = ['Firm', 'Amount', 'Term', 'Party', 'Chamber', 'full_name', 'District']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "funding = pd.concat([\n",
    "    do.assign(kind=\"donation\"),\n",
    "    lo.assign(kind=\"lobbying\")\n",
    "], ignore_index=True)\n",
    "\n",
    "funding[\"Amount\"] = funding[\"Amount\"].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "funding.columns = ['Firm', 'amount', 'term', 'party', 'house', 'full_name', 'district_id', 'kind']\n",
    "funding['year'] = funding['term'].apply(lambda x: int(x.split('-')[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "funding['cycle'] = funding['year'].apply(district_cycle)\n",
    "funding['district_id'] = funding['district_id'].apply(lambda x: re.sub(r'\\s+', '', str(x))).astype(float)\n",
    "\n",
    "funding['district_id'] = funding['district_id'].astype(int)\n",
    "funding['cycle'] = funding['cycle'].apply(lambda x: x if x == 'current' else '2011')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "funding_w = funding.merge(\n",
    "    weights,\n",
    "    on=[\"house\",\"cycle\",\"district_id\"],\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_many\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "funding_w[\"county_amount\"] = (\n",
    "    funding_w[\"amount\"] * funding_w[\"district_share_in_county_pop\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_funding = (\n",
    "    funding_w\n",
    "    .groupby([\"COUNTYFP\",\"NAMELSAD\"], as_index=False)\n",
    "    .agg(total_amount=(\"county_amount\",\"sum\"))\n",
    "    .rename(columns={\"COUNTYFP\":\"county_id\",\"NAMELSAD\":\"county_name\"})\n",
    ")\n",
    "\n",
    "county_funding[\"county_id\"] = county_funding[\"county_id\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_funders = (\n",
    "    funding_w\n",
    "    .groupby(\n",
    "        [\"COUNTYFP\",\"NAMELSAD\",\"Firm\"],\n",
    "        as_index=False\n",
    "    )\n",
    "    .agg(total_amount=(\"county_amount\",\"sum\"))\n",
    "    .rename(columns={\n",
    "        \"COUNTYFP\":\"county_id\",\n",
    "        \"NAMELSAD\":\"county_name\",\n",
    "        \"Firm\":\"funder\"\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_term_funding = funding_w.groupby(['NAMELSAD', 'term'], as_index=False).agg(total_amount=('county_amount', \"sum\")).rename(columns={\"COUNTYFP\":\"county_id\", \"NAMELSAD\":\"county_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('node_id_map.json', 'r') as f:\n",
    "    node_id_map = json.load(f)\n",
    "\n",
    "legislators = pickle.load(open('legislators.pkl', 'rb'))\n",
    "committees = pickle.load(open('committees.pkl', 'rb'))\n",
    "\n",
    "node_ids = {}\n",
    "for k in node_id_map.keys():\n",
    "    node_ids[k] = {v: i for i, v in node_id_map[k].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_from_id(row):\n",
    "    node_id, node_type = row\n",
    "    if node_type in ['donor', 'lobby_firm']:\n",
    "        return node_ids[node_type].get(node_id)\n",
    "    mapped = node_ids.get(node_type, {}).get(node_id)\n",
    "    if not mapped:\n",
    "        return None\n",
    "    num = int(mapped.split(\"_\")[0])\n",
    "    if node_type == 'committee':\n",
    "        return committees.get(num)\n",
    "    return legislators.get(num)\n",
    "\n",
    "actor_topic['name'] = actor_topic[['actor_index', 'actor_type']].apply(name_from_id, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('subject_key.json', 'r') as f:\n",
    "    subject_key = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/jkjxx5pj447bytbqv8pkw9nh0000gn/T/ipykernel_60172/2064526979.py:80: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(pack_topics)\n"
     ]
    }
   ],
   "source": [
    "funder_topics = (\n",
    "    actor_topic\n",
    "    .loc[actor_topic['actor_type'].isin(['donor', 'lobby_firm'])]\n",
    "    .assign(\n",
    "        actor_name=lambda d: d['name'].str.strip()\n",
    "    )\n",
    "    [['actor_name', 'topic_id', 'stance']]\n",
    "    .dropna(subset=['actor_name', 'topic_id', 'stance'])\n",
    "    .groupby(['actor_name', 'topic_id'], as_index=False)\n",
    "    .agg(stance=('stance', 'mean'))\n",
    ")\n",
    "\n",
    "county_funder_topics = (\n",
    "    county_funders\n",
    "    .merge(\n",
    "        funder_topics,\n",
    "        left_on='funder',\n",
    "        right_on='actor_name',\n",
    "        how='left'\n",
    "    )\n",
    "    .drop(columns='actor_name')\n",
    "    .dropna(subset=['topic_id', 'stance'])\n",
    ")\n",
    "\n",
    "county_funder_topics['abs_weight'] = county_funder_topics['total_amount'] * county_funder_topics['stance'].abs()\n",
    "county_funder_topics['signed_weight'] = county_funder_topics['total_amount'] * county_funder_topics['stance']\n",
    "\n",
    "county_funder_topics = county_funder_topics.assign(\n",
    "    abs_weight = county_funder_topics['total_amount'] * county_funder_topics['stance'].abs(),\n",
    "    signed_weight = county_funder_topics['total_amount'] * county_funder_topics['stance']\n",
    ")\n",
    "\n",
    "def top_topics(df, sign, n=3):\n",
    "    d = df.loc[(df['stance'] > 0) if sign == 'support' else (df['stance'] < 0)]\n",
    "    return (\n",
    "        d.sort_values('abs_weight', ascending=False)\n",
    "         .groupby(['county_id', 'funder'], as_index=False)\n",
    "         .head(n)\n",
    "         .assign(position=sign)\n",
    "    )\n",
    "\n",
    "top_support = top_topics(county_funder_topics, 'support', n=3)\n",
    "top_oppose = top_topics(county_funder_topics, 'oppose', n=3)\n",
    "topics_long = pd.concat([top_support, top_oppose], ignore_index=True)\n",
    "\n",
    "topics_long['topic'] = (\n",
    "    topics_long['topic_id']\n",
    "    .astype(int)\n",
    "    .astype(str)\n",
    "    .map(subject_key)\n",
    ")\n",
    "\n",
    "def pack_topics(df):\n",
    "    support = (\n",
    "        df.loc[df['position'] == 'support']\n",
    "          .sort_values('abs_weight', ascending=False)\n",
    "          ['topic']\n",
    "          .tolist()\n",
    "    )\n",
    "\n",
    "    oppose = (\n",
    "        df.loc[df['position'] == 'oppose']\n",
    "          .sort_values('abs_weight', ascending=False)\n",
    "          ['topic']\n",
    "          .tolist()\n",
    "    )\n",
    "\n",
    "    return pd.Series({\n",
    "        'top_supported_topics': support,\n",
    "        'top_opposed_topics': oppose\n",
    "    })\n",
    "\n",
    "\n",
    "county_top_funders = (\n",
    "    topics_long\n",
    "    .groupby(\n",
    "        ['county_id', 'county_name', 'funder', 'total_amount'],\n",
    "        as_index=False\n",
    "    )\n",
    "    .apply(pack_topics)\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_top_funders = (\n",
    "    county_top_funders\n",
    "    .assign(\n",
    "        rank_in_county=lambda d: (\n",
    "            d.groupby('county_id')['total_amount']\n",
    "             .rank(method='dense', ascending=False)\n",
    "        )\n",
    "    )\n",
    "    .loc[lambda d: d['rank_in_county'] <= 5]\n",
    "    .sort_values(['county_id', 'rank_in_county'])\n",
    "    .drop(columns='rank_in_county')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_top_funders = county_top_funders[['county_id', 'county_name', 'funder', 'total_amount', 'top_supported_topics','top_opposed_topics'\n",
    "]]\n",
    "\n",
    "county_top_funders['top_opposed_topics'] = county_top_funders['top_opposed_topics'].apply(lambda x: \" / \".join(x))\n",
    "county_top_funders['top_supported_topics'] = county_top_funders['top_supported_topics'].apply(lambda x: \" / \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "firm_totals = {row['Firm']: row['amount'] for _, row in funding_w[['Firm', 'amount', 'term', 'NAMELSAD', 'full_name']].drop_duplicates().groupby('Firm')['amount'].sum().reset_index().iterrows()}\n",
    "county_top_funders['firm_total'] = county_top_funders['funder'].map(firm_totals)\n",
    "county_top_funders['region_concentration'] = county_top_funders['total_amount'] / county_top_funders['firm_total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power & Influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "legislator_funding = (\n",
    "    funding\n",
    "    .groupby(\n",
    "        ['full_name', 'term', 'house', 'party', 'kind'],\n",
    "        as_index=False\n",
    "    )\n",
    "    .agg(amount=('amount', 'sum'))\n",
    "    .pivot_table(\n",
    "        index=['full_name', 'term', 'house', 'party'],\n",
    "        columns='kind',\n",
    "        values='amount',\n",
    "        fill_value=0\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "legislator_funding.columns.name = None\n",
    "legislator_funding = legislator_funding.rename(\n",
    "    columns={'donation': 'donations', 'lobbying': 'lobbying'}\n",
    ")\n",
    "\n",
    "legislator_funding['total_funding'] = (\n",
    "    legislator_funding['donations'] + legislator_funding['lobbying']\n",
    ")\n",
    "\n",
    "legislator_funding['funding_pct_overall'] = (\n",
    "    legislator_funding\n",
    "    .groupby('term')['total_funding']\n",
    "    .rank(pct=True)\n",
    ")\n",
    "\n",
    "legislator_funding['funding_pct_house'] = (\n",
    "    legislator_funding\n",
    "    .groupby(['term', 'house'])['total_funding']\n",
    "    .rank(pct=True)\n",
    ")\n",
    "\n",
    "legislator_funding['funding_rank_house'] = (\n",
    "    legislator_funding\n",
    "    .groupby(['term', 'house'])['total_funding']\n",
    "    .rank(method='dense', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "legislator_funding['funding_tier'] = pd.cut(\n",
    "    legislator_funding['funding_pct_overall'],\n",
    "    bins=[0, 0.5, 0.9, 0.97, 1.0],\n",
    "    labels=['Low', 'Medium', 'High', 'Very High']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_topics = actor_topic.loc[actor_topic['actor_type'] == 'legislator_term']\n",
    "leg_topics['term'] = leg_topics['actor_index'].apply(lambda x: node_ids['legislator_term'].get(x).split('_')[1])\n",
    "leg_topics = leg_topics.dropna(subset=['name', 'topic_id', 'stance'])[['name', 'term', 'topic_id', 'stance', \"influence\"]].groupby(['name', 'term', 'topic_id'], as_index=False).agg(stance=('stance', 'mean'), influence=(\"influence\", \"mean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/jkjxx5pj447bytbqv8pkw9nh0000gn/T/ipykernel_60172/3369996702.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(pack_focus_topics)\n"
     ]
    }
   ],
   "source": [
    "def pack_focus_topics(df, n=5):\n",
    "    df = df.assign(abs_i=df['stance'].abs())\n",
    "\n",
    "    top_topics = (\n",
    "        df.sort_values('abs_i', ascending=False)\n",
    "          .head(n)['topic_id']\n",
    "          .astype(int)\n",
    "          .tolist()\n",
    "    )\n",
    "\n",
    "    return pd.Series({\n",
    "        'top_topics': top_topics,\n",
    "        'topic_concentration': df['abs_i'].sum()\n",
    "    })\n",
    "\n",
    "leg_topic_summary = (\n",
    "    leg_topics\n",
    "    .groupby(['name', 'term'])\n",
    "    .apply(pack_focus_topics)\n",
    "    .reset_index()\n",
    "    .rename(columns={'name': 'full_name'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_components = (\n",
    "    leg_topics\n",
    "    .assign(abs_impact=lambda d: d['influence'].abs())\n",
    "    .groupby(['name', 'term'], as_index=False)\n",
    "    .agg(\n",
    "        influence_l1=('abs_impact', 'sum'),\n",
    "        influence_l2=('abs_impact', lambda x: np.sqrt((x**2).sum())),\n",
    "        n_topics=('topic_id', 'nunique')\n",
    "    )\n",
    ")\n",
    "\n",
    "overall_components['overall_influence'] = (\n",
    "    overall_components['influence_l1'] *\n",
    "    np.log1p(overall_components['n_topics'])\n",
    ")\n",
    "\n",
    "overall_components['overall_influence_z'] = (\n",
    "    overall_components\n",
    "    .groupby('term')['overall_influence']\n",
    "    .transform(lambda x: (x - x.mean()) / x.std())\n",
    ")\n",
    "\n",
    "overall_components = overall_components.rename(columns={'name': 'full_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "legislator_power = (\n",
    "    legislator_funding\n",
    "    .merge(leg_topic_summary, on=['full_name', 'term'], how='left')\n",
    "    .merge(\n",
    "        overall_components[\n",
    "            ['full_name', 'term', 'overall_influence', 'overall_influence_z',\n",
    "             'influence_l1', 'influence_l2', 'n_topics']\n",
    "        ],\n",
    "        on=['full_name', 'term'],\n",
    "        how='left'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "legislator_power['influence_tier'] = pd.cut(\n",
    "    legislator_power['overall_influence_z'],\n",
    "    bins=[-np.inf, -1, 0, 1, np.inf],\n",
    "    labels=['Low', 'Below Avg', 'Above Avg', 'High']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "legislator_power['name'] = legislator_power['full_name'].apply(lambda x: x.split(',')[1].strip() + ' ' + x.split(',')[0].strip() if ',' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_events['motion'] = vote_events['motion_id'].map(motion_codes)\n",
    "\n",
    "leg_votes = (\n",
    "    vote_events\n",
    "    .dropna(subset=['clean_full_name', 'vote'])\n",
    "    .rename(columns={'clean_full_name': 'full_name'})\n",
    ")\n",
    "\n",
    "yes_rate = (\n",
    "    leg_votes\n",
    "    .groupby(['full_name', 'term'], as_index=False)\n",
    "    .agg(yes_rate=('vote', 'mean'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRICTION = {\n",
    "    'Concurrence',\n",
    "    'Reconsideration',\n",
    "    'Urgency Clause',\n",
    "    'Placed on Appropriations Suspense File',\n",
    "    'W/O REF. TO FILE'\n",
    "}\n",
    "\n",
    "leg_votes['procedural'] = leg_votes['motion'].isin(FRICTION)\n",
    "\n",
    "procedural_exposure = (\n",
    "    leg_votes\n",
    "    .groupby(['full_name', 'term'], as_index=False)\n",
    "    .agg(procedural_exposure=('procedural', 'mean'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_votes = leg_votes.merge(\n",
    "    yes_rate[['full_name', 'term', 'yes_rate']],\n",
    "    on=['full_name', 'term'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "leg_votes['vote_deviation'] = (leg_votes['vote'] - leg_votes['yes_rate']).abs()\n",
    "\n",
    "vote_volatility = (\n",
    "    leg_votes\n",
    "    .groupby(['full_name', 'term'], as_index=False)\n",
    "    .agg(vote_volatility=('vote_deviation', 'mean'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_votes['is_floor'] = leg_votes['location_code'].isin(['AFLOOR', 'SFLOOR'])\n",
    "\n",
    "procedural_leverage = (\n",
    "    leg_votes\n",
    "    .groupby(['full_name', 'term'], as_index=False)\n",
    "    .agg(procedural_leverage=('is_floor', lambda x: 1 - x.mean()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "legislator_behavior = (\n",
    "    yes_rate\n",
    "    .merge(procedural_exposure, on=['full_name', 'term'], how='left')\n",
    "    .merge(vote_volatility, on=['full_name', 'term'], how='left')\n",
    "    .merge(procedural_leverage, on=['full_name', 'term'], how='left')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bills Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "pols = politicians[['chamber', 'Term', 'Party', \"full_name\"]].drop_duplicates().pivot_table(index='Term', columns='Party', aggfunc='count').iloc[:, :3]\n",
    "pols.columns = ['D', 'I', 'R']\n",
    "pols['I'] = pols['I'].fillna(0)\n",
    "pols = pols.reset_index().drop(columns='I')\n",
    "pols['p_D'] = pols['D'] / (pols['D'] + pols['R'])\n",
    "pols['p_R'] = pols['R'] / (pols['D'] + pols['R'])\n",
    "\n",
    "bill_events = pd.DataFrame.from_dict({\n",
    "    \"bill_ID\": vote_events['bill_ID'].drop_duplicates().values,\n",
    "    'First': vote_events['bill_ID'].drop_duplicates().apply(lambda x: min(introduction_dates.get(x)['Dates'])).values,\n",
    "    \"Last\": vote_events['bill_ID'].drop_duplicates().apply(lambda x: max(introduction_dates.get(x)['Dates'])).values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_rows(row):\n",
    "    last = row['legislator_name'].strip().lower()\n",
    "    legislator = legislators_last_names.get((row['chamber'].lower(), last, row['term']), None)\n",
    "    if legislator is None:\n",
    "        if len(last.split(' ')) > 1:\n",
    "            legislator = row['legislator_name']\n",
    "    return legislator\n",
    "\n",
    "voting['full_name'] = voting.apply(voting_rows, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "vot = voting.merge(politicians[['chamber','Party', \"full_name\"]].drop_duplicates(), on=['chamber', 'full_name'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "vt = vot.groupby(['bill_ID', 'Party'])['vote_code'].apply(lambda x: (x == 'AYE').mean()).unstack()\n",
    "bill_polarization = (vt[\"D\"] - vt[\"R\"]).abs().rename(\"polarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "ve = vote_events.copy()\n",
    "ve['comb'] = ve['Date'].astype(str) + \".\" + ve['voting_place']\n",
    "vote_num = ve.groupby(['bill_ID', 'bv_id'])['comb'].nunique().sort_values(ascending=False).reset_index()\n",
    "n_versions = ve.groupby('bill_ID')['bv_id'].nunique().reset_index()\n",
    "yes_rate = ve.groupby(['bill_ID', 'term'])['vote'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_rate['p_D'] = yes_rate['term'].map({row['Term']: row['p_D'] for _, row in pols[['Term', 'p_D']].drop_duplicates().iterrows()})\n",
    "yes_rate['vote_deviation'] = (yes_rate['vote'] - yes_rate['p_D']).abs()\n",
    "yes_rate = yes_rate.merge(vote_num, on='bill_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('data5.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type = ('legislator_term', 'voted_on', 'bill_version')\n",
    "store = data[edge_type]\n",
    "\n",
    "src, dst = store.edge_index\n",
    "edge_attr = store.edge_attr\n",
    "vote_idx = -1\n",
    "votes = edge_attr[:, vote_idx].float()\n",
    "votes = (votes > 0).float()\n",
    "bv_to_bill = vid_map\n",
    "bill_ids = [bv_to_bill.get(node_ids['bill_version'].get(int(bv))) for bv in dst.cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_df = pd.DataFrame({\n",
    "    'bill_ID': bill_ids,\n",
    "    'vote': votes.cpu().numpy()\n",
    "}).dropna(subset=['bill_ID'])\n",
    "\n",
    "bill_yes_rate = (\n",
    "    vote_df\n",
    "    .groupby('bill_ID', as_index=False)\n",
    "    .agg(\n",
    "        yes_rate=('vote', 'mean'),\n",
    "        n_votes=('vote', 'size')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_stats = (\n",
    "    bill_yes_rate.merge(yes_rate, on='bill_ID', how='left')\n",
    "    .merge(n_versions, on='bill_ID', how='left')\n",
    "    .merge(bill_events, on='bill_ID', how='left')\n",
    "    .merge(vote_num, on='bill_ID', how='left')\n",
    "    .merge(bill_polarization, on='bill_ID', how='left')\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "bill_stats['vote_deviation'] = (bill_stats['yes_rate'] - bill_stats['p_D']).abs()\n",
    "\n",
    "bill_stats['lifespan_days'] = (\n",
    "    bill_stats['Last'] - bill_stats['First']\n",
    ").dt.days.clip(lower=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_stats['n_dem'] = bill_stats['term'].map({row['Term']: row['D'] for _, row in pols[['Term', 'D']].drop_duplicates().iterrows()})\n",
    "bill_stats['n_rep'] = bill_stats['term'].map({row['Term']: row['R'] for _, row in pols[['Term', 'R']].drop_duplicates().iterrows()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_stats[\"balance_factor\"] = np.sqrt((bill_stats[\"n_dem\"] * bill_stats[\"n_rep\"]) /(bill_stats[\"n_dem\"] + bill_stats[\"n_rep\"])**2)\n",
    "\n",
    "bill_stats[\"polarization_adj\"] = (bill_stats[\"polarization\"] * bill_stats[\"balance_factor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_stats['yes_uncertainty'] = (\n",
    "    1 - (bill_stats['yes_rate'] - 0.5).abs() * 2\n",
    ")\n",
    "\n",
    "ALPHA = 0.7\n",
    "\n",
    "bill_stats['contention'] = (\n",
    "    ALPHA * bill_stats['vote_deviation']\n",
    "    + (1 - ALPHA) * bill_stats['yes_uncertainty']\n",
    ")\n",
    "\n",
    "bill_stats['procedural_intensity'] = (\n",
    "    bill_stats['comb_x']\n",
    "    * bill_stats['bv_id_y']\n",
    "    * np.log1p(bill_stats['lifespan_days'])\n",
    ")\n",
    "\n",
    "bill_stats['controversy'] = (\n",
    "    (bill_stats['polarization']\n",
    "    * bill_stats['contention'])\n",
    "    * np.log1p(bill_stats['procedural_intensity'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bill_labels.json', 'r') as f:\n",
    "    bill_labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_stats['topic'] = bill_stats['bill_ID'].map(bill_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_outcomes = pickle.load(open(\"bill_outcomes.pkl\", \"rb\"))\n",
    "bill_stats['outcome'] = bill_stats['bill_ID'].map(bill_outcomes).fillna(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_names = politicians[['Term', 'Last', 'full_name', 'chamber', 'clean_full_name']].drop_duplicates()\n",
    "\n",
    "def strip_accents(text):\n",
    "    try:\n",
    "        text = str(text)\n",
    "    except NameError:\n",
    "        pass\n",
    "    normalized_text = unicodedata.normalize('NFD', text)\n",
    "    stripped_text = \"\".join(\n",
    "        c for c in normalized_text if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "    return str(stripped_text)\n",
    "\n",
    "def fix_sponsors(row):\n",
    "    if row['full_name'] != np.nan:\n",
    "        return row['full_name']\n",
    "    elif '-' in row['Name']:\n",
    "        name = re.sub(r'-', ' ', row['Name'])\n",
    "        full = pol_names.loc[pol_names['Last'] == name, 'full_name'].values[0]\n",
    "        return full\n",
    "    else:\n",
    "        name = strip_accents(row['Name'])\n",
    "        print(name)\n",
    "        full = pol_names.loc[pol_names['clean_full_name'] == name, 'full_name'].values[0]\n",
    "        return full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "sponsors['name'] = sponsors.apply(fix_sponsors, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "sponsors['bill'] = sponsors['bill_ID'].map(bv_to_bill)\n",
    "bill_authors = sponsors.loc[sponsors['full_name'].notna()].groupby('bill').agg({'full_name': lambda x: list(set(x))}).reset_index()\n",
    "\n",
    "def reverse_names(name_list):\n",
    "    hold = []\n",
    "    for n in name_list:\n",
    "        if ',' in n:\n",
    "            hold.append(n.split(',')[1] + ' ' + n.split(',')[0])\n",
    "        else:\n",
    "            hold.append(n.split(' ')[1] + ' ' + n.split(' ')[0])\n",
    "    return \", \".join(hold)\n",
    "bill_authors['Name'] = bill_authors['full_name'].apply(reverse_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_authors = bill_authors.rename(columns={'bill': 'bill_ID'})\n",
    "bill_stats = bill_stats.merge(bill_authors[['bill_ID', 'Name']], on='bill_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_stats['Subject'] = bill_stats['bill_ID'].map(bill_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_embeddings = torch.load('subject_embeddings.pt')\n",
    "subject_embeddings = {k: v.cpu().numpy().tolist() for k, v in subject_embeddings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_stats['embeddings'] = bill_stats['Subject'].apply(text_clean).map(subject_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_tokens(s):\n",
    "    if not isinstance(s, str):\n",
    "        return []\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[^\\w\\s]', ' ', s)\n",
    "    return list(set(s.split()))\n",
    "\n",
    "bill_stats['author_tokens'] = bill_stats['Name'].apply(author_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_stats['term'] = bill_stats['bill_ID'].apply(lambda x: f\"{x[:4]}-{x[4:8]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['controversy', 'procedural_intensity', 'n_votes', 'lifespan_days', 'contention']:\n",
    "    bill_stats[f'{col}_z'] = (\n",
    "        bill_stats\n",
    "        .groupby('term')[col]\n",
    "        .transform(lambda x: (x - x.mean()) / x.std())\n",
    "    )\n",
    "\n",
    "bill_stats[\"combined_index\"] = (\n",
    "    0.3 * bill_stats[\"procedural_intensity_z\"]\n",
    "  + 0.4 * bill_stats[\"controversy_z\"]\n",
    "  + 0.3 * bill_stats[\"contention_z\"]\n",
    ")\n",
    "\n",
    "bill_stats['controversy_pct'] = (\n",
    "    bill_stats\n",
    "    .groupby('term')['controversy_z']\n",
    "    .rank(pct=True) * 100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_topic_stats = bill_stats.copy()\n",
    "\n",
    "bill_topic_stats['term'] = bill_topic_stats['bill_ID'].apply(lambda x: f\"{x[:4]}-{x[4:8]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_term_sum = (\n",
    "    bill_topic_stats\n",
    "    .groupby(['topic', 'term'], as_index=False)\n",
    "    .agg(\n",
    "        n_bills=('bill_ID', 'nunique'),\n",
    "        avg_controversy=('controversy', 'mean'),\n",
    "        total_votes=('n_votes', 'sum'),\n",
    "        total_versions=('bv_id_y', 'sum'),\n",
    "        avg_lifespan_days=('lifespan_days', 'mean'),\n",
    "        pass_rate=('outcome', lambda x: (x == 1).mean())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_topics['abs_impact'] = leg_topics['stance'].abs()\n",
    "leg_topics['abs_denom'] = leg_topics.groupby(['name', 'term'])['abs_impact'].transform('sum')\n",
    "leg_topics = leg_topics.loc[leg_topics['abs_denom'] > 0].copy()\n",
    "\n",
    "leg_topics['w_abs'] = leg_topics['abs_impact'] / leg_topics['abs_denom']\n",
    "\n",
    "leg_topics['w_signed'] = leg_topics['stance'] / leg_topics['abs_denom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "funding_alloc = (\n",
    "    funding\n",
    "    .merge(leg_topics, left_on=['full_name', 'term'], right_on=['name', 'term'], how='left', validate='many_to_many')\n",
    "    .dropna(subset=['topic_id', 'stance', 'w_abs'])\n",
    "    .assign(\n",
    "        topic_amount=lambda d: d['amount'] * d['w_abs'],\n",
    "        topic_amount_signed=lambda d: d['amount'] * d['w_signed']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_term_funding = (\n",
    "    funding_alloc\n",
    "    .groupby(['term', 'topic_id'], as_index=False)\n",
    "    .agg(\n",
    "        topic_amount=('topic_amount', 'sum'),\n",
    "        topic_amount_signed=('topic_amount_signed', 'sum'),\n",
    "        n_edges=('amount', 'size'),\n",
    "        n_funders=('Firm', 'nunique'),\n",
    "        n_recipients=('full_name', 'nunique')\n",
    "    )\n",
    ")\n",
    "\n",
    "topic_term_funding['topic'] = (\n",
    "    topic_term_funding['topic_id']\n",
    "    .astype(int).astype(str)\n",
    "    .map(subject_key)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_term_summa = topic_term_sum.merge(\n",
    "    topic_term_funding,\n",
    "    on=['topic', 'term'],\n",
    "    how='left'\n",
    ").fillna({'total_topic_funding': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_ = topic_term_summa.copy().loc[topic_term_summa['term'].isin(['2023-2024', '2025-2026'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_term_sum(df, year_fix=True):\n",
    "    df['attention_score'] = (\n",
    "        df['n_bills']\n",
    "        * np.log1p(df['total_versions'])\n",
    "    )\n",
    "\n",
    "    df['controversy_rank'] = (\n",
    "        df\n",
    "        .groupby('term')['avg_controversy']\n",
    "        .rank(pct=True)\n",
    "    )\n",
    "\n",
    "    df['funding_rank'] = (\n",
    "        df\n",
    "        .groupby('term')['topic_amount']\n",
    "        .rank(pct=True)\n",
    "    )\n",
    "    df = df.sort_values(['topic', 'term'])\n",
    "\n",
    "    df['delta_controversy'] = (\n",
    "        df\n",
    "        .groupby('topic')['avg_controversy']\n",
    "        .diff()\n",
    "    )\n",
    "\n",
    "    df['delta_funding'] = (\n",
    "        df\n",
    "        .groupby('topic')['topic_amount']\n",
    "        .diff()\n",
    "    )\n",
    "\n",
    "    df['delta_pass_rate'] = (\n",
    "        df\n",
    "        .groupby('topic')['pass_rate']\n",
    "        .diff()\n",
    "    )\n",
    "    df['quadrant'] = np.select(\n",
    "        [\n",
    "            (df['controversy_rank'] > 0.75)\n",
    "            & (df['funding_rank'] > 0.75),\n",
    "\n",
    "            (df['controversy_rank'] < 0.25)\n",
    "            & (df['funding_rank'] > 0.75)\n",
    "            & (df['pass_rate'] > 0.7)\n",
    "        ],\n",
    "        [\n",
    "            'High Controversy / High Funding',\n",
    "            'Low Controversy / High Funding / High Success'\n",
    "        ],\n",
    "        default='Other'\n",
    "    )\n",
    "\n",
    "    if year_fix:\n",
    "        df['year'] = df['term'].apply(lambda x: int(x[:4]))\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/jkjxx5pj447bytbqv8pkw9nh0000gn/T/ipykernel_60172/398002544.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(\n"
     ]
    }
   ],
   "source": [
    "topic_polarization = (\n",
    "    bill_topic_stats\n",
    "    .groupby([\"topic\", \"term\"])\n",
    "    .apply(\n",
    "        lambda g: np.average(\n",
    "            g[\"polarization_adj\"],\n",
    "            weights=g[\"n_votes\"]\n",
    "        )\n",
    "    )\n",
    "    .rename(\"topic_polarization\")\n",
    "    .reset_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_term_summary = top_term_sum(topic_term_summa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhc = latest_.groupby('topic').agg(\n",
    "    topic_amount=('topic_amount', 'sum'),\n",
    "    n_bills=('n_bills', 'sum'),\n",
    "    avg_controversy=('avg_controversy', 'mean'),\n",
    "    total_versions=('total_versions', 'sum'),\n",
    "    pass_rate=('pass_rate', 'mean')\n",
    ")\n",
    "lhc['term'] = 'current'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_high_conflict = top_term_sum(lhc, year_fix=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_high_conflict = latest_high_conflict.loc[latest_high_conflict['quadrant'] == 'High Controversy / High Funding']\n",
    "\n",
    "latest_high_conflict = (\n",
    "    latest_high_conflict\n",
    "    .loc[:, [\n",
    "        'topic',\n",
    "        'topic_amount',\n",
    "        'funding_rank',\n",
    "        'avg_controversy',\n",
    "        'controversy_rank',\n",
    "        'pass_rate'\n",
    "    ]]\n",
    "    .rename(columns={\n",
    "        'topic': 'Topic',\n",
    "        'topic_amount': 'Total Funding',\n",
    "        'funding_rank': 'Funding Percentile',\n",
    "        'avg_controversy': 'Relative Controversy',\n",
    "        'controversy_rank': 'Controversy Percentile',\n",
    "        'pass_rate': 'Pass Rate'\n",
    "    })\n",
    ")\n",
    "\n",
    "latest_high_conflict = latest_high_conflict.assign(\n",
    "    **{\n",
    "        'Funding Percentile': latest_high_conflict['Funding Percentile'].round(2),\n",
    "        'Controversy Percentile': latest_high_conflict['Controversy Percentile'].round(2),\n",
    "        'Relative Controversy': latest_high_conflict['Relative Controversy'].round(2),\n",
    "        'Pass Rate': (latest_high_conflict['Pass Rate'] * 100).round(1)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_players = (\n",
    "    actor_topic\n",
    "    .loc[\n",
    "        actor_topic['actor_type'].isin([\n",
    "            'legislator_term',\n",
    "            'committee',\n",
    "            'donor',\n",
    "            'lobby_firm'\n",
    "        ])\n",
    "    ]\n",
    "    [['topic_id', 'actor_type', 'name', 'stance', \"influence\"]]\n",
    "    .dropna(subset=['name', 'stance', \"influence\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "topic_players[['Influence']] = PowerTransformer().fit_transform(topic_players[['influence']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_key_players = (\n",
    "    topic_players\n",
    "    .groupby(['topic_id', 'actor_type', 'name'], as_index=False)\n",
    "    .agg(\n",
    "        avg_impact=('Influence', 'mean'),\n",
    "        abs_impact=('Influence', lambda x: np.abs(x).mean())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_key_players['rank_in_topic'] = (\n",
    "    topic_key_players\n",
    "    .groupby(['topic_id', 'actor_type'])['abs_impact']\n",
    "    .rank(method='dense', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "funding['Name'] = funding['full_name'].apply(lambda n: n.split(',')[1] + ' ' + n.split(',')[0] if ',' in n else n.split(' ')[1] + ' ' + n.split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_term_summary = topic_term_summary.merge(topic_polarization, on=['topic', 'term'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `county_funding.parquet`\n",
    "- `county_top_funders`\n",
    "- `legislator_funding`\n",
    "- `legislator_power`\n",
    "- `legislator_behavior`\n",
    "- `bill_stats`\n",
    "- `topic_term_summary`\n",
    "- `funding`\n",
    "- `latest_high_conflict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "county_funding\n",
      "\n",
      "\n",
      "['county_id', 'county_name', 'total_amount']\n",
      "\n",
      "\n",
      "county_term_funding\n",
      "\n",
      "\n",
      "['county_name', 'term', 'total_amount']\n",
      "\n",
      "\n",
      "county_top_funders\n",
      "\n",
      "\n",
      "['county_id', 'county_name', 'funder', 'total_amount', 'top_supported_topics', 'top_opposed_topics', 'firm_total', 'region_concentration']\n",
      "\n",
      "\n",
      "legislator_funding\n",
      "\n",
      "\n",
      "['full_name', 'term', 'house', 'party', 'donations', 'lobbying', 'total_funding', 'funding_pct_overall', 'funding_pct_house', 'funding_rank_house', 'funding_tier']\n",
      "\n",
      "\n",
      "legislator_power\n",
      "\n",
      "\n",
      "['full_name', 'term', 'house', 'party', 'donations', 'lobbying', 'total_funding', 'funding_pct_overall', 'funding_pct_house', 'funding_rank_house', 'funding_tier', 'top_topics', 'topic_concentration', 'overall_influence', 'overall_influence_z', 'influence_l1', 'influence_l2', 'n_topics', 'influence_tier', 'name']\n",
      "\n",
      "\n",
      "legislator_behavior\n",
      "\n",
      "\n",
      "['full_name', 'term', 'yes_rate', 'procedural_exposure', 'vote_volatility', 'procedural_leverage']\n",
      "\n",
      "\n",
      "bill_stats\n",
      "\n",
      "\n",
      "['bill_ID', 'yes_rate', 'n_votes', 'term', 'vote', 'p_D', 'vote_deviation', 'bv_id_x', 'comb_x', 'bv_id_y', 'First', 'Last', 'bv_id', 'comb_y', 'polarization', 'lifespan_days', 'n_dem', 'n_rep', 'balance_factor', 'polarization_adj', 'yes_uncertainty', 'contention', 'procedural_intensity', 'controversy', 'topic', 'outcome', 'Name', 'Subject', 'embeddings', 'author_tokens', 'controversy_z', 'procedural_intensity_z', 'n_votes_z', 'lifespan_days_z', 'contention_z', 'combined_index', 'controversy_pct']\n",
      "\n",
      "\n",
      "topic_term_summary\n",
      "\n",
      "\n",
      "['topic', 'term', 'n_bills', 'avg_controversy', 'total_votes', 'total_versions', 'avg_lifespan_days', 'pass_rate', 'topic_id', 'topic_amount', 'topic_amount_signed', 'n_edges', 'n_funders', 'n_recipients', 'attention_score', 'controversy_rank', 'funding_rank', 'delta_controversy', 'delta_funding', 'delta_pass_rate', 'quadrant', 'year', 'topic_polarization']\n",
      "\n",
      "\n",
      "funding\n",
      "\n",
      "\n",
      "['Firm', 'amount', 'term', 'party', 'house', 'full_name', 'district_id', 'kind', 'year', 'cycle', 'Name']\n",
      "\n",
      "\n",
      "latest_high_conflict\n",
      "\n",
      "\n",
      "['Topic', 'Total Funding', 'Funding Percentile', 'Relative Controversy', 'Controversy Percentile', 'Pass Rate']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df, n in zip([county_funding, county_term_funding, county_top_funders, legislator_funding, legislator_power, legislator_behavior, bill_stats, topic_term_summary, funding, latest_high_conflict], ['county_funding', 'county_term_funding', 'county_top_funders', 'legislator_funding', 'legislator_power', 'legislator_behavior', 'bill_stats', 'topic_term_summary', 'funding', \"latest_high_conflict\"]):\n",
    "    print(n)\n",
    "    print('\\n')\n",
    "    print(df.columns.tolist())\n",
    "    print('\\n')\n",
    "    df.to_parquet(f\"dashboard/shiny-app/data/{n}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
