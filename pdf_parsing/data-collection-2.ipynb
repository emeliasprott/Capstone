{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot.io as camelot\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "from pypdf import PdfReader\n",
    "\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rosters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Senate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_cases = {\n",
    "    \"7,8\": {\n",
    "        'party_check': True,\n",
    "    },\n",
    "    '15,16': {\n",
    "        'select_a': [0, 5, 9, 10, 11, 12, 13],\n",
    "        'combine_a': [(0, 1), (5, 6)],\n",
    "        'select_b': [0, 1, 13, 14, 15, 16, 17],\n",
    "        'combine_b': [(1, 2), (17, 18, 19, 20, 21, 22, 23, 25)],\n",
    "        'party_check': True\n",
    "    },\n",
    "    \"21,22\": {\n",
    "        'select_a': [0, 10, 29, 30, 31, 32, 33],\n",
    "        'combine_a': [(0, 1)],\n",
    "        'select_b': [0, 10, 13, 14, 15, 16, 17],\n",
    "        'combine_b': [(10, 11)],\n",
    "        'party_check': False\n",
    "    },\n",
    "    \"23,24\": {\n",
    "        'select_a': [0, 10, 25, 26, 27, 28, 29],\n",
    "        'combine_a': [(0, 1), (10, 11)],\n",
    "        'select_b': [0, 10, 13, 14, 15, 16, 17],\n",
    "        'combine_b': [(10, 11), (17, 18)],\n",
    "        'party_check': False\n",
    "    },\n",
    "    \"25,26\": {\n",
    "        'select_a': [0, 9, 28, 29, 30, 31, 32],\n",
    "        'select_b': [0, 6, 16, 17, 18, 19, 20],\n",
    "        'combine_b': [(0, 1), (6, 7, 9, 15), (20, 21, 22)],\n",
    "        'party_check': False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(word, name=False):\n",
    "    if name:\n",
    "        pattern = r'[^A-Za-z\\s,]'\n",
    "    else:\n",
    "        pattern = r'[^A-Za-z\\s,\\'-]'\n",
    "    return re.sub(pattern, '', word)\n",
    "\n",
    "def row_overlap(t):\n",
    "    missing_counties = t.loc[(t['Name'] == '') & (t['Counties'] != '')].sort_index(ascending=False).index\n",
    "    for i in missing_counties:\n",
    "        t.loc[i-1, 'Counties'] = t.loc[i-1, 'Counties'] + t.loc[i, 'Counties']\n",
    "    return t\n",
    "\n",
    "def senate_table_1(pages, special_params=None, version=1):\n",
    "    tables = camelot.read_pdf(\"Senate_Rosters.pdf\", pages=pages, flavor='stream')\n",
    "    t1 = tables[0].df\n",
    "    t2 = tables[1].df\n",
    "    if (special_params is None) or (pages == '7,8'):\n",
    "        if version == 1:\n",
    "            t1 = t1.loc[((t1[0] == '') & (t1[6] != '')) | (t1[0] != ''), :6]\n",
    "            t2 = t2.loc[((t2[0] == '') & (t2[6] != '')) | (t2[0] != ''), :6]\n",
    "            col_names = ['Name', 'Occupation', 'Party', 'District No.', 'Seat No.', 'Phone', 'Counties']\n",
    "        elif version == 2:\n",
    "            t1 = t1.loc[((t1[0] == '') & (t1[5] != '')) | (t1[0] != ''), :5]\n",
    "            t2 = t2.loc[((t2[0] == '') & (t2[5] != '')) | (t2[0] != ''), :5]\n",
    "            col_names = ['Name', 'Occupation', 'Party', 'District No.', 'Seat No.' 'Counties']\n",
    "    else:\n",
    "        if 'combine_a' in special_params[pages].keys():\n",
    "            for combo in special_params[pages]['combine_a']:\n",
    "                t1[combo[0]] = t1[[c for c in combo]].apply(lambda x: ' '.join(x), axis=1)\n",
    "        if 'combine_b' in special_params[pages].keys():\n",
    "            for combo in special_params[pages]['combine_b']:\n",
    "                t2[combo[0]] = t2[[c for c in combo]].apply(lambda x: ' '.join(x), axis=1)\n",
    "        t1 = t1[special_params[pages]['select_a']]\n",
    "        t2 = t2[special_params[pages]['select_b']]\n",
    "        col_names = ['Name', 'Occupation', 'Party', 'District No.', 'Seat No.', 'Phone', 'Counties']\n",
    "        if pages == '25,26':\n",
    "            t2.iloc[29, 0] = ''\n",
    "            t2.iloc[27, 0] = t2.iloc[27, 0] + ' Martinez'\n",
    "\n",
    "    t1.columns = col_names\n",
    "    t2.columns = col_names\n",
    "    t1.reset_index(drop=True, inplace=True)\n",
    "    t2.reset_index(drop=True, inplace=True)\n",
    "    if pages == \"25,26\":\n",
    "        for i, row in t2.iterrows():\n",
    "            if \"\\n.\" not in row['Occupation']:\n",
    "                t2.loc[i, 'Occupation'] = t2.loc[i, 'Occupation'] + ' ' + t2.loc[i, 'Occupation']\n",
    "        t2['Occupation'] = t2['Occupation'].apply(lambda x: re.sub(r'\\n.', '', x))\n",
    "        t2.loc[t2['Name'].str.startswith('Weber'), 'Occupation'] = 'Physician'\n",
    "    for t in [t1, t2]:\n",
    "        for col in ['Occupation', 'Counties']:\n",
    "            t[col] = t[col].apply(lambda x: text_clean(x, name=False))\n",
    "        t['Name'] = t['Name'].apply(lambda x: text_clean(x, name=True))\n",
    "    t1 = row_overlap(t1)\n",
    "    t2 = row_overlap(t2)\n",
    "\n",
    "    t1['Name'] = t1['Name'].apply(lambda x: x.strip())\n",
    "    t2['Name'] = t2['Name'].apply(lambda x: x.strip())\n",
    "    if special_params is not None:\n",
    "        if special_params[pages]['party_check']:\n",
    "            pstring_1 = \" \".join(p for p in t1['Party'] if (\"Party\" not in p) and (p != ' ') and (p != ''))\n",
    "            pstring_2 = \" \".join(p for p in t2['Party'] if (\"Party\" not in p) and (p != ' ') and (p != ''))\n",
    "            p_series1 = pd.Series(pstring_1.split(' '))\n",
    "            p_series2 = pd.Series(pstring_2.split(' '))\n",
    "\n",
    "    t1 = t1.loc[(t1['Name'] != '') & (t1['Name'] != 'Name')& (t1['Name'] != ' ') & (t1['Name'] != 'Vacancy')].reset_index(drop=True)\n",
    "    t2 = t2.loc[(t2['Name'] != '') & (t2['Name'] != 'Name') & (t2['Name'] != ' ') & (t2['Name'] != 'Vacancy')].reset_index(drop=True)\n",
    "    if special_params is not None:\n",
    "        if special_params[pages]['party_check']:\n",
    "            t1['Party'] = p_series1\n",
    "            t2['Party'] = p_series2\n",
    "\n",
    "    t = pd.concat([t1, t2])\n",
    "    t['pages'] = pages\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = []\n",
    "for i in np.arange(1, 27, 2):\n",
    "    pages = f\"{i},{i+1}\"\n",
    "\n",
    "    if pages in special_cases:\n",
    "        sc.append(senate_table_1(pages, special_cases, version=1))\n",
    "    else:\n",
    "        try:\n",
    "            sc.append(senate_table_1(pages, special_params=None, version=1))\n",
    "        except:\n",
    "            sc.append(senate_table_1(pages, special_params=None, version=2))\n",
    "t = pd.concat(sc)\n",
    "# t.to_csv(\"senate_roster.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_clean(name):\n",
    "    wd = str(unidecode(name))\n",
    "    if wd.endswith(\"Jr\"):\n",
    "        wd = re.sub(r\"\\,\\s*(J|S)r\\.*\\s*$\", \"\", wd)\n",
    "    if wd.endswith(\"III\"):\n",
    "        wd = re.sub(r\"\\,\\s*I{2,}\\s*$\", \"\", wd)\n",
    "    clean = re.sub(r\"\\-\", \" \", wd)\n",
    "    clean = re.sub(r\"[^a-zA-Z\\,/\\s]\", \"\", clean).strip()\n",
    "    return clean\n",
    "\n",
    "\n",
    "def assembly_name_cleaner(name):\n",
    "    try:\n",
    "        name2 = name_clean(name)\n",
    "        first, last = first_last_name(name2)\n",
    "        return first, last\n",
    "    except:\n",
    "        name1 = re.sub(r\"\\s{2,}\", \" \", name).strip()\n",
    "        name2 = re.sub(r\"(?<=[a-z])\\s+(?=[A-Z][a-z]+)\", \", \", name1)\n",
    "        name3 = name_clean(name2)\n",
    "        first, last = first_last_name(name3)\n",
    "        return first, last\n",
    "\n",
    "\n",
    "def assembly_cleaner(df, i):\n",
    "    df[\"Term\"] = f\"{2000 + i}-{2000 + i + 1}\"\n",
    "    df[\"Occupation\"] = df[\"Occupation\"].apply(word_cleaner)\n",
    "    df[\"Party\"] = df[\"Party\"].str.strip()\n",
    "    df_clear = df.loc[~df[\"Name\"].isin([\"\", \" \", \"Name\"])]\n",
    "    df_clear[[\"First\", \"Last\"]] = (\n",
    "        df_clear[\"Name\"].apply(assembly_name_cleaner).apply(pd.Series)\n",
    "    )\n",
    "\n",
    "    return df_clear.reset_index(drop=True)\n",
    "\n",
    "def word_cleaner(word, name=False):\n",
    "    wd = unidecode(word)\n",
    "    if name:\n",
    "        clean = re.sub(r\"[^a-zA-Z\\,/]\", \"\", str(wd))\n",
    "        clean2 = re.sub(r\"[-(?:\\s{2,})]\", \" \", clean)\n",
    "    else:\n",
    "        clean = re.sub(r\"[^a-zA-Z\\,/]\", \"\", str(wd))\n",
    "        clean2 = re.sub(r\"\\s{2,}\", \" \", clean)\n",
    "    return clean2.strip()\n",
    "\n",
    "\n",
    "def first_last_name(name):\n",
    "    if (name.strip(\" \") == \"Vacancy\") or \"Vacancy\" in name:\n",
    "        return \"Vacancy\", \"Vacancy\"\n",
    "\n",
    "    if name.endswith(\"Jr\"):\n",
    "        name = re.sub(r\"\\,\\s*(J|S)r\\.*\\s*$\", \"\", name)\n",
    "    if name.endswith(\"III\"):\n",
    "        name = re.sub(r\"\\,\\s*III*\\s*$\", \"\", name)\n",
    "\n",
    "    try:\n",
    "        last, first = name.split(\", \")\n",
    "        return first, last\n",
    "    except ValueError:\n",
    "        try:\n",
    "            last, first = name.split(\",\")\n",
    "            return last, first\n",
    "        except:\n",
    "            try:\n",
    "                last, first = name.split(\" \")\n",
    "                return first, last\n",
    "            except:\n",
    "                return '', ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_candidate_data(t, i):\n",
    "\n",
    "    if len(t[0].df.columns) <= 9:\n",
    "        t_a = t[0].df.iloc[:, :5]\n",
    "        t_b = t[1].df.iloc[:, :5]\n",
    "        t_a.columns = [\"Name\", \"Occupation\", \"Party\", \"District No.\", \"Seat No.\"]\n",
    "        t_b.columns = [\"Name\", \"Occupation\", \"Party\", \"District No.\", \"Seat No.\"]\n",
    "    elif len(t[0].df.columns) == 45:\n",
    "        t_a = t[0].df.iloc[:, [0, 10, 11, 39, 40, 41]]\n",
    "        t_a.loc[:, 10] = t_a.loc[:, 10] + \" \" + t_a.loc[:, 11]\n",
    "\n",
    "        t_a = t_a.drop(columns=[11])\n",
    "        t_a.columns = [\"Name\", \"Occupation\", \"Party\", \"District No.\", \"Seat No.\"]\n",
    "        t_b = t[1].df.iloc[:, [0, 8, 9, 28, 29, 30]]\n",
    "        t_b.loc[:, 8] = t_b.loc[:, 8] + \" \" + t_b.loc[:, 9]\n",
    "        t_b = t_b.drop(columns=[9])\n",
    "        t_b.columns = [\"Name\", \"Occupation\", \"Party\", \"District No.\", \"Seat No.\"]\n",
    "    elif len(t[0].df.columns) == 29:\n",
    "        t_a = t[0].df.iloc[:, [0, 1, 7, 8, 23, 24, 25]]\n",
    "        t_a.loc[:, 0] = t_a.loc[:, 0] + \" \" + t_a.loc[:, 1]\n",
    "        t_a.loc[:, 7] = t_a.loc[:, 7] + \" \" + t_a.loc[:, 8]\n",
    "        t_a = t_a.drop(columns=[1, 8])\n",
    "        t_a.columns = [\"Name\", \"Occupation\", \"Party\", \"District No.\", \"Seat No.\"]\n",
    "        t_b = t[1].df.iloc[:, [0, 1, 15, 48, 49, 50]]\n",
    "        t_b.iloc[16, 1] = \"Valladres, Suzette Martinez\"\n",
    "        t_b.iloc[17, 0] = \"\"\n",
    "        t_b.loc[:, 0] = t_b.loc[:, 0] + \" \" + t_b.loc[:, 1]\n",
    "        t_b = t_b.drop(columns=[1])\n",
    "        t_b.columns = [\"Name\", \"Occupation\", \"Party\", \"District No.\", \"Seat No.\"]\n",
    "    elif len(t[0].df.columns) == 26:\n",
    "        t_a = t[0].df.iloc[:, [0, 6, 7, 20, 21, 22]]\n",
    "        t_a.loc[:, 6] = t_a.loc[:, 6] + \" \" + t_a.loc[:, 7]\n",
    "        t_a = t_a.drop(columns=[7])\n",
    "        t_a.columns = [\"Name\", \"Occupation\", \"Party\", \"District No.\", \"Seat No.\"]\n",
    "        if len(t[1].df.columns) == 30:\n",
    "            t_b = t[1].df.iloc[:, [0, 6, 7, 24, 25, 26]]\n",
    "            t_b.loc[:, 6] = t_b.loc[:, 6] + \" \" + t_b.loc[:, 7]\n",
    "            t_b = t_b.drop(columns=[7])\n",
    "        else:\n",
    "            t_b = t[1].df.iloc[:, [0, 7, 40, 41, 42]]\n",
    "        t_b.columns = [\"Name\", \"Occupation\", \"Party\", \"District No.\", \"Seat No.\"]\n",
    "    table = pd.concat([t_a, t_b]).reset_index(drop=True)\n",
    "    table = assembly_cleaner(table, i)\n",
    "\n",
    "    positions = t[2].df.iloc[:, :2].rename(columns={0: \"Position\", 1: \"Name\"})\n",
    "    positions = positions.loc[~positions[\"Name\"].isin(['', ' ', 'Name'])]\n",
    "    positions['Position'] = positions['Position'].apply(word_cleaner)\n",
    "    positions[['First', 'Last']] = positions['Name'].apply(assembly_name_cleaner).apply(pd.Series)\n",
    "    positions = positions.loc[~positions['Position'].isin(['ChiefClerk', 'ChiefSergeantatArms'])].drop(columns=['Name'])\n",
    "    tale = table.merge(positions, on=['First', 'Last'], how='left').drop(columns=['Name'])\n",
    "    return tale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_roster = pd.DataFrame(columns=['Occupation', 'Party', 'District No.', 'Seat No.', 'Term', 'First', 'Last', 'Position'])\n",
    "for i in np.arange(1, 27, 2):\n",
    "    page_numbers = f\"{i},{i+1}\"\n",
    "    t = camelot.read_pdf('Assembly_Rosters.pdf', pages=page_numbers, flavor='stream')\n",
    "    table = process_candidate_data(t, i)\n",
    "    assembly_roster = pd.concat([assembly_roster, table], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_roster.to_csv(\"assembly_roster.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Senate Committees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "senate_reader = PdfReader('Senate_Committees.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_format_sen_coms(page, page_num):\n",
    "    senate_coms = {}\n",
    "    t = unidecode(page)\n",
    "    t_ = re.sub(r'(?:(?:MEMBERSHIPS)|(?:Continued)|(?:continued))(?=[\\nA-Za-z])', '. ', t)\n",
    "    if page_num in [0, 3, 5,6, 7]:\n",
    "        matches = [m for m in re.finditer(r'(?<=\\.)\\s*([A-Z][A-Za-z\\s\\']+)(?=\\s*--\\(\\d+\\)--\\s*)', str(t_))]\n",
    "    else:\n",
    "        matches = [m for m in re.finditer(r'(?<=\\.)\\s*\\n([A-Z][A-Za-z\\s\\'-]+)(?=\\s*--\\(\\s*\\d+\\s*\\)--\\s*)', str(t_))]\n",
    "    for i, m in enumerate(matches):\n",
    "        start_ = m.start()\n",
    "        end_ = matches[i+1].start() - 1 if i < len(matches)-1 else len(str(t_))\n",
    "        string_ = str(t_)[start_:end_].split(r'--')\n",
    "        name = re.sub(r'(?<=\\w)\\n(?=\\w)', '', string_[0]).strip()\n",
    "        committees = string_[2].strip().split(';')\n",
    "        senate_coms[name] = {'committees': {}}\n",
    "        for committee in committees:\n",
    "            committee_ = re.sub(r'\\n', ' ', committee)\n",
    "            position_match = re.search(r'((?:\\s*C\\s*o\\s*-\\s*C\\s*h\\s*a\\s*i\\s*r\\s*)|(?:(?:\\s*C\\s*o)*\\s*C\\s*h\\s*a\\s*i\\s*r)|(?:\\s*V\\s*ic\\s*e\\s*-*C\\s*hai\\s*r)|(?:(?:\\s*R\\s*e\\s*p\\s*u\\s*b\\s*l\\s*i\\s*c\\s*a\\s*n)|(?:\\s*D\\s*e\\s*m\\s*o\\s*c\\s*r\\s*a\\s*t\\s*i\\s*c\\s*)\\s*A\\s*l\\s*ter\\s*nate))', committee_)\n",
    "            if position_match:\n",
    "                position = position_match.group(1).strip()\n",
    "                replace = rf'\\(\\s*{re.escape(position)}\\s*\\)'\n",
    "                committee_ = re.sub(replace, '', committee_).strip()\n",
    "            else:\n",
    "                position = 'Member'\n",
    "                committee_ = committee_.strip()\n",
    "            committee__ = re.sub(r'(?<=[a-z])(?=[A-Z])', ' ', committee_).strip()\n",
    "            committee___ = re.sub(r'(?<=[a-z])\\s+(?=[a-z]{1,2}\\b)', '', committee__).strip()\n",
    "\n",
    "            senate_coms[name]['committees'].update({committee___: position})\n",
    "    return senate_coms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def later_format_sen_coms(page, page_num, year, leftovers=None):\n",
    "    senate_coms = {}\n",
    "    holding = None\n",
    "    t = unidecode(page)\n",
    "    t_ = re.sub(r'(\\n*SENATOR.*COMMITTEE.*(?:\\n\\s*(?:AND)*.*COUNCIL).*MEMBERSHIPS)', '', t)\n",
    "    t__ = re.sub(r'Boar\\nds', 'Boards', t_)\n",
    "    if page_num == 24:\n",
    "        matches = [m for m in re.finditer(r'--[Cc]ontinued\\s*\\n*([A-Z][A-Za-z\\s\\']+)(?=\\s*--continued)', str(t__))]\n",
    "    elif page_num == 32:\n",
    "        matches = [m for m in re.finditer(r'(?:Continued)*\\n\\s*([A-Z][A-Za-z\\s\\']+)\\n', str(t__))]\n",
    "    elif page_num == 46:\n",
    "        matches = [m for m in re.finditer(r'\\n([A-Z][\\w\\s]+)\\s*\\n(?:(?:S\\s*t\\s*a\\s*n\\s*d\\s*i\\s*n\\s*g)|(?:\\s*S\\s*e\\s*l\\s*e\\s*c\\s*t))\\s*\\n*\\s*C\\s*o\\s*m\\s*m\\s*i\\s*t\\s*t\\s*e\\s*e\\s*s\\s*--\\(\\s*\\w+\\s*\\)', str(t__))]\n",
    "    else:\n",
    "        matches = [m for m in re.finditer(r'\\n([A-Z][\\w\\s\\']+)(?:\\s*-*-*\\s*continued\\s*)*\\n[\\w\\s,]+--\\(\\s*\\w+\\s*\\)', str(t__))]\n",
    "    for i, match in enumerate(matches):\n",
    "        end = matches[i+1].start() - 1 if i < len(matches)-1 else len(str(t__))\n",
    "        if leftovers is None or i > 0:\n",
    "            if page_num == 32:\n",
    "                name_ = re.search(r'\\n(.*)\\n', match.group()).group().strip()\n",
    "            else:\n",
    "                name_ = re.search(r'\\n(.*)\\s*\\n(?=Standing\\s*\\n*\\s*C\\s*om\\s*m\\s*i\\s*t\\s*t\\s*e\\s*es*)', match.group()).group().strip()\n",
    "        else:\n",
    "            if page_num == 24 or page_num == 30:\n",
    "                name_ = match.group(1).strip()\n",
    "            else:\n",
    "                name_ = re.search(r'\\n(.*)(?=\\s*-*-*(?:[C|c]ontinued\\s*)|\\n*[A-Z](?:.*\\n*\\s*C\\s*o\\s*m\\s*m\\s*i\\s*t\\s*t\\s*e\\s*es*)]*)', match.group()).group().strip()\n",
    "                name_ = re.sub(r'--\\s*(?:[C|c]ontinued)*', '', name_).strip()\n",
    "        _start = match.end()\n",
    "        coms = str(t__)[_start:end]\n",
    "        clean = [c for c in coms.split('--') if re.search(r'\\([1-9]+\\)', c) is None]\n",
    "        cleaned = [re.sub(r'\\n*(?:\\s*S\\s*e\\s*l\\s*e\\s*c\\s*t\\s* C\\s*o\\s*m\\s*m\\s*i\\s*t\\s*t\\s*e\\s*e\\s*s)|(?:S\\s*u\\s*b\\s*c\\s*o\\s*m\\s*m\\s*i\\s*t\\s*t\\s*e\\s*e\\s*s)|(?:J\\s*o\\s*i\\s*n\\s*t C\\s*o\\s*m\\s*m\\s*i\\s*t\\s*t\\s*e\\s*e\\s*s)|(?:B\\s*o\\s*a\\s*r\\s*d\\s*s, C\\s*o\\s*m\\s*m\\s*i\\s*s\\s*s\\s*i\\s*o\\s*n\\s*s, a\\s*n\\s*d C\\s*o\\s*u\\s*n\\s*c\\s*i\\s*l\\s*s)', ' ', c) for c in clean]\n",
    "        cleaned_ = re.sub(r'(?<!No)(?<=[a-z\\s\\)])\\.(?=[\\s\\n]*[A-Z]*)', '; ', ''.join(cleaned), flags=re.UNICODE)\n",
    "        committees = cleaned_.split(';')\n",
    "        senate_coms[name_] = {'committees': {}}\n",
    "        if not (leftovers is None or i > 0):\n",
    "            if name_ in leftovers:\n",
    "                senate_coms[name_]['committees'].update(leftovers[name_]['committees'])\n",
    "        for j, committee in enumerate(committees):\n",
    "            committee_ = re.sub(r'\\n', ' ', committee)\n",
    "            position_match = re.search(r'((?:\\s*C\\s*o\\s*-\\s*C\\s*h\\s*a\\s*i\\s*r\\s*)|(?:(?:\\s*C\\s*o)*\\s*C\\s*h\\s*a\\s*i\\s*r)|(?:\\s*V\\s*ic\\s*e\\s*-*C\\s*hai\\s*r)|(?:(?:\\s*R\\s*e\\s*p\\s*u\\s*b\\s*l\\s*i\\s*c\\s*a\\s*n)|(?:\\s*D\\s*e\\s*m\\s*o\\s*c\\s*r\\s*a\\s*t\\s*i\\s*c\\s*)\\s*A\\s*l\\s*ter\\s*nate))', committee_)\n",
    "            if position_match:\n",
    "                position = position_match.group(1).strip()\n",
    "                replace = rf'\\(\\s*{re.escape(position)}\\s*\\)'\n",
    "                committee__ = re.sub(replace, '', committee_).strip()\n",
    "            else:\n",
    "                position = 'Member'\n",
    "                committee__ = committee_.strip()\n",
    "            committee___ = re.sub(r'\\(\\s*\\d+\\s*\\)*|(?<=\\w)-(?=\\s*\\w)', '', committee__).strip()\n",
    "            committee____ = re.sub(r'\\s{2,}', ' ', committee___).strip()\n",
    "            committee____ = committee____.replace('(Serves Ex Officioon all Standing and Joint Committees)', '')\n",
    "            if j == len(committees) - 1:\n",
    "                committee____ = re.sub(r'(?<=[^No])\\s*\\.\\s*.*$', '', committee____)\n",
    "\n",
    "            if committee____ != '':\n",
    "                if 'Rules' in senate_coms[name_]['committees'].keys() and 'Rules' in committee____:\n",
    "                    senate_coms[name_]['committees'].update({f\"Joint Committee on {committee____}\": position})\n",
    "                else:\n",
    "                    if committee____ == \"Select Committees2020 United States Census\":\n",
    "                        committee____ = \"Select Committee on 2020 United States Census\"\n",
    "                    if re.sub(r'\\s*\\(\\s*\\d+\\s*\\)\\s*', '', committee____) != '':\n",
    "                        senate_coms[name_]['committees'].update({committee____: position})\n",
    "\n",
    "        if i == len(matches) - 1:\n",
    "            if ((year == 2010) and not any(['Joint Committee' in c for c in clean])) or ((year != 2010) and not any(['Boards, Commissions, and Councils' in c for c in clean])):\n",
    "                holding = {name_: senate_coms[name_]}\n",
    "                senate_coms.pop(name_)\n",
    "    return holding, senate_coms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_year = 2002\n",
    "senator_committees = {}\n",
    "leftover = None\n",
    "year_values = []\n",
    "for i, page_raw in enumerate(senate_reader.pages):\n",
    "    try:\n",
    "        hold = leftover\n",
    "        leftover = None\n",
    "        page = page_raw.extract_text()\n",
    "        if (i <= 8) or (i >= 49):\n",
    "            page_ = early_format_sen_coms(page, i)\n",
    "        else:\n",
    "            leftover, page_ = later_format_sen_coms(page, i, current_year, hold)\n",
    "        keys = [k for k in page_.keys()]\n",
    "\n",
    "        if (keys[0].startswith('A')) and i != 0:\n",
    "            senator_committees[str(current_year)] = {k: v for d in year_values for k, v in d.items()}\n",
    "            year_values = [page_]\n",
    "            current_year += 2\n",
    "        elif i == len(senate_reader.pages) - 1:\n",
    "            year_values.append(page_)\n",
    "            senator_committees[str(current_year)] = dict((k, v) for d in year_values for k, v in d.items())\n",
    "        else:\n",
    "            year_values.append(page_)\n",
    "    except:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "senators = []\n",
    "for term, politicians in senator_committees.items():\n",
    "    for politician, details in politicians.items():\n",
    "        for committee, position in details['committees'].items():\n",
    "            senators.append({'term': term, 'politician': politician, 'committee': committee, 'position': position})\n",
    "senators_committees = pd.DataFrame(senators)\n",
    "senators_committees['term'] = senators_committees['term'].apply(lambda x: f\"{int(x)-1}-{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "senators_committees = senators_committees.loc[(senators_committees['committee'] != \"(Serves Ex Officioon all Standing and Joint Committees)\") & (senators_committees['committee'] != \"(4)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/jkjxx5pj447bytbqv8pkw9nh0000gn/T/ipykernel_51272/388427317.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  senators_committees.loc[senators_committees['committee'].str.contains('(Serves Ex Officioon)'), 'committee'] = senators_committees.loc[senators_committees['committee'].str.contains('(Serves Ex Officioon)'), 'committee'].apply(lambda x: x.split('.')[0])\n"
     ]
    }
   ],
   "source": [
    "senators_committees.loc[senators_committees['committee'].str.contains('(Serves Ex Officioon)'), 'committee'] = senators_committees.loc[senators_committees['committee'].str.contains('(Serves Ex Officioon)'), 'committee'].apply(lambda x: x.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "senators_committees.to_csv('senators_committees.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assembly Committees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_reader = PdfReader('assembly_committees.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assembly_committees(page, year, page_num):\n",
    "    t = unidecode(page)\n",
    "    assembly_coms = {}\n",
    "    y = year\n",
    "    matches = [m for m in re.finditer(r'(?:(?:[Cc]ontinued)|\\.)\\s*\\n\\s*([A-Z]+[\\w+,\\'\\-\\s]*)\\s*--', str(t))]\n",
    "    if (matches[0].group(1).strip().startswith('A')) or (matches[0].group(1).strip().startswith('B')):\n",
    "        if page_num < 74:\n",
    "            term = re.search(r'(\\d{4}-\\s*\\d{2,})\\s*R\\s*E\\s*G\\s*U\\s*L\\s*A\\s*R', str(t))\n",
    "            if term is not None:\n",
    "                term = f\"20{term.group(1).split('-')[1].strip()}\"\n",
    "                if term != year:\n",
    "                    y = term\n",
    "        else:\n",
    "            term = re.search(r'[A-Z]+\\s*\\d+,*\\s*(\\d+)\\s*\\n', str(t))\n",
    "            if term is not None:\n",
    "                if len(term.group(1)) > 4:\n",
    "                    term_ = term.group(1)[:4]\n",
    "                else:\n",
    "                    term_ = term.group(1)\n",
    "                if term_ != year:\n",
    "                    if term_ == '2025':\n",
    "                        y = '2026'\n",
    "                    else:\n",
    "                        y = term_\n",
    "    for i, m in enumerate(matches):\n",
    "        end = matches[i+1].start() if i < len(matches)-1 else len(str(t))\n",
    "        start = m.end()\n",
    "        c_string = str(t)[start:end].strip()\n",
    "        name = m.group(1).strip()\n",
    "        assembly_coms[name] = {'committees': {}}\n",
    "        committees = c_string.split(';')\n",
    "        for committee in committees:\n",
    "            committee_ = re.sub(r'\\n', ' ', committee)\n",
    "            position_match = re.search(r'((?:\\s*C\\s*o\\s*-\\s*C\\s*h\\s*a\\s*i\\s*r\\s*)|(?:(?:\\s*C\\s*o)*\\s*C\\s*h\\s*a\\s*i\\s*r)|(?:\\s*V\\s*ic\\s*e\\s*-*C\\s*hai\\s*r)|(?:(?:\\s*R\\s*e\\s*p\\s*u\\s*b\\s*l\\s*i\\s*c\\s*a\\s*n)|(?:\\s*D\\s*e\\s*m\\s*o\\s*c\\s*r\\s*a\\s*t\\s*i\\s*c\\s*)\\s*A\\s*l\\s*ter\\s*nate))', committee_)\n",
    "            if position_match:\n",
    "                position = position_match.group(1).strip()\n",
    "                replace = rf'\\(\\s*{re.escape(position_match.group())}\\s*\\)'\n",
    "                committee__ = re.sub(replace, '', committee_).strip()\n",
    "            else:\n",
    "                position = 'Member'\n",
    "                committee__ = committee_.strip()\n",
    "            if re.search(r'\\.\\s*-+$', committee__) is not None:\n",
    "                committee__ = re.sub(r'\\.\\s*-+$', '', committee__).strip()\n",
    "            if committee__ != '':\n",
    "                assembly_coms[name]['committees'].update({committee__: position})\n",
    "    return y, assembly_coms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_coms = {}\n",
    "term_values = []\n",
    "year = '2002'\n",
    "for i, page in enumerate(assembly_reader.pages):\n",
    "    p = page.extract_text()\n",
    "    year, v = assembly_committees(p, year, i)\n",
    "    if year not in assembly_coms.keys():\n",
    "        assembly_coms[year] = v\n",
    "    else:\n",
    "        assembly_coms[year].update(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly = []\n",
    "for term, politician in assembly_coms.items():\n",
    "    for politician, details in politician.items():\n",
    "        for committee, position in details['committees'].items():\n",
    "            assembly.append({'term': term, 'politician': politician, 'committee': committee, 'position': position})\n",
    "assembly_committees = pd.DataFrame(assembly)\n",
    "assembly_committees['term'] = assembly_committees['term'].apply(lambda x: f\"{int(x)-1}-{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_committees.to_csv('assembly_committees.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ca_leg_etl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
