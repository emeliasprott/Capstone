{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_votes = pd.read_csv('ca_leg/legislation_data/bill_summary_vote_tbl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_history = pd.read_csv('ca_leg/legislation_data/bill_history_tbl.csv', dtype={'action_status': str, 'primary_location': str, 'secondary_location': str, 'end_status': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = pd.read_csv('ca_leg/legislation_data/authors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.read_csv('ca_leg/legislation_data/history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "versions = pd.read_csv('ca_leg/legislation_data/bill_versions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_votes = pd.read_csv('ca_leg/legislation_data/bill_detail_vote_tbl.csv', parse_dates=['session_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_summary = pd.read_csv('ca_leg/legislation_data/bill_summary_vote_tbl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_motions = pd.read_csv('ca_leg/legislation_data/bill_motion_tbl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = pd.read_csv('ca_leg/legislation_data/committee_codes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians = pd.read_csv('ca_leg/legislation_data/politicians.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lobbying = pd.read_csv('calaccess/lobbying_clean2.csv', dtype={'PAYEE_NAMS': str, 'BAKREF_TID': str})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "expend_assembly = pd.read_csv('calaccess/expend_assembly_matched.csv', dtype={'TargetPropositionName': str})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "expend_senate = pd.read_csv('calaccess/expend_senate_matched.csv', dtype={'TargetPropositionName': str})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "digests = pd.read_csv('ca_leg/legislation_data/digest.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hearings = pd.read_csv('ca_leg/legislation_data/committee_hearing_tbl.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_votes['vote_date_time'] = pd.to_datetime(bill_votes['vote_date_time']).apply(lambda x: x.strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_votes['legislator_name'] = bill_votes['legislator_name'].apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_KEYWORDS = [\n",
    "    \"Assembly Third Reading\", \"Assembly 3rd reading\", 'senate 3rd reading', \"Senate Third Reading\",\"Concurrence - Urgency Added\", \"Concurrence in Senate Amendments\", \"Do pass as amended, and re-refer\", \"Do pass as amended, but re-refer\", \"Do pass as amended\", \"Do pass and be re-referred\",\n",
    "    \"Concurrence\", \"Consent Calendar\", \"Urgency Clause\", \"Special Consent\",\n",
    "    \"Motion to Reconsider\", \"Do pass\", \"Reconsideration\", \"Committee amendments\",\n",
    "    \"W/O REF. TO FILE\", \"Be re-referred to the Committee\",\n",
    "    \"Lay on the Table\", \"Amend by\", \"Unfinished Business\", \"Placed on Appropriations Suspense File\",\n",
    "]\n",
    "\n",
    "def extract_action(motion_text):\n",
    "    if not isinstance(motion_text, str) or motion_text is None:\n",
    "        return None\n",
    "    motion = motion_text.upper()\n",
    "\n",
    "    action = next((act for act in ACTION_KEYWORDS if act.upper() in motion), None)\n",
    "    if action != 'Reconsideration' and 'RECONSIDER' in motion:\n",
    "        if action is not None:\n",
    "            action += ' Reconsideration'\n",
    "        else:\n",
    "            action = 'Reconsideration'\n",
    "\n",
    "\n",
    "    return action if action else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_motions['simplified_motion'] = bill_motions['motion_text'].apply(extract_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_coms = {}\n",
    "for i, row in locations.iterrows():\n",
    "    if row['committee_code'].startswith('CZ'):\n",
    "        continue\n",
    "    name = row['committee_name']\n",
    "    if row['committee_code'].startswith('CS'):\n",
    "        if name.startswith('Sen.'):\n",
    "            cname = re.sub(r'Sen. ', 'senate ', name).lower()\n",
    "        elif name.startswith('Senate '):\n",
    "            cname = name.lower()\n",
    "        else:\n",
    "            cname = 'senate ' + name.lower()\n",
    "    elif row['committee_code'].startswith('CX'):\n",
    "        if name.lower().startswith('assembly'):\n",
    "            cname = name.lower()\n",
    "        else:\n",
    "            cname = 'assembly ' + name.lower()\n",
    "    if re.search(r'x\\d$', cname) is not None:\n",
    "        cname = re.sub(r'x(?=\\d$)', 'no. ', cname)\n",
    "    clean_coms[row['committee_code']] = cname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "leg_committees = [f\"{row['chamber']} {row['committee_clean']}\".lower() for _, row in politicians[['committee_clean', 'chamber']].drop_duplicates().iterrows()]\n",
    "\n",
    "def match_committees(_names, clean_coms, threshold=92):\n",
    "    clean_c = list(clean_coms.values())\n",
    "    clean_codes = list(clean_coms.keys())\n",
    "    name_mapping = {}\n",
    "    for i, clean in enumerate(clean_c):\n",
    "        code = clean_codes[i]\n",
    "        matches = []\n",
    "        matches.append(process.extractOne(\n",
    "            clean,\n",
    "            _names,\n",
    "            scorer=fuzz.token_sort_ratio,\n",
    "            score_cutoff=threshold\n",
    "        ))\n",
    "        matches.append(process.extractOne(\n",
    "            clean,\n",
    "            _names,\n",
    "            scorer=fuzz.partial_ratio,\n",
    "            score_cutoff=threshold\n",
    "        ))\n",
    "        valid_matches = [m for m in matches if m is not None]\n",
    "        if len(valid_matches) > 0:\n",
    "            best_match = max(valid_matches, key=lambda x: x[1])\n",
    "            name_mapping[code] = best_match[0]\n",
    "        else:\n",
    "            fall_back = process.extractOne(\n",
    "                clean,\n",
    "                _names,\n",
    "                scorer=fuzz.token_sort_ratio,\n",
    "                score_cutoff=threshold - 8\n",
    "            )\n",
    "            if fall_back is not None:\n",
    "                name_mapping[code] = fall_back[0]\n",
    "            else:\n",
    "                name_mapping[code] = None\n",
    "    return name_mapping\n",
    "\n",
    "committee_matches = match_committees(leg_committees, clean_coms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations['committee_clean'] = locations['committee_code'].map(committee_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.loc[locations['committee_name'] == 'EDUCATION X5', 'committee_clean'] = 'Budget and Fiscal Review: Education'\n",
    "locations.loc[locations['committee_code'] == 'CX12', 'committee_clean'] = 'Budget No. 1 on Health and Human Services'\n",
    "locations.loc[locations['committee_code'] == 'CS68', 'committee_clean'] = 'Budget No. 3 - Health and Human Services'\n",
    "locations.loc[locations['committee_code'] == 'CS66', 'committee_clean'] = 'Senate Veterans Affairs'\n",
    "locations.loc[locations['committee_code'] == 'CS56', 'committee_clean'] = 'Senate Public Employment and Retirement'\n",
    "locations.loc[locations['committee_code'] == 'CS62', 'committee_clean'] = 'Senate Budget and Fiscal Review'\n",
    "locations.loc[locations['committee_code'] == 'CX23', 'committee_clean'] = 'Assembly Utilities and Commerce'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_codes = {\n",
    "    row['motion_id']: row['simplified_motion']\n",
    "    for _, row in bill_motions.iterrows()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_votes['motion_text'] = summary_votes['motion_id'].map(motion_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_bill_id(id):\n",
    "    front, end = id[:4], id[4:]\n",
    "    if re.search(r'\\d{4}$', front):\n",
    "        return f\"{front}{int(front) + 1}{end}\"\n",
    "    else:\n",
    "        return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "versions['ID'] = versions['bill_id'].apply(lambda x: repair_bill_id(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_vers = versions.loc[versions['bill_id'].str.startswith('2')]\n",
    "for i, row in bill_vers.iterrows():\n",
    "    tail = f\"{row['VersionNum']}{row['MeasureState']}\"\n",
    "    repaired = repair_bill_id(re.sub(tail, '', row['bill_id']))\n",
    "    end = int(repaired[-4:])\n",
    "\n",
    "    bill_vers.loc[i, 'bill_ID'] = f\"{repaired[:-4]}{end}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "legislators = {i: pol for i, pol in enumerate(politicians['full_name'].unique().tolist())}\n",
    "\n",
    "leg_parties = {row['full_name']: row['Party'] for _, row in politicians[['full_name', 'Party']].drop_duplicates().iterrows()}\n",
    "leg_occupations = {row['full_name']: row['Occupation'] for _, row in politicians[['full_name', 'Occupation']].drop_duplicates().iterrows()}\n",
    "committees = {i: com for i, com in enumerate(politicians['committee_clean'].unique().tolist())}\n",
    "lobby_firms = {i: firm for i, firm in enumerate(lobbying['FIRM_NAME'].unique().tolist())}\n",
    "\n",
    "donor_names = list(set(expend_assembly['ExpenderName'].unique().tolist() + expend_senate['ExpenderName'].unique().tolist()))\n",
    "donors = {i: donor for i, donor in enumerate(donor_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_dict(d, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, d in zip(\n",
    "    ['legislators', 'committees', 'lobby_firms', 'donors'],\n",
    "    [legislators, committees, lobby_firms, donors]\n",
    "):\n",
    "    save_dict(d, f'{name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_titles = {row['bill_ID']: row['Title'] for _, row in bill_vers[['bill_ID', 'Title']].drop_duplicates().iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_subjects = {row['bill_ID']: row['GeneralSubject'] for _, row in bill_vers.loc[bill_vers['GeneralSubject'].apply(lambda x: x is not None and isinstance(x, str)), ['bill_ID', 'GeneralSubject']].drop_duplicates().iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_ids = list(set(bill_votes.loc[bill_votes['bill_id'].str.startswith('2'), 'bill_id'].unique().tolist() + summary_votes.loc[summary_votes['bill_id'].str.startswith('2'), 'bill_id'].unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_id_codes = {row['bill_id']: row['bill_ID'] for _, row in bill_vers.drop_duplicates(subset=['bill_id', 'bill_ID']).iterrows()}\n",
    "history['bill_ID'] = history['bill_id'].map(bill_id_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['Date'] = pd.to_datetime(history['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "introduction_dates = {}\n",
    "for v, group in history.loc[history['bill_ID'].isin(bill_ids)].groupby('bill_ID'):\n",
    "    introduction_dates[v] = {'Dates': group['Date'].unique().tolist(), 'Actions': group.sort_values('Date', ascending=True).drop_duplicates(subset=['Action', 'Date'])['Action'].tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_id_mapping = {i: list(group.values) for i, group in bill_vers.groupby('bill_ID')['ID']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict(version_id_mapping, 'version_id_mapping.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_id_mapping2 = {i: list(group.values) for i, group in bill_vers.groupby('bill_ID')['bill_id']}\n",
    "bv2b = {v: k for k, val in version_id_mapping2.items() for v in val}\n",
    "history['bill_ID'] = history['bill_id'].map(bv2b)\n",
    "save_dict(bv2b, 'bill_id_mapping.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_ranges = {}\n",
    "\n",
    "for k, v in introduction_dates.items():\n",
    "    first, last = min(v['Dates']), max(v['Dates'])\n",
    "    date_ranges[k] = {'First_action': first, 'Last_action': last}\n",
    "\n",
    "save_dict(date_ranges, 'bill_dates_map.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = history.loc[history['bill_ID'].notna()].sort_values('Date', ascending=False).groupby('bill_ID').first().reset_index()[['bill_ID', 'Action']]\n",
    "outcomes.loc[outcomes['Action'].isin(['CHAPTERED', 'ENROLLED', 'FILED', 'APPROVED']), 'Outcome'] = 1\n",
    "outcomes.loc[outcomes['Action'] == 'VETOED', 'Outcome'] = -1\n",
    "outcomes.loc[outcomes['Outcome'].isna(), 'Outcome'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = outcomes.set_index('bill_ID')['Outcome'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict(outcome, 'bill_outcomes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_bill_ids = {}\n",
    "for i in summary_votes.loc[summary_votes['bill_id'].isin(bill_ids)].groupby(['year', 'motion_id'])['bill_id'].value_counts().index:\n",
    "    year, motion_id, bill_id = i\n",
    "    if (year, motion_id) not in vote_bill_ids.keys():\n",
    "        vote_bill_ids[(year, motion_id)] = [bill_id]\n",
    "    else:\n",
    "        vote_bill_ids[(year, motion_id)].append(bill_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_vers_dig = bill_vers.merge(digests, on='bill_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "legislators_last_names = {}\n",
    "for _, row in politicians[['chamber', 'Last', 'Term', 'full_name']].drop_duplicates().iterrows():\n",
    "    legislators_last_names[(row['chamber'], row['Last'].lower(), row['Term'])] = row['full_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {row['ID']: {\n",
    "    'digest': row['DigestText'],\n",
    "    'MeasureState': row['MeasureState'],\n",
    "    'VoteRequired': row['VoteRequired'] if row['VoteRequired'] is not None else 'No',\n",
    "    'VersionNum': row['VersionNum'] if row['VersionNum'] is not None else 'No',\n",
    "    'LocalProgram': row['LocalProgram'] if row['LocalProgram'] is not None else 'No',\n",
    "    'FiscalCommittee': row['FiscalCommittee'] if row['FiscalCommittee'] is not None else 'No',\n",
    "    'TaxLevy': row['TaxLevy'] if row['TaxLevy'] is not None else 'No',\n",
    "    'Urgency': row['Urgency'] if row['Urgency'] is not None else 'No'} for _, row in bill_vers_dig.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "legislator_codes = {v: k for k, v in legislators.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "committee_codes = {v.lower(): k for k, v in committees.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_votes['chamber'] = bill_votes['location_code'].apply(lambda x: 'assembly' if x == 'AFLOOR' or x.startswith('CX') else 'senate' if x == 'SFLOOR' or x.startswith('CS') else 'full')\n",
    "bill_votes['vote_date_time'] = pd.to_datetime(bill_votes['vote_date_time'])\n",
    "bill_votes['term'] = bill_votes['vote_date_time'].apply(lambda x: f\"{x.year}-{x.year + 1}\" if x.year % 2 == 1  else f\"{x.year - 1}-{x.year}\" if x.year % 2 == 0 and x < pd.Timestamp(year=x.year, month=11, day=2) else f\"{x.year + 1}-{x.year + 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_locations = authors.loc[(authors['House'] == 'UNKNOWN') & (authors['bill_id'].map(bill_id_codes).isin(bill_ids)), ['bill_id', 'Name']].drop_duplicates()\n",
    "for i, row in author_locations.iterrows():\n",
    "    if 'AB' in row['bill_id']:\n",
    "        author_locations.loc[i, 'name'] = 'Assembly ' + row['Name']\n",
    "    elif 'SB' in row['bill_id']:\n",
    "        author_locations.loc[i, 'name'] = 'Senate ' + row['Name']\n",
    "    else:\n",
    "        author_locations.loc[i, 'name'] = 'Joint ' + row['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def fuzzy_strings(source_list, target_list):\n",
    "    def preprocess_name(name):\n",
    "        if not isinstance(name, str):\n",
    "            return \"\"\n",
    "        name = name.lower()\n",
    "        name = re.sub(r'\\(.*?\\)', '', name)\n",
    "        name = re.sub(r'committee on', '', name)\n",
    "        name = re.sub(r'[^a-z\\s]', ' ', name)\n",
    "        name = re.sub(r'\\s+', ' ', name).strip()\n",
    "        return name\n",
    "\n",
    "    clean_source = [preprocess_name(c) for c in source_list]\n",
    "    clean_target = [preprocess_name(c) for c in target_list]\n",
    "\n",
    "    keywords = [\"education\", \"health\", \"finance\", \"budget\", \"transportation\",\n",
    "                \"judiciary\", \"environment\", \"agriculture\", \"energy\", \"labor\",\n",
    "                \"housing\", \"veterans affairs\", \"public safety\", \"insurance\", \"banking\", \"public health\", \"small business\", \"redistricting\",\n",
    "                \"public utilities\", \"natural resources\", \"water\",\n",
    "                \"technology\", \"communications\", \"elections\", \"government\",\n",
    "                \"appropriations\", \"rules\", \"ethics\", 'criminal justice', \"environmental protection\", \"college and university\", \"human services\", \"reproductive health\", \"mental health\", \"technology\", \"aggriculture\", \"urban development\", \"renewable energy\", \"gun violence\", \"commerce\", \"privacy\", \"cybersecurity\", \"infrastructure\", \"disaster preparedness\", \"prisons\", \"aging\"]\n",
    "\n",
    "    def get_committee_keywords(name):\n",
    "        return set(kw for kw in keywords if kw in name)\n",
    "\n",
    "    target_keywords = [get_committee_keywords(name) for name in clean_target]\n",
    "\n",
    "    def calculate_similarity(source_idx, target_idx):\n",
    "        source = clean_source[source_idx]\n",
    "        target = clean_target[target_idx]\n",
    "\n",
    "        if not source or not target:\n",
    "            return 0\n",
    "\n",
    "        if source == target:\n",
    "            return 100\n",
    "\n",
    "        token_sort = fuzz.token_sort_ratio(source, target)\n",
    "        token_set = fuzz.token_set_ratio(source, target)\n",
    "        partial = fuzz.partial_ratio(source, target)\n",
    "\n",
    "        source_kw = get_committee_keywords(source)\n",
    "        keyword_overlap = len(source_kw.intersection(target_keywords[target_idx]))\n",
    "        keyword_bonus = min(20, keyword_overlap * 10)\n",
    "        weighted_score = (token_sort * 0.3) + (token_set * 0.5) + (partial * 0.2) + keyword_bonus\n",
    "\n",
    "        return weighted_score\n",
    "\n",
    "    matches = {}\n",
    "    for i, source in enumerate(source_list):\n",
    "        scores = [calculate_similarity(i, j) for j in range(len(target_list))]\n",
    "\n",
    "        if not scores or max(scores) < 60:\n",
    "            matches[source] = None\n",
    "        else:\n",
    "            best_idx = np.argmax(scores)\n",
    "            confidence = scores[best_idx]\n",
    "\n",
    "            if confidence >= 60:\n",
    "                matches[source] = target_list[best_idx]\n",
    "            else:\n",
    "                matches[source] = None\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_com_matches = fuzzy_strings(author_locations['name'].unique().tolist(), leg_committees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_locations['name'] = author_locations['name'].map(author_com_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sponsors = authors.loc[authors['bill_id'].map(bill_id_codes).isin(bill_ids)]\n",
    "sponsors['term'] = sponsors['bill_id'].apply(lambda x: f\"{x[:4]}-{int(x[:4]) + 1}\" if int(x[:4]) % 2 == 1 else f\"{int(x[:4]) - 1}-{x[:4]}\" if int(x[:4]) % 2 == 0 and int(x[:4]) < 2009 else f\"{x[:4]}-{int(x[:4]) + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lob = lobbying.loc[lobbying['clean_beneficiary'].notna(), ['FIRM_NAME', 'EXPN_DSCR', 'clean_beneficiary', 'EXPN_DATE', 'BENE_AMT']]\n",
    "lob['EXPN_DATE'] = pd.to_datetime(lob['EXPN_DATE'])\n",
    "lob['term'] = lob['EXPN_DATE'].apply(lambda x: f\"{x.year}-{x.year + 1}\" if x.year % 2 == 1  else f\"{x.year - 1}-{x.year}\" if x.year % 2 == 0 and x < pd.Timestamp(year=x.year, month=11, day=2) else f\"{x.year}-{x.year + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in politicians.loc[politicians['full_name'].apply(lambda x: isinstance(x, float)), ['Term', 'Last', 'chamber']].drop_duplicates().iterrows():\n",
    "    term, last = row['Term'], row['Last']\n",
    "    a = politicians.loc[(politicians['Last'] == last) & (politicians['Term'] == term) & (politicians['full_name'].apply(lambda x: isinstance(x, str)))]\n",
    "    if len(a) > 0:\n",
    "        politicians.loc[(politicians['Term'] == term) & (politicians['Last'] == last) & (politicians['chamber'] == row['chamber']), 'full_name'] = a['full_name'].values[0]\n",
    "        continue\n",
    "    else:\n",
    "        a = politicians.loc[(politicians['Last'] == last) & (politicians['full_name'].apply(lambda x: isinstance(x, str)))]\n",
    "    if len(a) > 0:\n",
    "        politicians.loc[(politicians['Term'] == term) & (politicians['Last'] == last) & (politicians['chamber'] == row['chamber']), 'full_name'] = a['full_name'].values[0]\n",
    "    else:\n",
    "        print(last, term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_names_terms = {}\n",
    "for _, row in politicians[['full_name', 'Term', 'chamber']].drop_duplicates().iterrows():\n",
    "    if ',' in row['full_name']:\n",
    "        name = row['full_name'].split(',')[1].strip() + ' ' + row['full_name'].split(',')[0].strip()\n",
    "    else:\n",
    "        name = row['full_name']\n",
    "    pol_names_terms[(row['full_name'].lower(), row['Term'])] = {'chamber': row['chamber'], 'name': name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "expend_assembly = expend_assembly.rename(columns={'term': 'Term'})\n",
    "expend_assembly['chamber'] = 'assembly'\n",
    "expend_senate = expend_senate.rename(columns={'term': 'Term'})\n",
    "expend_senate['chamber'] = 'senate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_contributions = pd.concat([expend_assembly.loc[expend_assembly['matched_target_name'].notna(), ['ExpenderName', 'Amount', 'matched_target_name', 'Term', 'chamber', 'DateEnd']].drop_duplicates(subset=['ExpenderName', 'Amount', 'matched_target_name', 'DateEnd']), expend_senate.loc[expend_senate['matched_target_name'].notna(), ['ExpenderName', 'Amount', 'matched_target_name', 'Term', 'chamber', 'DateEnd']].drop_duplicates(subset=['ExpenderName', 'Amount', 'matched_target_name', 'DateEnd'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_contributions['DateEnd'] = pd.to_datetime(campaign_contributions['DateEnd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sponsors['bill_ID'] = sponsors['bill_id'].apply(repair_bill_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = history.merge(bill_votes, left_on=['bill_ID', 'Date'], right_on=['bill_id', 'vote_date_time'], how='inner').rename(columns={'bill_id_x': 'bill_version'}).drop('bill_id_y', axis=1)\n",
    "voting['bv_id'] = voting['bill_version'].apply(repair_bill_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_places = {}\n",
    "for i, row in voting.groupby(['motion_id', 'term', 'chamber', 'Date']).agg({'legislator_name': lambda x: list(x)}).iterrows():\n",
    "    motion_id, term, chamber, date = i\n",
    "    g = politicians.loc[(politicians['chamber'] == chamber) & (politicians['Term'] == term) & (politicians['Last'].isin(row['legislator_name']))]\n",
    "    voting_places[(motion_id, term, chamber, date)] = {\n",
    "        'most_common_committee': g.groupby('committee_clean').size().sort_values(ascending=False).head(1).index[0] if len(g) > 0 else None\n",
    "    }\n",
    "voting['voting_place'] = voting.apply(lambda row: voting_places.get((row['motion_id'], row['term'], row['chamber'], row['Date']), {}).get('most_common_committee', None), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2', device='mps')\n",
    "REFRESH_FLAG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(title):\n",
    "    if not isinstance(title, str):\n",
    "        return ''\n",
    "    title = re.sub(r'\\(.*?\\)', '', title)\n",
    "    title = re.sub(r'[^a-zA-Z0-9\\s]', ' ', title)\n",
    "    title = re.sub(r'\\s+', ' ', title).strip()\n",
    "    return title.lower()\n",
    "\n",
    "def batched_embeddings(values, output_dims=384):\n",
    "    vals = [text_clean(v) for v in values if isinstance(v, str)]\n",
    "    vals = list(set([v for v in vals if v != '']))\n",
    "    embeddings = model.encode(vals, batch_size=64, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True, num_workers=4, output_dims=output_dims)\n",
    "    embs = {v: e for v, e in zip(vals, embeddings)}\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = list(set([t for t in versions.loc[versions['bill_id'].str.startswith('2')]['GeneralSubject'].tolist() if (isinstance(t, str) and t is not None)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_original = {text_clean(t): t for t in subjects}\n",
    "if REFRESH_FLAG == True:\n",
    "    save_dict(subjects_original, 'subjects_original.pkl')\n",
    "    subject_embeddings = batched_embeddings(subjects)\n",
    "    torch.save(subject_embeddings, 'subject_embeddings.pt')\n",
    "else:\n",
    "    subject_embeddings = torch.load('subject_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_embeddings = {}\n",
    "for occ in list(set(list(leg_occupations.values()))):\n",
    "    if isinstance(occ, str) and len(occ) > 0 and text_clean(occ) != '':\n",
    "        occ_embeddings[occ] = model.encode(\n",
    "            text_clean(occ),\n",
    "            convert_to_tensor=True,\n",
    "            normalize_embeddings=True,\n",
    "            output_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29df4cec1504ee395b2ee7c19365f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "titles = [t for t in bill_vers['Title'].unique().tolist() if (isinstance(t, str) and t not in [None, '', np.nan])]\n",
    "title_embeddings = batched_embeddings(titles, output_dims=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4768e6a2184dae98fd360f22bdcfd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lobbying_firms_embeddings = batched_embeddings([firm for firm in lobbying.loc[(lobbying['clean_beneficiary'].notna()) & (lobbying['FIRM_NAME'])]['FIRM_NAME'].unique().tolist() if isinstance(firm, str)], output_dims=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "committee_embeddings = {}\n",
    "for committee in politicians['committee_clean'].unique().tolist():\n",
    "    co = re.sub(r'assembly|senate|committee|subcommittee', '', committee.lower())\n",
    "    committee_embeddings[committee.lower()] = model.encode(co,  convert_to_tensor=True, normalize_embeddings=True, truncate_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 506/506 [00:35<00:00, 14.29it/s]\n"
     ]
    }
   ],
   "source": [
    "donor_embeddings = {}\n",
    "\n",
    "for donor in tqdm(donor_names):\n",
    "    donor_embeddings[donor] = model.encode(donor, convert_to_tensor=True, normalize_embeddings=True, truncate_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 37.06it/s]\n"
     ]
    }
   ],
   "source": [
    "motion_embeddings = {}\n",
    "for motion in tqdm([t for t in pd.DataFrame.from_dict(motion_codes, orient='index').reset_index().rename({'index': 'motion_id', 0: 'motion_text'}, axis=1)['motion_text'].drop_duplicates().tolist() if t is not None]):\n",
    "    motion_embeddings[motion] = model.encode(motion, convert_to_tensor=True, normalize_embeddings=True, truncate_dim=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "digest_embeddings = torch.load('digests.pt')\n",
    "if (len([a for a in (list(set([t if (isinstance(t, str) and t is not None) else '' for t in digests.loc[digests['bill_id'].str.startswith('2')]['DigestText'].tolist()]))) if a not in digest_embeddings.keys()]) == 0) & (REFRESH_FLAG == False):\n",
    "    pass\n",
    "else:\n",
    "    for digest in tqdm(list(set([t if (isinstance(t, str) and t is not None) else '' for t in digests.loc[digests['bill_id'].str.startswith('2')]['DigestText'].tolist()]))):\n",
    "        if digest not in digest_embeddings.keys():\n",
    "            digest_embeddings[digest] = model.encode(digest, convert_to_tensor=True, normalize_embeddings=True, truncate_dim=64)\n",
    "    torch.save(digest_embeddings, 'digests.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "hear = hearings[['bill_id', 'location_code']].merge(locations[['committee_code', 'committee_clean']], left_on='location_code', right_on='committee_code', how='left')[['bill_id', 'committee_clean']].drop_duplicates()\n",
    "hear['year'] = hear['bill_id'].apply(lambda x: int(x[:4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = {p: 'Democratic Alternate' if re.search(r'Democratic\\s*Alternate', p) is not None else 'Vice Chair' if re.search(r'V\\s*i\\s*c\\s*e\\s*-*\\s*C\\s*h\\s*a\\s*i\\s*r\\s*', p) is not None else 'Co-Chair' if re.search(r'Co\\s*-\\s*Chair', p) is not None else 'Chair' if re.search(r'Cha\\s*i\\s*r', p) is not None else 'Republican Alternate' if re.search(r'\\s*Republican\\s*Alternate', p) is not None else p for p in politicians['position'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnums = bill_vers.set_index('ID')['VersionNum'].to_dict()\n",
    "vid_map = {v: k for k, val in version_id_mapping.items() for v in val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sponsors['chamber'] = sponsors['House'].apply(lambda x: x.lower() if isinstance(x, str) else None)\n",
    "sponsors = sponsors.merge(politicians[['Term', 'Last', 'chamber', 'full_name']].drop_duplicates(), left_on=['chamber', 'Name', 'term'], right_on=['chamber', 'Last', 'Term'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOP Graph-Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch_geometric.data import HeteroData\n",
    "import numpy as np\n",
    "\n",
    "author_type_map = {\n",
    "    'LEAD_AUTHOR': 'LEAD_AUTHOR',\n",
    "    'PRINCIPAL_COAUTHOR': 'PRINCIPAL_COAUTHOR',\n",
    "    'COAUTHOR': 'COAUTHOR',\n",
    "    'data=\"COAUTHOR\"': 'COAUTHOR',\n",
    "    'data=\"LEAD_AUTHOR\"': 'LEAD_AUTHOR',\n",
    "    'data=\"PRINCIPAL_COAUTHOR\"': 'PRINCIPAL_COAUTHOR',\n",
    "    'nan': 'AUTHOR'\n",
    "}\n",
    "author_levels = {\n",
    "    'AUTHOR': 1,\n",
    "    'COAUTHOR': 1,\n",
    "    'PRINCIPAL_COAUTHOR': 2,\n",
    "    'LEAD_AUTHOR': 3\n",
    "}\n",
    "\n",
    "def features_vote_required(vr):\n",
    "    if not isinstance(vr, str):\n",
    "        return 'MAJORITY'\n",
    "    if \"FOUR_FIFTHS\" in vr:\n",
    "        return '80_PCT'\n",
    "    elif \"THREE_FOURTHS\" in vr:\n",
    "        return '75_PCT'\n",
    "    elif \"SEVENTY_PERCENT\" in vr or \"70%\" in vr:\n",
    "        return '70_PCT'\n",
    "    elif \"TWO_THIRDS\" in vr:\n",
    "        return '66-67_PCT'\n",
    "    elif \"55%\" in vr:\n",
    "        return '55_PCT'\n",
    "    else:\n",
    "        return 'MAJORITY'\n",
    "\n",
    "vote_required_codes = {\n",
    "    'MAJORITY': 0,\n",
    "    '55_PCT': 1,\n",
    "    '66-67_PCT': 2,\n",
    "    '70_PCT': 3,\n",
    "    '75_PCT': 4,\n",
    "    '80_PCT': 5\n",
    "}\n",
    "\n",
    "def bool_correction(val):\n",
    "    if not isinstance(val, str):\n",
    "        return 0\n",
    "    if 'YES' in val:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "measure_types = bill_vers['MeasureType'].unique()\n",
    "parties = politicians['Party'].unique()\n",
    "chambers = politicians['chamber'].unique()\n",
    "outcome_mapping = {'CHAPTERED': 1, 'VETOED': 0, 'FAILED': -1, 'ENROLLED': 1}\n",
    "measure_encoder = LabelEncoder()\n",
    "measure_encoder.fit(measure_types)\n",
    "party_encoder = LabelEncoder()\n",
    "party_encoder.fit(parties)\n",
    "chamber_encoder = LabelEncoder()\n",
    "chamber_encoder.fit(chambers)\n",
    "pos = list(positions.values()) + ['member']\n",
    "pos_encoder = LabelEncoder()\n",
    "pos_encoder.fit(pos)\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, id, type, features=None):\n",
    "        self.id = id\n",
    "        self.type = type\n",
    "        self.features = features or {}\n",
    "\n",
    "class Edge:\n",
    "    def __init__(self, source, target, relation, attributes=None):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        self.relation = relation\n",
    "        self.attributes = attributes or {}\n",
    "\n",
    "class Bill(Node):\n",
    "    def __init__(self, bill_id, title, subject, measure_type):\n",
    "        measure_type = measure_encoder.transform([measure_type])[0] if measure_type in measure_encoder.classes_ else -1\n",
    "        features = {\n",
    "            'title': title,\n",
    "            'subject': subject,\n",
    "            'measure_type': measure_type,\n",
    "            'date': None,\n",
    "        }\n",
    "        super().__init__(bill_id, \"bill\", features)\n",
    "        self.actions = None\n",
    "        self.order_df = None\n",
    "        self.outcome = None\n",
    "\n",
    "    def add_actions(self, actions):\n",
    "        if self.actions is None:\n",
    "            self.actions = actions\n",
    "        else:\n",
    "            self.actions = pd.concat([self.actions, actions], ignore_index=True).drop_duplicates()\n",
    "\n",
    "    def add_date(self, date):\n",
    "        self.features['date'] = date\n",
    "\n",
    "    def add_order_df(self, order_df):\n",
    "        if self.order_df is None:\n",
    "            self.order_df = order_df\n",
    "        else:\n",
    "            self.order_df = pd.concat([self.order_df, order_df], ignore_index=True).drop_duplicates()\n",
    "\n",
    "    def add_outcome(self, outcome):\n",
    "        outcome = outcome_mapping.get(outcome, -1)\n",
    "        self.outcome = outcome\n",
    "\n",
    "    def align_actions_versions(self, bill, versions_, dates):\n",
    "        dates = pd.Series(dates).sort_values(ascending=True).drop_duplicates().tolist()\n",
    "        actions = [i for i in introduction_dates.get(bill, {}).get('Actions', []) if i != 'FILED']\n",
    "        if len(actions) > len(dates):\n",
    "            if actions[-2:] == ['ENROLLED', 'CHAPTERED'] or actions[-2:] == ['APPROVED', 'CHAPTERED'] or len(actions) <= 4 and actions[-1] == 'ENROLLED' or abs(len(dates) - len(actions)) >= 2 and actions[-1] == 'ENROLLED' or actions == ['INTRODUCED', 'ENROLLED', 'AMENDED_SENATE'] or actions[-1] == 'APPROVED' or len(actions) == 3 and all(a.startswith('PASSED_') for a in actions[-2:]) or actions == ['ENROLLED', 'INTRODUCED'] or actions == ['INTRODUCED', 'ENROLLED'] or actions == ['INTRODUCED', 'REVISED'] or len(actions) > 3 and actions[-3:] == ['ENROLLED', 'CORRECTED', 'CHAPTERED'] or len(actions) > 3 and actions[-3:] == ['PASSED_SENATE', 'PASSED_ASSEMBLY', 'AMENDED_SENATE'] or list(set(['INTRODUCED', 'PASSED_SENATE', 'PASSED_ASSEMBLY', 'AMENDED_SENATE'])) == list(set(actions)) or list(set(['INTRODUCED', 'PASSED_SENATE', 'PASSED_ASSEMBLY', 'AMENDED_ASSEMBLY'])) == list(set(actions)) or actions[-2] == 'ENROLLED' and actions[-1].startswith('PASSED_') or len(actions) > 5 and actions[-4] == 'CHAPTERED' and actions[-1].startswith('PASSED_') or actions[-2:] == ['PASSED_SENATE', 'PASSED_ASSEMBLY'] or actions == ['INTRODUCED', 'AMENDED_SENATE', 'PASSED_SENATE', 'PASSED_ASSEMBLY', 'AMENDED_ASSEMBLY'] or len(actions) == 9 and actions[-6:] == ['APPROVED', 'CHAPTERED', 'ENROLLED', 'AMENDED_SENATE', 'PASSED_ASSEMBLY', 'PASSED_SENATE'] or len(actions) > 5 and actions[-4:] == ['ENROLLED', 'PASSED_SENATE', 'APPROVED', 'PASSED_ASSEMBLY'] or dates == [pd.Timestamp('2008-12-08 00:00:00'), pd.Timestamp('2008-12-18 00:00:00')]:\n",
    "                dates.append(dates[-1])\n",
    "                if len(actions) > len(dates):\n",
    "                    dates.append(dates[-1])\n",
    "                    if len(actions) > len(dates):\n",
    "                        dates.append(dates[-1])\n",
    "                        if len(actions) > len(dates):\n",
    "                            dates.append(dates[-1])\n",
    "                            if len(actions) > len(dates):\n",
    "                                dates.append(dates[-1])\n",
    "            if len(dates) == 1 and len(actions) > 1:\n",
    "                for _ in range(len(actions) - len(dates)):\n",
    "                    dates.append(dates[0])\n",
    "            if actions[-2:] == ['INTRODUCED', 'PASSED_ASSEMBLY']:\n",
    "                dates = [dates[0]] + dates\n",
    "            if len(actions) >= 6 and actions[:3] == ['INTRODUCED', 'AMENDED_ASSEMBLY', 'ENROLLED'] and actions[-3:] == ['CHAPTERED', 'APPROVED', 'CORRECTED']:\n",
    "                dates = dates[:2] + [dates[2]] + dates[2:-2] + [dates[-2]] + dates[-2:]\n",
    "            elif ('PASSED_ASSEMBLY' in actions and 'AMENDED_ASSEMBLY' in actions) or ('PASSED_SENATE' in actions and 'AMENDED_SENATE' in actions):\n",
    "                if len(dates) == 3:\n",
    "                    dates = dates[:1] + [dates[1]] + dates[1:]\n",
    "                    if all(a for a in ['PASSED_ASSEMBLY', 'AMENDED_ASSEMBLY', 'PASSED_SENATE', 'AMENDED_SENATE'] if a in actions):\n",
    "                        dates = dates[:1] + [dates[1]] + dates[1:]\n",
    "                elif 'PROPOSED_CONFERENCE_REPORT_1' in actions and len(actions) - len(dates) == 2:\n",
    "                    dates = dates[:2] + [dates[2]] + [dates[2]] + dates[2:]\n",
    "                elif len(dates) > 3 and len(actions) - len(dates) > 0 and not (actions[-4:] == ['PASSED_ASSEMBLY', 'ENROLLED', 'PASSED_SENATE', 'CHAPTERED'] and 'AMENDED_SENATE' in actions):\n",
    "                    dates = dates[:2] + [dates[2]] + dates[2:]\n",
    "                if len(actions) > 4 and actions[-3:] == ['ENROLLED', 'PASSED_SENATE', 'CHAPTERED']:\n",
    "                    dates = dates[:-2] + [dates[-2]] + dates[-2:]\n",
    "\n",
    "            if len(actions) - len(dates) == 1:\n",
    "                if 'CORRECTED' in actions:\n",
    "                    actions.remove('CORRECTED')\n",
    "                elif 'RESCIND' in actions:\n",
    "                    actions.remove('RESCIND')\n",
    "\n",
    "            if actions[-1] == 'CORRECTED' and len(actions) - len(dates) == 2:\n",
    "                if len(dates) >= 5:\n",
    "                    dates = dates[:3] + [dates[3]] + [dates[3]] + [dates[4]] + dates[4:]\n",
    "                elif len(dates) == 2:\n",
    "                    dates = [dates[0]] + [dates[0]] + dates[0:]\n",
    "                else:\n",
    "                    dates = dates[:2] + [dates[2]] + [dates[2]] + dates[2:]\n",
    "            if actions[-1] == 'CHAPTERED' and len(actions) - len(dates) == 3:\n",
    "                dates = dates + [dates[-1]] + [dates[-1]] + [dates[-1]]\n",
    "            if actions[-2:] == ['ENROLLED', 'VETOED'] and len(actions) - len(dates) > 0 :\n",
    "                dates = dates[:-4] + [dates[-4]]  + [dates[-3]] + dates[-3:]\n",
    "\n",
    "            if len(dates) < len(actions) and'ENROLLED' in actions and actions.index('ENROLLED') < len(actions) - 1:\n",
    "                for i in range(len(actions) - actions.index('ENROLLED')):\n",
    "                    dates = dates + [dates[-1]]\n",
    "        if len(actions) + 1 == len(dates):\n",
    "            dates = dates[:-1]\n",
    "        try:\n",
    "            action_df = pd.DataFrame({'date': dates, 'action': actions})\n",
    "        except:\n",
    "            return None, None, None\n",
    "        action_df['date'] = pd.to_datetime(action_df['date'], errors='coerce')\n",
    "        order_df = action_df.loc[~action_df['action'].isin(['FILED', 'PASSED_ASSEMBLY', 'PASSED_SENATE', 'APPROVED'])]\n",
    "        repair_flag = False\n",
    "        if order_df.shape[0] > len(versions_):\n",
    "            version_ends = [re.search(r'INT|AMD|ENR|CHP|PRO', v).group() for v in versions_]\n",
    "            if 'ENR' in version_ends:\n",
    "                v_enr = version_ends.index('ENR')\n",
    "                extension = [versions_[v_enr - 1] if v_enr - 1 != 0 else versions_[v_enr] for _ in range(len(order_df) - len(versions_))]\n",
    "                versions_ = versions_[:v_enr] + extension + versions_[v_enr:]\n",
    "            else:\n",
    "                repair_flag = True\n",
    "        vr = pd.DataFrame({'version': versions_})\n",
    "        if vr.shape[0] == 0:\n",
    "            return None, None, None\n",
    "        try:\n",
    "            vr['v_num'] = vr['version'].apply(lambda x: re.search(r'\\d{2}(?=INT|AMD|ENR|CHP|PRO)', x).group()).astype(int)\n",
    "        except:\n",
    "            return None, None, None\n",
    "        vr = vr.sort_values('v_num', ascending=False).reset_index(drop=True)\n",
    "        if repair_flag:\n",
    "            last_v = vr.loc[vr['version'].notna()].iloc[-1]['version']\n",
    "            last_v_num = float(re.search(r'\\d{2}(?=INT|AMD|ENR|CHP|PRO)', last_v).group())\n",
    "            for i in range(len(order_df) - len(versions_)):\n",
    "                vr.loc[len(vr) + i, 'version'] = last_v\n",
    "                vr.loc[len(vr) + i, 'v_num'] = last_v_num\n",
    "\n",
    "        order_df['version'] = vr['version']\n",
    "        order_df['order'] = range(1, len(order_df) + 1)\n",
    "        outcomes = order_df['action'].tolist()\n",
    "        if 'CHAPTERED' in outcomes or 'FILED' in outcomes:\n",
    "            if 'VETOED' in outcomes:\n",
    "                outcome = 'VETOED'\n",
    "            else:\n",
    "                outcome = 'CHAPTERED'\n",
    "        else:\n",
    "            outcome = 'FAILED'\n",
    "        return action_df, order_df, outcome\n",
    "\n",
    "class BillVersion(Node):\n",
    "    def __init__(self, bill_id, version_id, digest, vote_required, local_program, fiscal_com, tax_levy, urgency):\n",
    "        vote_required = vote_required_codes.get(features_vote_required(vote_required), 0)\n",
    "        local_program = bool_correction(local_program)\n",
    "        fiscal_com = bool_correction(fiscal_com)\n",
    "        tax_levy = bool_correction(tax_levy)\n",
    "        urgency = bool_correction(urgency)\n",
    "        features = {\n",
    "            'digest': digest,\n",
    "            'VoteRequired': vote_required,\n",
    "            'LocalProgram': local_program,\n",
    "            'FiscalCommittee': fiscal_com,\n",
    "            'TaxLevy': tax_levy,\n",
    "            'Urgency': urgency,\n",
    "            'date': None\n",
    "        }\n",
    "        super().__init__(version_id, \"bill_version\", features)\n",
    "        self.bill_id = bill_id\n",
    "        self.actions = {}\n",
    "\n",
    "    def add_actions(self, location, date):\n",
    "        if location not in self.actions:\n",
    "            self.actions[location] = []\n",
    "        self.actions[location].append(date)\n",
    "\n",
    "    def add_date(self, date):\n",
    "        self.features['date'] = date\n",
    "\n",
    "class Legislator(Node):\n",
    "    def __init__(self, legislator_id, party, occupation):\n",
    "        party = party_encoder.transform([party])[0] if party in party_encoder.classes_ else -1\n",
    "        features = {\n",
    "            'party': party,\n",
    "            'occupation': occupation\n",
    "        }\n",
    "        super().__init__(legislator_id, \"legislator\", features)\n",
    "        self.terms = []\n",
    "\n",
    "class LegislatorTerm(Node):\n",
    "    def __init__(self, term, legislator_id, chamber, district):\n",
    "        chamber = chamber_encoder.transform([chamber])[0] if chamber in chamber_encoder.classes_ else -1\n",
    "        features = {\n",
    "            'chamber': chamber,\n",
    "            'district': district,\n",
    "            'term': term\n",
    "        }\n",
    "        node_id = f\"{legislator_id}_{term}_{chamber}\"\n",
    "        super().__init__(node_id, \"legislator_term\", features)\n",
    "        self.committees = []\n",
    "        self.committee_positions = []\n",
    "\n",
    "    def add_committee(self, committee_id):\n",
    "        self.committees.append(committee_id)\n",
    "\n",
    "    def add_committee_position(self, committee_id, position):\n",
    "        self.committee_positions.append((committee_id, position))\n",
    "\n",
    "class Committee(Node):\n",
    "    def __init__(self, committee_id, name, chamber, term):\n",
    "        chamber = chamber_encoder.transform([chamber])[0] if chamber in chamber_encoder.classes_ else -1\n",
    "        features = {\n",
    "            'name': name,\n",
    "            'chamber': chamber\n",
    "        }\n",
    "        term_ = term.split('-')[0]\n",
    "        id = f\"{committee_id}_{term_}\"\n",
    "        super().__init__(id, \"committee\", features)\n",
    "        self.members = []\n",
    "\n",
    "    def add_member(self, legislator_id):\n",
    "        self.members.append(legislator_id)\n",
    "\n",
    "class LobbyFirm(Node):\n",
    "    def __init__(self, firm_id, name):\n",
    "        features = {\n",
    "            'name': name\n",
    "        }\n",
    "        super().__init__(firm_id, \"lobby_firm\", features)\n",
    "        self.total_donations = 0\n",
    "\n",
    "    def add_donation(self, amount):\n",
    "        self.total_donations += amount\n",
    "\n",
    "class Donor(Node):\n",
    "    def __init__(self, donor_id, name):\n",
    "        features = {\n",
    "            'name': name\n",
    "        }\n",
    "        super().__init__(donor_id, \"donor\", features)\n",
    "        self.total_donations = 0\n",
    "\n",
    "    def add_donation(self, amount):\n",
    "        self.total_donations += amount\n",
    "\n",
    "class Vote(Edge):\n",
    "    def __init__(self, legislator, bill_version, vote, motion, date, direction):\n",
    "        attributes = {\n",
    "            'vote': 1 if vote == 'AYE' else -1 if (vote == 'NOE' or vote == 'NO') else 0,\n",
    "            'motion': motion,\n",
    "            'date': date\n",
    "        }\n",
    "        if direction == 1:\n",
    "            super().__init__(legislator, bill_version, 'voted_on', attributes)\n",
    "        else:\n",
    "            super().__init__(bill_version, legislator, 'vote_from', attributes)\n",
    "\n",
    "class CommitteeMembership(Edge):\n",
    "    def __init__(self, legislator, committee, position, direction):\n",
    "        position = pos_encoder.transform([position])[0] if position in pos_encoder.classes_ else pos_encoder.transform(['member'])[0]\n",
    "        attributes = {\n",
    "            'position': position\n",
    "        }\n",
    "        if direction == 1:\n",
    "            super().__init__(legislator, committee, 'member_of', attributes)\n",
    "        else:\n",
    "            super().__init__(committee, legislator, 'has_member', attributes)\n",
    "        committee.add_member(legislator)\n",
    "\n",
    "class Sponsorship(Edge):\n",
    "    def __init__(self, legislator, bill_version, author_type, direction):\n",
    "        author_type = author_levels.get(author_type_map.get(author_type, 'AUTHOR'))\n",
    "        attributes = {\n",
    "            'author_type': author_type\n",
    "        }\n",
    "        if direction == 1:\n",
    "            super().__init__(legislator, bill_version, 'wrote', attributes)\n",
    "        else:\n",
    "            super().__init__(bill_version, legislator, 'written_by', attributes)\n",
    "\n",
    "class Reading(Edge):\n",
    "    def __init__(self, bill, committee, date, direction):\n",
    "        attributes = {\n",
    "            'date': date\n",
    "        }\n",
    "        if direction == 1:\n",
    "            super().__init__(committee, bill, 'read', attributes)\n",
    "        else:\n",
    "            super().__init__(bill, committee, 'read_by', attributes)\n",
    "\n",
    "class Donation(Edge):\n",
    "    def __init__(self, donor, recipient, amount, date, type, direction=1):\n",
    "        attributes = {\n",
    "            'amount': amount,\n",
    "            'date': date\n",
    "        }\n",
    "        if type == 'CampaignContribution':\n",
    "            if direction == 1:\n",
    "                super().__init__(donor, recipient, 'donated_to', attributes)\n",
    "            else:\n",
    "                super().__init__(recipient, donor, 'has_donation', attributes)\n",
    "        else:\n",
    "            if direction == 1:\n",
    "                super().__init__(donor, recipient, 'lobbied', attributes)\n",
    "            else:\n",
    "                super().__init__(recipient, donor, 'has_lobbying', attributes)\n",
    "\n",
    "class Version(Edge):\n",
    "    def __init__(self, bill_version, bill, direction):\n",
    "        if direction == 1:\n",
    "            super().__init__(bill_version, bill, 'is_version')\n",
    "        else:\n",
    "            super().__init__(bill, bill_version, 'has_version')\n",
    "\n",
    "class siblingVersion(Edge):\n",
    "    def __init__(self, version1, version2, direction):\n",
    "        if direction == 1:\n",
    "            super().__init__(version1, version2, 'priorVersion')\n",
    "        else:\n",
    "            super().__init__(version2, version1, 'nextVersion')\n",
    "\n",
    "class samePerson(Edge):\n",
    "    def __init__(self, node1, node2):\n",
    "        super().__init__(node1, node2, 'samePerson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphBuilder:\n",
    "    def __init__(self):\n",
    "        self.nodes = {}\n",
    "        self.edges = []\n",
    "        self.versions = []\n",
    "        self.nodes_by_type = defaultdict(list)\n",
    "        self.edges_by_type = defaultdict(list)\n",
    "        self._type_counters = defaultdict(int)\n",
    "\n",
    "    def add_version(self, version):\n",
    "        self.versions.append(version)\n",
    "\n",
    "    def add_node(self, node):\n",
    "        key = (node.type, node.id)\n",
    "        if key not in self.nodes:\n",
    "            self.nodes[key] = node\n",
    "        idx = self._type_counters[node.type]\n",
    "        self._type_counters[node.type] += 1\n",
    "        self.nodes_by_type[node.type].append(node)\n",
    "\n",
    "    def get_node(self, type_, id_):\n",
    "        return self.nodes.get((type_, id_))\n",
    "\n",
    "    def add_edge(self, edge):\n",
    "        self.edges.append(edge)\n",
    "        etype = (edge.source.type, edge.relation, edge.target.type)\n",
    "        self.edges_by_type[etype].append(edge)\n",
    "\n",
    "    def build(self):\n",
    "        return {\n",
    "            \"nodes\": list(self.nodes.values()),\n",
    "            \"edges\": self.edges,\n",
    "            \"nodes_by_type\": self.nodes_by_type,\n",
    "            \"edges_by_type\": self.edges_by_type\n",
    "        }\n",
    "\n",
    "    def add_bills(self, bill_ids, titles, subjects, titles_embs, subjects_embs, features):\n",
    "        def process_single_bill(bill):\n",
    "            try:\n",
    "                title = text_clean(titles.get(bill, ''))\n",
    "                subject = text_clean(subjects.get(bill, ''))\n",
    "                title_emb = titles_embs.get(title, None)\n",
    "                subject_emb = subjects_embs.get(subject, None)\n",
    "                measure_type = re.search(r'[A-Za-z]+', bill).group()\n",
    "                bill_node = Bill(bill, title_emb, subject_emb, measure_type)\n",
    "\n",
    "                versions = version_id_mapping.get(bill, [])\n",
    "                versions_ = []\n",
    "                dates = introduction_dates.get(bill, {}).get('Dates', [])\n",
    "                try:\n",
    "                    fd = sorted(list(set(dates)))[0]\n",
    "                except IndexError:\n",
    "                    y = int(bill[:4])\n",
    "                    fd = pd.Timestamp(year=y, month=2, day=1)\n",
    "                bill_node.add_date(fd)\n",
    "\n",
    "                if not versions:\n",
    "                    return\n",
    "\n",
    "                self.add_node(bill_node)\n",
    "\n",
    "                for version in versions:\n",
    "                    digest = features[version]['digest']\n",
    "                    if str(digest) == 'nan' or version.endswith('VETO'):\n",
    "                        continue\n",
    "\n",
    "                    digest_emb = digest_embeddings.get(digest, None)\n",
    "                    if digest_emb is None:\n",
    "                        continue\n",
    "\n",
    "                    version_node = BillVersion(\n",
    "                        bill, version, digest_emb,\n",
    "                        features[version]['VoteRequired'],\n",
    "                        features[version]['LocalProgram'],\n",
    "                        features[version]['FiscalCommittee'],\n",
    "                        features[version]['TaxLevy'],\n",
    "                        features[version]['Urgency']\n",
    "                    )\n",
    "\n",
    "                    self.add_node(version_node)\n",
    "                    if version not in self.versions:\n",
    "                        self.versions.append(version)\n",
    "                    versions_.append(version)\n",
    "\n",
    "\n",
    "                orders = [vnums.get(v) for v in versions]\n",
    "                sorted_versions = [s for _, s in sorted(zip(orders, versions))]\n",
    "                for i, s in enumerate(sorted_versions):\n",
    "                    v = self.get_node('bill_version', s)\n",
    "                    if v is None or bill_node is None:\n",
    "                        continue\n",
    "                    self.add_edge(Version(v, bill_node, 1))\n",
    "                    if i > 0:\n",
    "                        prev_v = self.get_node('bill_version', sorted_versions[i - 1])\n",
    "                        if prev_v is not None:\n",
    "                            self.add_edge(siblingVersion(prev_v, v, 1))\n",
    "                o = outcome.get(bill, 0)\n",
    "                bill_node.add_outcome(o)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Error processing bill {bill}: {e}\")\n",
    "\n",
    "        for bill in tqdm(bill_ids):\n",
    "            process_single_bill(bill)\n",
    "\n",
    "    def add_legislators(self, legislators_):\n",
    "        for legislator in tqdm(legislators_):\n",
    "            leg_name = legislators[legislator]\n",
    "            party = leg_parties.get(leg_name)\n",
    "            occupation = leg_occupations.get(leg_name)\n",
    "            occ_embedding = occ_embeddings.get(occupation, None)\n",
    "            legislator_node = Legislator(legislator, party, occ_embedding)\n",
    "            self.add_node(legislator_node)\n",
    "            terms = politicians.loc[politicians['full_name'] == leg_name, ['Term', 'District No.', 'chamber']].drop_duplicates()\n",
    "            for _, term in terms.iterrows():\n",
    "                term_node = LegislatorTerm(term['Term'], legislator, term['chamber'], term['District No.'])\n",
    "                self.add_node(term_node)\n",
    "                self.add_edge(samePerson(legislator_node, term_node))\n",
    "\n",
    "    def add_committees(self, committees_df):\n",
    "        for _, row in tqdm(committees_df[['committee_clean', 'Term', 'chamber']].drop_duplicates().iterrows(), total=committees_df[['committee_clean', 'Term', 'chamber']].drop_duplicates().shape[0]):\n",
    "            committee_name = committee_embeddings.get(row['committee_clean'].lower(), None)\n",
    "            committee_id = committee_codes.get(row['committee_clean'].lower(), None)\n",
    "            chamber = chamber_encoder.transform([row['chamber']])[0] if row['chamber'] in chamber_encoder.classes_ else -1\n",
    "            committee_node = Committee(committee_id, committee_name, chamber, row['Term'])\n",
    "            self.add_node(committee_node)\n",
    "            term = row['Term']\n",
    "            members = politicians.loc[(politicians['committee_clean'] == row['committee_clean']) & (politicians['Term'] == row['Term']), ['position', 'full_name', 'chamber']].drop_duplicates()\n",
    "            for _, member in members.iterrows():\n",
    "                leg_id = legislator_codes[member['full_name']]\n",
    "                chamber = chamber_encoder.transform([member['chamber']])[0] if member['chamber'] in chamber_encoder.classes_ else -1\n",
    "                leg_node_id = f\"{leg_id}_{term}_{chamber}\"\n",
    "                leg_node = self.get_node('legislator_term', leg_node_id)\n",
    "                if (leg_node is not None) & (committee_node is not None):\n",
    "                    self.add_edge(CommitteeMembership(leg_node, committee_node, member['position'], 1))\n",
    "                    committee_node.add_member(leg_node_id)\n",
    "                    leg_node.add_committee(committee_name)\n",
    "\n",
    "    def add_votes(self):\n",
    "        for _, row in tqdm(voting.loc[voting['bill_ID'].isin(bill_ids)].iterrows(), total=voting.loc[voting['bill_ID'].isin(bill_ids)].shape[0]):\n",
    "            bv_id = row['bv_id']\n",
    "            v_node = self.get_node('bill_version', bv_id)\n",
    "            if v_node is None:\n",
    "                continue\n",
    "            last = row['legislator_name'].strip().lower()\n",
    "            house = chamber_encoder.transform([row['chamber']])[0] if row['chamber'] in chamber_encoder.classes_ else -1\n",
    "            legislator = legislators_last_names.get((row['chamber'].lower(), last, row['term']), None)\n",
    "            if legislator is None:\n",
    "                if len(last.split(' ')) > 1:\n",
    "                    legislator = row['legislator_name']\n",
    "                else:\n",
    "                    continue\n",
    "            legislator_id = legislator_codes.get(legislator, None)\n",
    "            leg_term_node = self.get_node('legislator_term', f\"{legislator_id}_{row['term']}_{house}\")\n",
    "            if leg_term_node is None:\n",
    "                continue\n",
    "            vote = row['vote_code']\n",
    "            motion_id = row['motion_id']\n",
    "            motion_text = motion_codes.get(motion_id, None)\n",
    "            if motion_text is None:\n",
    "                continue\n",
    "            if row['location_code'] not in ['AFLOOR', 'SFLOOR']:\n",
    "                actions = v_node.actions\n",
    "                if row['location_code'] in actions:\n",
    "                    if row['vote_date_time'] not in actions[row['location_code']]:\n",
    "                        actions[row['location_code']].append(row['vote_date_time'])\n",
    "            if motion_text is None:\n",
    "                motion_embedding = ''\n",
    "            else:\n",
    "                motion_embedding = motion_embeddings.get(motion_text, None)\n",
    "            self.add_edge(Vote(leg_term_node, v_node, vote, motion_embedding, row['vote_date_time'], 1))\n",
    "\n",
    "\n",
    "    def add_readings(self):\n",
    "        for _, row in tqdm(hear.loc[hear['bill_id'].isin(bill_ids)].iterrows(), total=hear.loc[hear['bill_id'].isin(bill_ids)].shape[0]):\n",
    "            b_node = self.get_node('bill', row['bill_id'])\n",
    "            if b_node is None:\n",
    "                continue\n",
    "            location = row['committee_clean']\n",
    "            if location is None or location == '':\n",
    "                continue\n",
    "            term = row['year']\n",
    "            committee_id = committee_codes.get(str(location).lower(), None)\n",
    "            if committee_id is None:\n",
    "                continue\n",
    "            committee_node = self.get_node('committee', f\"{committee_id}_{term}\")\n",
    "            if committee_node is None:\n",
    "                continue\n",
    "            self.add_edge(Reading(committee_node, b_node, term, 1))\n",
    "        for _, row in tqdm(voting.loc[(voting['bv_id'].notna()) & (voting['voting_place'].notna()) & (voting['bill_ID'].isin(bill_ids)), ['bv_id', 'Date', 'voting_place']].drop_duplicates().iterrows()):\n",
    "            bv_node = self.get_node('bill_version', row['bv_id'])\n",
    "            if bv_node is None:\n",
    "                continue\n",
    "            location = row['voting_place']\n",
    "            if location is None or location == '':\n",
    "                continue\n",
    "            date = pd.Timestamp(row['Date'])\n",
    "            committee_id = committee_codes.get(str(location).lower(), None)\n",
    "            if committee_id is None:\n",
    "                continue\n",
    "            year = int(date.year)\n",
    "            committee_node = self.get_node('committee', f\"{committee_id}_{year}\")\n",
    "            if committee_node is None:\n",
    "                continue\n",
    "            self.add_edge(Reading(committee_node, bv_node, date, 1))\n",
    "\n",
    "\n",
    "    def add_sponsorships(self, sponsors):\n",
    "        for _, row in tqdm(sponsors.loc[sponsors['Name'].apply(lambda x: isinstance(x, str))].iterrows(), total=sponsors.shape[0]):\n",
    "            version = row['bill_ID']\n",
    "            version_node = self.get_node('bill_version', version)\n",
    "            if version_node is None:\n",
    "                continue\n",
    "            if row['House'] == 'UNKNOWN':\n",
    "                com = author_com_matches.get(row['Name'], None)\n",
    "                year = row['term'].split('-')[0]\n",
    "                com_node = self.get_node('committee', f\"{com}_{year}\")\n",
    "                if com_node is None:\n",
    "                   continue\n",
    "                self.add_edge(Sponsorship(com_node, version_node, row['Contribution'], 1))\n",
    "                continue\n",
    "            else:\n",
    "                if row['Name'].strip() in ['Mark Stone', 'Cristina Garcia', 'John Campbell', 'Bill Campbell', 'Eduardo Garcia']:\n",
    "                    leg_name = row['Name']\n",
    "                else:\n",
    "                    leg_name = row['full_name']\n",
    "                    if leg_name is None or leg_name == '':\n",
    "                        continue\n",
    "                house = chamber_encoder.transform([row['House'].lower()])[0] if row['House'].lower() in chamber_encoder.classes_ else -1\n",
    "                leg_id = legislator_codes.get(leg_name)\n",
    "                leg_node = self.get_node('legislator_term', f\"{leg_id}_{row['term']}_{house}\")\n",
    "                if leg_node is None:\n",
    "                    continue\n",
    "\n",
    "                self.add_edge(Sponsorship(leg_node, version_node, row['Contribution'], 1))\n",
    "\n",
    "\n",
    "    def add_lobbyists(self, lobbyists):\n",
    "        for key in tqdm(lobbyists.keys(), total=len(lobbyists.keys())):\n",
    "            lobbyist = LobbyFirm(text_clean(key), lobbyists[key])\n",
    "            self.add_node(lobbyist)\n",
    "\n",
    "    def add_donations(self, donations):\n",
    "        for _, row in tqdm(donations.iterrows(), total=donations.shape[0]):\n",
    "            firm = row['FIRM_NAME']\n",
    "            firm_node = self.get_node('lobby_firm', text_clean(firm))\n",
    "            if firm_node is None:\n",
    "                continue\n",
    "            if row['clean_beneficiary'] in committee_codes:\n",
    "                com = committee_codes.get(row['clean_beneficiary'])\n",
    "                year = row['term'].split('-')[0]\n",
    "                com_node = self.get_node('committee', f\"{com}_{year}\")\n",
    "                if com_node is None:\n",
    "                    continue\n",
    "                self.add_edge(Donation(firm_node, com_node, row['BENE_AMT'], row['EXPN_DATE'], 'Lobbying', 1))\n",
    "                firm_node.add_donation(row['BENE_AMT'])\n",
    "\n",
    "            else:\n",
    "                dicti = pol_names_terms.get((row['clean_beneficiary'], row['term']), None)\n",
    "                chamber = dicti['chamber'] if dicti is not None else None\n",
    "                name = dicti['name'] if dicti is not None else None\n",
    "                if chamber is None or name is None:\n",
    "                    continue\n",
    "                chamber = chamber_encoder.transform([chamber])[0] if chamber in chamber_encoder.classes_ else -1\n",
    "                leg_id = legislator_codes.get(name)\n",
    "                leg_node = self.get_node('legislator_term', f\"{leg_id}_{row['term']}_{chamber}\")\n",
    "                if leg_node is None:\n",
    "                    continue\n",
    "                self.add_edge(Donation(firm_node, leg_node, row['BENE_AMT'], row['EXPN_DATE'], 'Lobbying', 1))\n",
    "                firm_node.add_donation(row['BENE_AMT'])\n",
    "\n",
    "    def add_donors(self, donors):\n",
    "\n",
    "        for donor in tqdm(donors.keys(), total=len(donors.keys())):\n",
    "            donor_embedding = donors[donor]\n",
    "            donor = Donor(donor, donor_embedding)\n",
    "            self.add_node(donor)\n",
    "\n",
    "    def add_contributions(self, contributions):\n",
    "        for _, row in tqdm(contributions.iterrows(), total=contributions.shape[0]):\n",
    "            expender = row['ExpenderName']\n",
    "            expender_node = self.get_node('donor', expender)\n",
    "            if expender_node is None:\n",
    "                continue\n",
    "            recipient = row['matched_target_name']\n",
    "            recipient_id = legislator_codes.get(recipient)\n",
    "            chamber = chamber_encoder.transform([row['chamber']])[0] if row['chamber'] in chamber_encoder.classes_ else -1\n",
    "            recipient_node = self.get_node('legislator_term', f\"{recipient_id}_{row['Term']}_{chamber}\")\n",
    "            if recipient_node is None:\n",
    "                continue\n",
    "            self.add_edge(Donation(expender_node, recipient_node, row['Amount'], row['DateEnd'], 'CampaignContribution', 1))\n",
    "            expender_node.add_donation(row['Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47669/47669 [07:19<00:00, 108.53it/s]\n",
      "100%|██████████| 506/506 [00:02<00:00, 239.80it/s]\n",
      "100%|█████████▉| 702154/702157 [01:18<00:00, 8979.93it/s] \n"
     ]
    }
   ],
   "source": [
    "builder = GraphBuilder()\n",
    "builder.add_bills(bill_ids, bill_titles, bill_subjects, title_embeddings, subject_embeddings, features)\n",
    "builder.add_legislators(legislators)\n",
    "builder.add_sponsorships(sponsors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1699/1699 [00:09<00:00, 187.06it/s]\n",
      "100%|██████████| 1165/1165 [00:00<00:00, 215258.33it/s]\n",
      "100%|██████████| 122317/122317 [00:04<00:00, 24704.74it/s]\n",
      "100%|██████████| 506/506 [00:00<00:00, 379595.39it/s]\n",
      "100%|██████████| 9151/9151 [00:00<00:00, 10447.89it/s]\n"
     ]
    }
   ],
   "source": [
    "builder.add_committees(politicians)\n",
    "builder.add_lobbyists(lobbying_firms_embeddings)\n",
    "builder.add_donations(lob)\n",
    "builder.add_donors(donor_embeddings)\n",
    "builder.add_contributions(campaign_contributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5965170/5965170 [3:04:11<00:00, 539.76it/s]   \n",
      "100%|██████████| 120596/120596 [00:02<00:00, 46107.76it/s]\n",
      "99460it [02:31, 658.37it/s]  \n"
     ]
    }
   ],
   "source": [
    "builder.add_votes()\n",
    "builder.add_readings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = graph_data['nodes']\n",
    "edges = graph_data['edges']\n",
    "nodes_by_type = graph_data['nodes_by_type']\n",
    "edges_by_type = graph_data['edges_by_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_subject_embeddings = {v: k for k, v in subject_embeddings.items()}\n",
    "bill_subjects = {}\n",
    "\n",
    "for node in nodes_by_type['bill']:\n",
    "    if node.features['subject'] in rev_subject_embeddings:\n",
    "        subj = rev_subject_embeddings[node.features['subject']]\n",
    "        bill_subjects[node.id] = subj\n",
    "\n",
    "with open('bill_subjects.json', 'w') as f:\n",
    "    json.dump(bill_subjects, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = [g for g in globals() if g not in ['builder', 'graph_data', 'nodes', 'edges', 'nodes_by_type', 'edges_by_type', 'rev_subject_embeddings', 'bill_subjects', 'author_type_map', 'author_levels', 'measure_types', 'parties', 'chambers', 'outcome_mapping', 'measure_encoder', 'party_encoder', 'chamber_encoder', 'pos_encoder', 'feature_encoders', 'positions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in old:\n",
    "    if o in globals():\n",
    "        del globals()[o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data = torch.load('data4.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import hashlib\n",
    "import json\n",
    "import re\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "\n",
    "timestamp_edges = [\n",
    "    ('donor', 'donated_to', 'legislator_term'),\n",
    "    ('legislator_term', 'rev_donated_to', 'donor'),\n",
    "    ('lobby_firm', 'lobbied', 'legislator_term'),\n",
    "    ('lobby_firm', 'lobbied', 'committee'),\n",
    "    ('committee', 'rev_lobbied', 'lobby_firm'),\n",
    "    ('legislator_term', 'rev_lobbied', 'lobby_firm'),\n",
    "    ('bill_version', 'rev_voted_on', 'legislator_term'),\n",
    "    ('legislator_term', 'voted_on', 'bill_version'),\n",
    "    ('committee', 'read', 'bill'),\n",
    "    ('bill', 'rev_read', 'committee'),\n",
    "]\n",
    "timestamp_nodes = ['legislator_term', 'bill_version', 'bill']\n",
    "\n",
    "def _to_ts(t: Any) -> float:\n",
    "    try:\n",
    "        if isinstance(t, (int, float)) and 1900 <= t and t <= 2100:\n",
    "            return datetime.datetime(int(t), 6, 15).timestamp()\n",
    "        elif (isinstance(t, str) or isinstance(t, float)) and (float(t) < 2100 and float(t) > 1900):\n",
    "            return datetime.datetime(int(float(t)), 6, 15).timestamp()\n",
    "        elif float(t) > 0 and float(t) < 1990:\n",
    "            return float(t)\n",
    "        elif float(t) > 17000000.0:\n",
    "            return float(t)\n",
    "        elif isinstance(t, datetime.datetime):\n",
    "            return t.timestamp()\n",
    "        else:\n",
    "            return float(t) * 1e9\n",
    "    except:\n",
    "        return datetime.datetime(2000, 6, 15).timestamp()\n",
    "\n",
    "def _is_time_key(k: Any) -> bool:\n",
    "    if k is None:\n",
    "        return False\n",
    "    s = str(k).lower()\n",
    "    return ('date' in s) or ('time' in s) or (s in ('term', 'year'))\n",
    "\n",
    "def _parse_term_value(v: Any) -> Any:\n",
    "    if v is None:\n",
    "        return None\n",
    "    if isinstance(v, str):\n",
    "        m = re.search(r'\\d{4}', v)\n",
    "        if m:\n",
    "            return int(m.group(0))\n",
    "    if isinstance(v, (list, tuple)) and len(v) > 0:\n",
    "        return _parse_term_value(v[0])\n",
    "    return v\n",
    "\n",
    "def _looks_like_datetime_string(s: str) -> bool:\n",
    "    s = s.strip()\n",
    "    if not s:\n",
    "        return False\n",
    "    if re.search(r'\\d{4}-\\d{1,2}-\\d{1,2}', s):\n",
    "        return True\n",
    "    if re.search(r'\\d{1,2}/\\d{1,2}/\\d{2,4}', s):\n",
    "        return True\n",
    "    if re.search(r'(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)', s.lower()) and re.search(r'\\d{4}', s):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def _stable_hash_to_int(s: str) -> int:\n",
    "    return int(hashlib.blake2s(s.encode('utf-8'), digest_size=4).hexdigest(), 16)\n",
    "\n",
    "# —— vector parsing helpers ——\n",
    "\n",
    "_VECTOR_DICT_KEYS = ('embedding', 'vector', 'values', 'data', 'array')\n",
    "\n",
    "def _maybe_unwrap_dict_container(x: Any) -> Any:\n",
    "    if isinstance(x, dict):\n",
    "        for k in _VECTOR_DICT_KEYS:\n",
    "            if k in x:\n",
    "                return x[k]\n",
    "    return x\n",
    "\n",
    "def _parse_numeric_string_vector(s: str) -> np.ndarray | None:\n",
    "    # Try JSON list first\n",
    "    s2 = s.strip()\n",
    "    if not s2:\n",
    "        return None\n",
    "    if s2.startswith('[') and s2.endswith(']'):\n",
    "        try:\n",
    "            arr = json.loads(s2)\n",
    "            return _to_float_array(arr)\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Try comma-separated or whitespace-separated floats\n",
    "    if (',' in s2) or (re.search(r'\\s', s2) and len(s2.split()) > 1):\n",
    "        tokens = [t for t in re.split(r'[,\\s]+', s2) if t]\n",
    "        try:\n",
    "            vals = [float(t) for t in tokens]\n",
    "            return np.asarray(vals, dtype=np.float32)\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def _to_float_array(x: Any) -> np.ndarray | None:\n",
    "    x = _maybe_unwrap_dict_container(x)\n",
    "\n",
    "    # torch.Tensor\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        try:\n",
    "            arr = x.detach().cpu().numpy()\n",
    "            return arr.astype(np.float32).reshape(-1)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    # pandas Series\n",
    "    if isinstance(x, pd.Series):\n",
    "        try:\n",
    "            arr = x.to_numpy()\n",
    "            return np.asarray(arr, dtype=np.float32).reshape(-1)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    # numpy array\n",
    "    if isinstance(x, np.ndarray):\n",
    "        if x.dtype.kind in 'iuf':\n",
    "            return x.astype(np.float32).reshape(-1)\n",
    "        # object/other → try elementwise float cast\n",
    "        try:\n",
    "            flat = x.reshape(-1)\n",
    "            vals = [float(v) for v in flat]\n",
    "            return np.asarray(vals, dtype=np.float32)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    # list/tuple (possibly nested)\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        try:\n",
    "            arr = np.asarray(x, dtype=np.float32)\n",
    "            if arr.dtype.kind in 'iuf':\n",
    "                return arr.reshape(-1)\n",
    "            # if dtype not numeric, try elementwise coercion\n",
    "            flat = np.array([float(v) for v in _flatten_once(x)], dtype=np.float32)\n",
    "            return flat.reshape(-1)\n",
    "        except Exception:\n",
    "            # last resort: try manual elementwise\n",
    "            try:\n",
    "                vals = [float(v) for v in _flatten_once(x)]\n",
    "                return np.asarray(vals, dtype=np.float32).reshape(-1)\n",
    "            except Exception:\n",
    "                return None\n",
    "\n",
    "    # numeric scalar (keep as length-1 vector)\n",
    "    if isinstance(x, (int, float, np.integer, np.floating)) and not isinstance(x, bool):\n",
    "        return np.asarray([float(x)], dtype=np.float32)\n",
    "\n",
    "    # datetime-like strings → leave to time path elsewhere\n",
    "    if isinstance(x, str):\n",
    "        if _looks_like_datetime_string(x):\n",
    "            return None\n",
    "        # vector-like string?\n",
    "        vec = _parse_numeric_string_vector(x)\n",
    "        if vec is not None:\n",
    "            return vec.reshape(-1)\n",
    "        return None\n",
    "\n",
    "    return None\n",
    "\n",
    "def _flatten_once(seq):\n",
    "    for el in seq:\n",
    "        if isinstance(el, (list, tuple, np.ndarray)):\n",
    "            for sub in (el if isinstance(el, (list, tuple)) else el.tolist()):\n",
    "                yield sub\n",
    "        else:\n",
    "            yield el\n",
    "\n",
    "def _as1d_numeric_or_time(x: Any) -> np.ndarray | None:\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return np.array([1.0 if x else 0.0], dtype=np.float32)\n",
    "    if isinstance(x, (pd.Timestamp, np.datetime64)):\n",
    "        return np.array([pd.to_datetime(x, errors='coerce').value / 1e9], dtype=np.float32)\n",
    "    # try general numeric/vector coercion\n",
    "    return _to_float_array(x)\n",
    "\n",
    "def _collect_keys_allow_all(dicts: List[Dict[str, Any]]) -> List[str]:\n",
    "    keys = set()\n",
    "    for d in dicts:\n",
    "        if not d:\n",
    "            continue\n",
    "        keys.update(d.keys())\n",
    "    return sorted(keys)\n",
    "\n",
    "def _key_dims_with_default(dicts: List[Dict[str, Any]], keys: List[str], default_dim: int = 1) -> Dict[str, int]:\n",
    "    dims: Dict[str, int] = {}\n",
    "    for k in keys:\n",
    "        m = 0\n",
    "        for d in dicts:\n",
    "            v = d.get(k, None)\n",
    "            arr = _as1d_numeric_or_time(v)\n",
    "            if arr is not None:\n",
    "                m = max(m, int(arr.shape[0]))\n",
    "        dims[k] = m if m > 0 else default_dim\n",
    "    return dims\n",
    "\n",
    "def _fit_categorical_maps(\n",
    "    dicts: List[Dict[str, Any]],\n",
    "    keys: List[str],\n",
    "    dims: Dict[str, int],\n",
    "    max_card_per_key: int = 50000\n",
    ") -> Dict[str, Dict[str, int]]:\n",
    "    cat_maps: Dict[str, Dict[str, int]] = {}\n",
    "    for k in keys:\n",
    "        if dims[k] != 1:\n",
    "            continue\n",
    "        seen: Dict[str, int] = {}\n",
    "        next_id = 1  # 0 reserved for missing/unknown\n",
    "        for d in dicts:\n",
    "            v = d.get(k, None)\n",
    "            if v is None:\n",
    "                continue\n",
    "            if isinstance(v, str) and not _looks_like_datetime_string(v) and _parse_numeric_string_vector(v) is None:\n",
    "                if v not in seen:\n",
    "                    if len(seen) < max_card_per_key:\n",
    "                        seen[v] = next_id\n",
    "                        next_id += 1\n",
    "        if seen:\n",
    "            cat_maps[k] = seen\n",
    "    return cat_maps\n",
    "\n",
    "def _encode_scalar_from_category(v: Any, k: str, cat_maps: Dict[str, Dict[str, int]]) -> float:\n",
    "    if v is None:\n",
    "        return 0.0\n",
    "    if isinstance(v, bool):\n",
    "        return 1.0 if v else 0.0\n",
    "    if isinstance(v, (int, float, np.integer, np.floating)) and not isinstance(v, bool):\n",
    "        return float(v)\n",
    "    if isinstance(v, str) and not _looks_like_datetime_string(v) and _parse_numeric_string_vector(v) is None:\n",
    "        mapping = cat_maps.get(k, None)\n",
    "        if mapping is not None:\n",
    "            return float(mapping.get(v, 0))\n",
    "        return float((_stable_hash_to_int(v) % 65535) + 1)\n",
    "    return 0.0\n",
    "\n",
    "def _stack_with_categories(\n",
    "    dicts: List[Dict[str, Any]],\n",
    "    keys: List[str],\n",
    "    dims: Dict[str, int],\n",
    "    cat_maps: Dict[str, Dict[str, int]]\n",
    ") -> torch.Tensor:\n",
    "    if not keys:\n",
    "        return torch.empty((len(dicts), 0), dtype=torch.float32)\n",
    "    rows: List[np.ndarray] = []\n",
    "    for d in dicts:\n",
    "        parts: List[np.ndarray] = []\n",
    "        for k in keys:\n",
    "            v = d.get(k, None)\n",
    "            arr = _as1d_numeric_or_time(v)\n",
    "            if arr is None:\n",
    "                if dims[k] == 1:\n",
    "                    parts.append(np.array([_encode_scalar_from_category(v, k, cat_maps)], dtype=np.float32))\n",
    "                else:\n",
    "                    parts.append(np.zeros(dims[k], dtype=np.float32))\n",
    "            else:\n",
    "                if arr.shape[0] < dims[k]:\n",
    "                    pad = np.zeros(dims[k], dtype=np.float32)\n",
    "                    pad[:arr.shape[0]] = arr\n",
    "                    arr = pad\n",
    "                elif arr.shape[0] > dims[k]:\n",
    "                    arr = arr[:dims[k]]\n",
    "                parts.append(arr.astype(np.float32))\n",
    "        rows.append(np.concatenate(parts, axis=0))\n",
    "    mat = np.vstack(rows).astype(np.float32)\n",
    "    mat = np.nan_to_num(mat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return torch.from_numpy(mat)\n",
    "\n",
    "\n",
    "def _prep_node_dicts(ntype: str, nlist: List[Any]) -> List[Dict[str, Any]]:\n",
    "    dicts: List[Dict[str, Any]] = []\n",
    "    use_time = ntype in timestamp_nodes\n",
    "    for n in nlist:\n",
    "        d = dict((n.features or {}))\n",
    "        if use_time and d:\n",
    "            for k in list(d.keys()):\n",
    "                if _is_time_key(k):\n",
    "                    v = d[k]\n",
    "                    if k == 'term':\n",
    "                        v = _parse_term_value(v)\n",
    "                    d[k] = _to_ts(v)\n",
    "        dicts.append(d)\n",
    "    return dicts\n",
    "\n",
    "def _prep_edge_dicts_filtered(\n",
    "    etype: Tuple[str, str, str],\n",
    "    elist: List[Any],\n",
    "    id_map_src: Dict[Any, int],\n",
    "    id_map_dst: Dict[Any, int],\n",
    ") -> Tuple[List[int], List[int], List[Dict[str, Any]]]:\n",
    "    use_time = etype in timestamp_edges\n",
    "    src_idx: List[int] = []\n",
    "    dst_idx: List[int] = []\n",
    "    dicts: List[Dict[str, Any]] = []\n",
    "    for e in elist:\n",
    "        si = id_map_src.get(e.source.id, None)\n",
    "        di = id_map_dst.get(e.target.id, None)\n",
    "        if si is None or di is None:\n",
    "            continue\n",
    "        d = dict((e.attributes or {}))\n",
    "        if use_time and d:\n",
    "            for k in list(d.keys()):\n",
    "                if _is_time_key(k):\n",
    "                    d[k] = _to_ts(d[k])\n",
    "        src_idx.append(si)\n",
    "        dst_idx.append(di)\n",
    "        dicts.append(d)\n",
    "    return src_idx, dst_idx, dicts\n",
    "\n",
    "\n",
    "def _load_bill_labels(path: str):\n",
    "    with open(path, 'r') as f:\n",
    "        raw = json.load(f)\n",
    "    vals = list(raw.values())\n",
    "    if all(isinstance(v, (int, np.integer)) for v in vals):\n",
    "        label_map = {}\n",
    "        inv = None\n",
    "    else:\n",
    "        uniq = sorted(set(map(str, vals)))\n",
    "        label_map = {s: i for i, s in enumerate(uniq)}\n",
    "        inv = {i: s for s, i in label_map.items()}\n",
    "    return raw, label_map, inv\n",
    "\n",
    "\n",
    "def build_heterodata_compact_with_time_and_labels(gb, labels_json_path: str):\n",
    "    data = HeteroData()\n",
    "\n",
    "    # map original IDs to 0..N-1 per node type\n",
    "    id_maps: Dict[str, Dict[Any, int]] = {\n",
    "        ntype: {n.id: i for i, n in enumerate(nlist)}\n",
    "        for ntype, nlist in gb.nodes_by_type.items()\n",
    "    }\n",
    "\n",
    "    # — Nodes\n",
    "    for ntype, nlist in gb.nodes_by_type.items():\n",
    "        if not nlist:\n",
    "            continue\n",
    "        dicts = _prep_node_dicts(ntype, nlist)\n",
    "        keys = _collect_keys_allow_all(dicts)\n",
    "        dims = _key_dims_with_default(dicts, keys, default_dim=1)\n",
    "        cat_maps = _fit_categorical_maps(dicts, keys, dims)\n",
    "        x = _stack_with_categories(dicts, keys, dims, cat_maps)\n",
    "        if x.numel() == 0:\n",
    "            data[ntype].num_nodes = len(nlist)\n",
    "        else:\n",
    "            data[ntype].x = x\n",
    "\n",
    "    # — Edges\n",
    "    for etype, elist in gb.edges_by_type.items():\n",
    "        st, rel, dt = etype\n",
    "        if not elist or st not in id_maps or dt not in id_maps:\n",
    "            continue\n",
    "\n",
    "        id_map_src = id_maps[st]\n",
    "        id_map_dst = id_maps[dt]\n",
    "\n",
    "        src, dst, dicts = _prep_edge_dicts_filtered(etype, elist, id_map_src, id_map_dst)\n",
    "        if not src:\n",
    "            continue\n",
    "\n",
    "        edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "        keys = _collect_keys_allow_all(dicts)\n",
    "        dims = _key_dims_with_default(dicts, keys, default_dim=1)\n",
    "        cat_maps = _fit_categorical_maps(dicts, keys, dims)\n",
    "        edge_attr = _stack_with_categories(dicts, keys, dims, cat_maps)\n",
    "\n",
    "        data[etype].edge_index = edge_index\n",
    "        if edge_attr.numel() > 0:\n",
    "            data[etype].edge_attr = edge_attr\n",
    "\n",
    "    # — Bill labels & outcomes\n",
    "    if 'bill' in gb.nodes_by_type and gb.nodes_by_type['bill']:\n",
    "        raw_labels, label_map, _ = _load_bill_labels(labels_json_path)\n",
    "        bills = gb.nodes_by_type['bill']\n",
    "        clusters: List[int] = []\n",
    "        ys: List[int] = []\n",
    "        for n in bills:\n",
    "            bid = n.id\n",
    "            v = raw_labels.get(bid, None)\n",
    "            if v is None:\n",
    "                clusters.append(-1)\n",
    "            else:\n",
    "                if label_map:\n",
    "                    clusters.append(label_map.get(str(v), -1))\n",
    "                else:\n",
    "                    try:\n",
    "                        clusters.append(int(v))\n",
    "                    except:\n",
    "                        clusters.append(-1)\n",
    "            yv = getattr(n, 'outcome', None)\n",
    "            ys.append(-1 if yv is None else int(yv))\n",
    "        data['bill'].cluster = torch.tensor(clusters, dtype=torch.long)\n",
    "        data['bill'].y = torch.tensor(ys, dtype=torch.long)\n",
    "\n",
    "    # — Final numeric cleanup\n",
    "    for store in (list(data.node_stores) + list(data.edge_stores)):\n",
    "        for k, v in list(store.items()):\n",
    "            if isinstance(v, torch.Tensor) and v.dtype.is_floating_point:\n",
    "                torch.nan_to_num_(v, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    return data, id_maps\n",
    "\n",
    "data, id_maps = build_heterodata_compact_with_time_and_labels(builder, 'bill_labels.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data, 'data4.pt', _use_new_zipfile_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('node_id_map.json', 'w') as f:\n",
    "    json.dump(id_maps, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node type 'bill': 47658 nodes, feature shape: torch.Size([47658, 770])\n",
      "Node type 'bill_version': 200955 nodes, feature shape: torch.Size([200955, 390])\n",
      "Node type 'legislator': 506 nodes, feature shape: torch.Size([506, 385])\n",
      "Node type 'legislator_term': 1448 nodes, feature shape: torch.Size([1448, 4])\n",
      "Node type 'committee': 1699 nodes, feature shape: torch.Size([1699, 65])\n",
      "Node type 'lobby_firm': 1165 nodes, feature shape: torch.Size([1165, 384])\n",
      "Node type 'donor': 506 nodes, feature shape: torch.Size([506, 64])\n",
      "Edge type '('bill_version', 'is_version', 'bill')': 200955 edges, feature shape: N/A\n",
      "Edge type '('bill_version', 'priorVersion', 'bill_version')': 154342 edges, feature shape: N/A\n",
      "Edge type '('legislator', 'samePerson', 'legislator_term')': 1448 edges, feature shape: N/A\n",
      "Edge type '('legislator_term', 'wrote', 'bill_version')': 582740 edges, feature shape: torch.Size([582740, 1])\n",
      "Edge type '('legislator_term', 'member_of', 'committee')': 17563 edges, feature shape: torch.Size([17563, 1])\n",
      "Edge type '('lobby_firm', 'lobbied', 'legislator_term')': 182 edges, feature shape: torch.Size([182, 2])\n",
      "Edge type '('lobby_firm', 'lobbied', 'committee')': 3811 edges, feature shape: torch.Size([3811, 2])\n",
      "Edge type '('donor', 'donated_to', 'legislator_term')': 2324 edges, feature shape: torch.Size([2324, 2])\n",
      "Edge type '('legislator_term', 'voted_on', 'bill_version')': 4943957 edges, feature shape: torch.Size([4943957, 18])\n",
      "Edge type '('bill_version', 'read', 'committee')': 48796 edges, feature shape: torch.Size([48796, 1])\n"
     ]
    }
   ],
   "source": [
    "for ntype in data.node_types:\n",
    "    print(f\"Node type '{ntype}': {data[ntype].num_nodes} nodes, feature shape: {data[ntype].x.shape if 'x' in data[ntype] else 'N/A'}\")\n",
    "for etype in data.edge_types:\n",
    "    print(f\"Edge type '{etype}': {data[etype].edge_index.shape[1]} edges, feature shape: {data[etype].edge_attr.shape if 'edge_attr' in data[etype] else 'N/A'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
