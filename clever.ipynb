{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import GATConv, HeteroConv, GATv2Conv, SAGEConv\n",
    "import time, pickle, inspect\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('data.pt', weights_only=False)\n",
    "metadata = (data.node_types, data.edge_types)\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  bill_version={\n",
       "    x=[1, 390],\n",
       "    num_nodes=193262,\n",
       "  },\n",
       "  bill={\n",
       "    x=[1, 770],\n",
       "    y=[1],\n",
       "    num_nodes=45357,\n",
       "  },\n",
       "  legislator={\n",
       "    x=[1, 385],\n",
       "    num_nodes=508,\n",
       "  },\n",
       "  legislator_term={\n",
       "    x=[1, 3],\n",
       "    num_nodes=1448,\n",
       "  },\n",
       "  committee={\n",
       "    x=[1, 385],\n",
       "    num_nodes=1707,\n",
       "  },\n",
       "  lobby_firm={\n",
       "    x=[1, 384],\n",
       "    num_nodes=1325,\n",
       "  },\n",
       "  donor={\n",
       "    x=[1, 384],\n",
       "    num_nodes=1136,\n",
       "  },\n",
       "  (bill_version, is_version, bill)={\n",
       "    edge_index=[2, 142952],\n",
       "    edge_attr=[142952, 1],\n",
       "    num_edges=142952,\n",
       "  },\n",
       "  (bill_version, priorVersion, bill_version)={\n",
       "    edge_index=[2, 100658],\n",
       "    num_edges=100658,\n",
       "  },\n",
       "  (legislator, samePerson, legislator_term)={\n",
       "    edge_index=[2, 1448],\n",
       "    num_edges=1448,\n",
       "  },\n",
       "  (legislator_term, member_of, committee)={\n",
       "    edge_index=[2, 17633],\n",
       "    edge_attr=[17633, 1],\n",
       "    num_edges=17633,\n",
       "  },\n",
       "  (lobby_firm, lobbied, legislator_term)={\n",
       "    edge_index=[2, 65280],\n",
       "    edge_attr=[65280, 2],\n",
       "    num_edges=65280,\n",
       "  },\n",
       "  (lobby_firm, lobbied, committee)={\n",
       "    edge_index=[2, 3419],\n",
       "    edge_attr=[3419, 2],\n",
       "    num_edges=3419,\n",
       "  },\n",
       "  (donor, donated_to, legislator_term)={\n",
       "    edge_index=[2, 7028],\n",
       "    edge_attr=[7028, 2],\n",
       "    num_edges=7028,\n",
       "  },\n",
       "  (legislator_term, voted_on, bill_version)={\n",
       "    edge_index=[2, 5801959],\n",
       "    edge_attr=[5801959, 386],\n",
       "    num_edges=5801959,\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input_dims.pkl', 'rb') as f:\n",
    "    input_dims = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preprocess(data):\n",
    "    def date_to_float(t):\n",
    "        if t.dtype == torch.float32:\n",
    "            return t\n",
    "        return (t.float() / 86_400)\n",
    "\n",
    "    for rel in data.edge_types:\n",
    "        attrs = data[rel].edge_attr\n",
    "        if attrs is None:\n",
    "            continue\n",
    "        for k,v in attrs.items():\n",
    "            if k == \"date\":\n",
    "                attrs[k] = date_to_float(v)\n",
    "\n",
    "    scalers = {}\n",
    "    for rel in data.edge_types:\n",
    "        attrs = data[rel].edge_attr\n",
    "        if attrs is None:\n",
    "            continue\n",
    "        num_cols = {k:v for k,v in attrs.items() if v.dim()==2 and v.size(1)==1}\n",
    "        if num_cols:\n",
    "            M = torch.cat(list(num_cols.values()), dim=0).cpu().numpy()\n",
    "            scaler = StandardScaler().fit(M)\n",
    "            scalers[rel] = scaler\n",
    "            for k,v in num_cols.items():\n",
    "                attrs[k] = torch.as_tensor(\n",
    "                    scaler.transform(v.cpu().numpy()), dtype=torch.float32)\n",
    "    return scalers\n",
    "scalers = preprocess(data)\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeAttrEncoder(nn.Module):\n",
    "    def __init__(self, attr_dict_sample: dict[str, torch.Tensor],\n",
    "                 bottleneck=128, out_dim=256):\n",
    "        super().__init__()\n",
    "        mods = []\n",
    "        for k, v in attr_dict_sample.items():\n",
    "            if v.dim() == 2 and v.size(1) == 1:\n",
    "                mods.append((k, nn.Linear(1, bottleneck, bias=False)))\n",
    "            elif v.size(1) == 384:\n",
    "                mods.append((k, nn.Linear(384, bottleneck, bias=False)))\n",
    "            else:\n",
    "                continue\n",
    "        self.feat_proj = nn.ModuleDict(mods)\n",
    "        self.mlp       = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(len(mods)*bottleneck, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, attr_dict: dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        if not attr_dict:\n",
    "            raise ValueError(\"EdgeAttrEncoder got empty attr_dict\")\n",
    "\n",
    "        max_len = max(v.size(0) for v in attr_dict.values())\n",
    "        device  = next(self.parameters()).device\n",
    "\n",
    "        feats = []\n",
    "        for k, proj in self.feat_proj.items():\n",
    "            col = attr_dict[k].to(device)\n",
    "            if col.size(0) < max_len:\n",
    "                pad_rows = max_len - col.size(0)\n",
    "                col = F.pad(col, (0, 0, 0, pad_rows))\n",
    "            feats.append(proj(col))\n",
    "\n",
    "        return self.mlp(torch.cat(feats, dim=1))\n",
    "\n",
    "class BigEncoder(nn.Module):\n",
    "    def __init__(self, metadata, in_dims: dict,\n",
    "                 hidden=256, layers=3):\n",
    "        super().__init__()\n",
    "        self.lin = nn.ModuleDict({\n",
    "            ntype: nn.Linear(in_dim, hidden)\n",
    "            for ntype, in_dim in in_dims.items()\n",
    "        })\n",
    "        self.convs = nn.ModuleList([\n",
    "            HeteroConv({rel: SAGEConv((-1, -1), hidden)\n",
    "                        for rel in metadata[1]}, aggr=\"mean\")\n",
    "            for _ in range(layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        h_dict = {nt: F.relu(self.lin[nt](x)) for nt, x in x_dict.items()}\n",
    "\n",
    "        for conv in self.convs:\n",
    "            out_dict = conv(h_dict, edge_index_dict)\n",
    "\n",
    "            for nt in h_dict:\n",
    "                if nt not in out_dict:\n",
    "                    out_dict[nt] = h_dict[nt]\n",
    "\n",
    "            h_dict = {nt: F.relu(h) for nt, h in out_dict.items()}\n",
    "\n",
    "        return h_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkRecon(nn.Module):\n",
    "    def __init__(self, edge_attr_encoders: nn.ModuleDict, weight=1.0):\n",
    "        super().__init__()\n",
    "        self.bce       = nn.BCEWithLogitsLoss()\n",
    "        self.mse       = nn.MSELoss()\n",
    "        self.encoders  = edge_attr_encoders\n",
    "        self.weight    = weight\n",
    "\n",
    "    def forward(self, z, data, num_neg=1):\n",
    "        loss = torch.tensor(0., device=z[next(iter(z))].device)\n",
    "        for rel, ei in data.edge_index_dict.items():\n",
    "            s_t, _, d_t = rel\n",
    "            src, dst = ei\n",
    "            pos_log  = (z[s_t][src] * z[d_t][dst]).sum(-1)\n",
    "            pos_loss = self.bce(pos_log, torch.ones_like(pos_log))\n",
    "            attr_dict = data[rel].edge_attr\n",
    "            if str(rel) in self.encoders and attr_dict and len(attr_dict) > 0:\n",
    "                enc  = self.encoders[str(rel)]\n",
    "                tgt  = enc(attr_dict)\n",
    "                proj = nn.Linear(z[s_t].size(1), tgt.size(1),\n",
    "                                bias=False, device=z[s_t].device)\n",
    "                pred = proj(z[s_t][src] * z[d_t][dst])\n",
    "                pos_loss = pos_loss + self.mse(pred, tgt)\n",
    "\n",
    "            neg_dst = torch.randint(0, data[d_t].num_nodes, (src.size(0)*num_neg,), device=src.device)\n",
    "            neg_src = src.repeat(num_neg)\n",
    "            neg_log = (z[s_t][neg_src] * z[d_t][neg_dst]).sum(-1)\n",
    "            neg_loss = self.bce(neg_log,\n",
    "                                torch.zeros_like(neg_log))\n",
    "            loss = loss + pos_loss + neg_loss\n",
    "        return loss * self.weight\n",
    "\n",
    "class MaskedFeatRecon(nn.Module):\n",
    "    def __init__(self, mask_prob=0.05, weight=0.3):\n",
    "        super().__init__()\n",
    "        self.mask_prob = mask_prob\n",
    "        self.weight    = weight\n",
    "        self.mse       = nn.MSELoss()\n",
    "\n",
    "    def forward(self, encoder, data, z_full):\n",
    "        device = z_full[next(iter(z_full))].device\n",
    "        loss   = torch.tensor(0., device=device)\n",
    "\n",
    "        for nt in data.node_types:\n",
    "            x = data[nt].x\n",
    "            node_mask = torch.rand(x.size(0), device=device) < self.mask_prob\n",
    "            if not node_mask.any():\n",
    "                continue\n",
    "\n",
    "            x_dict_masked = {k: v for k, v in data.x_dict.items()}\n",
    "            x_masked = x.clone()\n",
    "            x_masked[node_mask] = 0.\n",
    "            x_dict_masked[nt] = x_masked\n",
    "\n",
    "            z_masked = encoder(x_dict_masked, data.edge_index_dict)\n",
    "\n",
    "            loss = loss + self.mse(z_masked[nt][node_mask],\n",
    "                                   z_full[nt][node_mask])\n",
    "\n",
    "        return loss * self.weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emeliasprott/miniconda3/envs/ml/lib/python3.12/site-packages/torch_geometric/nn/conv/hetero_conv.py:76: UserWarning: There exist node types ({'committee'}) whose representations do not get updated during message passing as they do not occur as destination type in any edge type. This may lead to unexpected behavior.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/250] loss=192.3003  time=65.6s\n",
      "[02/250] loss=9.8913  time=101.7s\n",
      "[03/250] loss=9.8773  time=76.1s\n",
      "[04/250] loss=9.8579  time=81.0s\n",
      "[05/250] loss=9.8555  time=75.5s\n",
      "[06/250] loss=9.8325  time=79.7s\n",
      "[07/250] loss=9.8259  time=54.1s\n",
      "[08/250] loss=9.8148  time=84.7s\n",
      "[09/250] loss=9.8001  time=83.7s\n",
      "[10/250] loss=9.7933  time=88.7s\n",
      "[11/250] loss=9.7775  time=69.8s\n",
      "[12/250] loss=9.7711  time=86.0s\n",
      "[13/250] loss=9.7524  time=64.0s\n",
      "[14/250] loss=9.7403  time=69.8s\n",
      "[15/250] loss=9.7153  time=50.0s\n",
      "[16/250] loss=9.6961  time=67.9s\n",
      "[17/250] loss=9.6614  time=60.1s\n",
      "[18/250] loss=9.6251  time=56.2s\n",
      "[19/250] loss=9.5705  time=78.7s\n",
      "[20/250] loss=9.5147  time=63.7s\n",
      "[21/250] loss=9.4460  time=70.5s\n",
      "[22/250] loss=9.3892  time=90.6s\n",
      "[23/250] loss=9.3593  time=88.9s\n",
      "[24/250] loss=9.3467  time=50.3s\n",
      "[25/250] loss=9.2982  time=67.3s\n",
      "[26/250] loss=9.2427  time=70.4s\n",
      "[27/250] loss=9.1961  time=67.7s\n",
      "[28/250] loss=9.1283  time=69.9s\n",
      "[29/250] loss=9.0844  time=72.0s\n",
      "[30/250] loss=9.0211  time=62.7s\n",
      "[31/250] loss=8.9881  time=78.5s\n",
      "[32/250] loss=8.9342  time=135.5s\n",
      "[33/250] loss=8.8859  time=102.0s\n",
      "[34/250] loss=8.8798  time=89.1s\n",
      "[35/250] loss=8.8420  time=89.4s\n",
      "[36/250] loss=8.8157  time=86.5s\n",
      "[37/250] loss=8.8028  time=77.7s\n",
      "[38/250] loss=8.7646  time=76.3s\n",
      "[39/250] loss=8.7439  time=107.0s\n",
      "[40/250] loss=8.7032  time=109.1s\n",
      "[41/250] loss=8.7131  time=101.6s\n",
      "[42/250] loss=8.6814  time=145.7s\n",
      "[43/250] loss=8.6593  time=73.3s\n",
      "[44/250] loss=8.6531  time=390.0s\n",
      "[45/250] loss=8.6399  time=1021.8s\n",
      "[46/250] loss=8.6359  time=90.7s\n",
      "[47/250] loss=8.6121  time=84.1s\n",
      "[48/250] loss=8.6027  time=55.0s\n",
      "[49/250] loss=8.6063  time=78.2s\n",
      "[50/250] loss=8.5906  time=68.1s\n",
      "[51/250] loss=8.5587  time=68.4s\n",
      "[52/250] loss=8.5486  time=64.3s\n",
      "[53/250] loss=8.5268  time=71.1s\n",
      "[54/250] loss=8.5451  time=70.8s\n",
      "[55/250] loss=8.5152  time=95.6s\n",
      "[56/250] loss=8.5102  time=70.0s\n",
      "[57/250] loss=8.5019  time=73.0s\n",
      "[58/250] loss=8.5062  time=73.9s\n",
      "[59/250] loss=8.4812  time=74.7s\n",
      "[60/250] loss=8.4755  time=66.7s\n",
      "[61/250] loss=8.4694  time=44.7s\n",
      "[62/250] loss=8.4617  time=62.8s\n",
      "[63/250] loss=8.4428  time=66.3s\n",
      "[64/250] loss=8.4474  time=87.9s\n",
      "[65/250] loss=8.4497  time=77.6s\n",
      "[66/250] loss=8.4465  time=57.4s\n",
      "[67/250] loss=8.4331  time=71.6s\n",
      "[68/250] loss=8.4214  time=45.1s\n",
      "[69/250] loss=8.4210  time=65.2s\n",
      "[70/250] loss=8.4208  time=73.1s\n",
      "[71/250] loss=8.4032  time=39.3s\n",
      "[72/250] loss=8.4054  time=39.0s\n",
      "[73/250] loss=8.3784  time=66.1s\n",
      "[74/250] loss=8.3817  time=58.2s\n",
      "[75/250] loss=8.3780  time=84.9s\n",
      "[76/250] loss=8.3670  time=88.4s\n",
      "[77/250] loss=8.3404  time=74.2s\n",
      "[78/250] loss=8.3521  time=124.8s\n",
      "[79/250] loss=8.3429  time=102.5s\n",
      "[80/250] loss=8.3301  time=112.5s\n",
      "[81/250] loss=8.3274  time=50.9s\n",
      "[82/250] loss=8.2956  time=87.8s\n",
      "[83/250] loss=8.3131  time=90.1s\n",
      "[84/250] loss=8.2792  time=62.9s\n",
      "[85/250] loss=8.2917  time=59.3s\n",
      "[86/250] loss=8.2553  time=82.1s\n",
      "[87/250] loss=8.2583  time=95.2s\n",
      "[88/250] loss=8.2511  time=98.4s\n",
      "[89/250] loss=8.2358  time=98.4s\n",
      "[90/250] loss=8.2172  time=1083.6s\n",
      "[91/250] loss=8.2155  time=105.9s\n",
      "[92/250] loss=8.2130  time=114.7s\n",
      "[93/250] loss=8.1664  time=111.9s\n",
      "[94/250] loss=8.1952  time=112.2s\n",
      "[95/250] loss=8.1759  time=117.9s\n",
      "[96/250] loss=8.1705  time=97.9s\n",
      "[97/250] loss=8.1673  time=105.0s\n",
      "[98/250] loss=8.1692  time=92.8s\n",
      "[99/250] loss=8.1458  time=98.0s\n",
      "[100/250] loss=8.1338  time=106.2s\n",
      "[101/250] loss=8.1317  time=95.3s\n",
      "[102/250] loss=8.1139  time=89.7s\n",
      "[103/250] loss=8.1096  time=105.9s\n",
      "[104/250] loss=8.0848  time=92.8s\n",
      "[105/250] loss=8.0821  time=117.3s\n",
      "[106/250] loss=8.0714  time=113.9s\n",
      "[107/250] loss=8.0775  time=109.7s\n",
      "[108/250] loss=8.0854  time=100.3s\n",
      "[109/250] loss=8.0659  time=92.9s\n",
      "[110/250] loss=8.0601  time=97.2s\n",
      "[111/250] loss=8.0474  time=90.6s\n",
      "[112/250] loss=8.0526  time=93.0s\n",
      "[113/250] loss=8.0209  time=119.3s\n",
      "[114/250] loss=8.0420  time=100.8s\n",
      "[115/250] loss=8.0250  time=113.2s\n",
      "[116/250] loss=8.0197  time=6114.3s\n",
      "[117/250] loss=8.0217  time=3416.6s\n",
      "[118/250] loss=7.9934  time=1652.8s\n",
      "[119/250] loss=7.9935  time=143.8s\n",
      "[120/250] loss=7.9896  time=150.2s\n",
      "[121/250] loss=8.0038  time=150.1s\n",
      "[122/250] loss=7.9726  time=140.8s\n",
      "[123/250] loss=7.9979  time=141.3s\n",
      "[124/250] loss=7.9755  time=145.4s\n",
      "[125/250] loss=7.9777  time=153.8s\n",
      "[126/250] loss=7.9619  time=139.8s\n",
      "[127/250] loss=7.9570  time=152.8s\n",
      "[128/250] loss=7.9557  time=151.8s\n",
      "[129/250] loss=7.9592  time=206.6s\n",
      "[130/250] loss=7.8994  time=173.0s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, EPOCHS+\u001b[32m1\u001b[39m):\n\u001b[32m     39\u001b[39m     t0   = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     loss = \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     dt   = time.time() - t0\n\u001b[32m     42\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     43\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mloss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  time=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mrun_epoch\u001b[39m\u001b[34m(encoder, tasks, data, opt, device)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks:\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(task, MaskedFeatRecon):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m         loss = \u001b[43mtask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_full\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# pass z_full\u001b[39;00m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     10\u001b[39m         loss = task(z_full, data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mMaskedFeatRecon.forward\u001b[39m\u001b[34m(self, encoder, data, z_full)\u001b[39m\n\u001b[32m     55\u001b[39m x_dict_masked[nt] = x_masked\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Encode once with the row‑masked features\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m z_masked = \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict_masked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# MSE between masked‑row embeddings and original embeddings\u001b[39;00m\n\u001b[32m     61\u001b[39m loss = loss + \u001b[38;5;28mself\u001b[39m.mse(z_masked[nt][node_mask],\n\u001b[32m     62\u001b[39m                        z_full[nt][node_mask])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mBigEncoder.forward\u001b[39m\u001b[34m(self, x_dict, edge_index_dict)\u001b[39m\n\u001b[32m     51\u001b[39m h_dict = {nt: F.relu(\u001b[38;5;28mself\u001b[39m.lin[nt](x)) \u001b[38;5;28;01mfor\u001b[39;00m nt, x \u001b[38;5;129;01min\u001b[39;00m x_dict.items()}\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.convs:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     out_dict = \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m nt \u001b[38;5;129;01min\u001b[39;00m h_dict:\n\u001b[32m     57\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m nt \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m out_dict:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/torch_geometric/nn/conv/hetero_conv.py:158\u001b[39m, in \u001b[36mHeteroConv.forward\u001b[39m\u001b[34m(self, *args_dict, **kwargs_dict)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_edge_level_arg:\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m out = \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dst \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m out_dict:\n\u001b[32m    161\u001b[39m     out_dict[dst] = [out]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/torch_geometric/nn/conv/sage_conv.py:134\u001b[39m, in \u001b[36mSAGEConv.forward\u001b[39m\u001b[34m(self, x, edge_index, size)\u001b[39m\n\u001b[32m    131\u001b[39m     x = (\u001b[38;5;28mself\u001b[39m.lin(x[\u001b[32m0\u001b[39m]).relu(), x[\u001b[32m1\u001b[39m])\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m out = \u001b[38;5;28mself\u001b[39m.lin_l(out)\n\u001b[32m    137\u001b[39m x_r = x[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/folders/z8/jkjxx5pj447bytbqv8pkw9nh0000gn/T/torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_hlkz3imq.py:173\u001b[39m, in \u001b[36mpropagate\u001b[39m\u001b[34m(self, edge_index, x, size)\u001b[39m\n\u001b[32m    167\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.update(\n\u001b[32m    168\u001b[39m         out,\n\u001b[32m    169\u001b[39m     )\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmutable_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m     \u001b[38;5;66;03m# Begin Message Forward Pre Hook #######################################\u001b[39;00m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/folders/z8/jkjxx5pj447bytbqv8pkw9nh0000gn/T/torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_hlkz3imq.py:83\u001b[39m, in \u001b[36mcollect\u001b[39m\u001b[34m(self, edge_index, x, size)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_x_0, Tensor):\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_size(size, \u001b[32m0\u001b[39m, _x_0)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     x_j = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_index_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_x_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_j\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     85\u001b[39m     x_j = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/torch_geometric/nn/conv/message_passing.py:267\u001b[39m, in \u001b[36mMessagePassing._index_select\u001b[39m\u001b[34m(self, src, index)\u001b[39m\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m src.index_select(\u001b[38;5;28mself\u001b[39m.node_dim, index)\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_index_select_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/torch_geometric/nn/conv/message_passing.py:271\u001b[39m, in \u001b[36mMessagePassing._index_select_safe\u001b[39m\u001b[34m(self, src, index)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_index_select_safe\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: Tensor, index: Tensor) -> Tensor:\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    273\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m index.numel() > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index.min() < \u001b[32m0\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def run_epoch(encoder, tasks, data, opt, device):\n",
    "    encoder.train()\n",
    "    z_full = encoder(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    loss_total = torch.tensor(0., device=device)\n",
    "    for task in tasks:\n",
    "        if isinstance(task, MaskedFeatRecon):\n",
    "            loss = task(encoder, data, z_full)   # pass z_full\n",
    "        else:\n",
    "            loss = task(z_full, data)\n",
    "        loss_total = loss_total + loss\n",
    "\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "    loss_total.backward()\n",
    "    opt.step()\n",
    "    return float(loss_total)\n",
    "\n",
    "\n",
    "encoder  = BigEncoder(data.metadata(), input_dims).to(device)\n",
    "edge_attr_enc = nn.ModuleDict()\n",
    "for rel in data.edge_types:\n",
    "    attrs = data[rel].edge_attr\n",
    "    if attrs is None:\n",
    "        continue\n",
    "    usable = {k: v for k, v in attrs.items()\n",
    "              if (v.dim() == 2 and (v.size(1) == 1 or v.size(1) == 384)) or (v.dim() == 1 and v.size(0) != 0)}\n",
    "    if usable:\n",
    "        edge_attr_enc[str(rel)] = EdgeAttrEncoder(usable)\n",
    "edge_attr_enc = edge_attr_enc.to(device)\n",
    "\n",
    "\n",
    "tasks = [\n",
    "    LinkRecon(edge_attr_enc, weight=1.0),\n",
    "    MaskedFeatRecon(mask_prob=0.05, weight=0.3),\n",
    "]\n",
    "opt = torch.optim.AdamW(encoder.parameters(), lr=1e-3, weight_decay=1e-4, amsgrad=True)\n",
    "EPOCHS = 250\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    t0   = time.time()\n",
    "    loss = run_epoch(encoder, tasks, data, opt, device)\n",
    "    dt   = time.time() - t0\n",
    "    print(f\"[{epoch:02d}/{EPOCHS}] \"\n",
    "            f\"loss={loss:.4f}  time={dt:.1f}s\")\n",
    "\n",
    "    encoder.eval()\n",
    "    with torch.inference_mode():\n",
    "        z = encoder(data.x_dict, data.edge_index_dict)\n",
    "    torch.save(z, \"node_embeddings_3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "california_topics = [\n",
    "    \"Public health\",\n",
    "    \"Mental health services\",\n",
    "    \"Medi-Cal and health insurance\",\n",
    "    \"Substance abuse and harm reduction\",\n",
    "    \"Child welfare and foster care\",\n",
    "    \"Developmental and disability services\",\n",
    "    \"Elder care and long-term support\",\n",
    "\n",
    "    \"K-12 education funding\",\n",
    "    \"Curriculum and instruction\",\n",
    "    \"Higher education and UC/CSU systems\",\n",
    "    \"Community colleges\",\n",
    "    \"School construction and facilities\",\n",
    "    \"Special education\",\n",
    "    \"Charter schools and school choice\",\n",
    "\n",
    "    \"Climate change and carbon reduction\",\n",
    "    \"Air quality and pollution control\",\n",
    "    \"Water supply and drought\",\n",
    "    \"Coastal protection\",\n",
    "    \"Wildfire prevention and forestry\",\n",
    "    \"Environmental justice\",\n",
    "    \"Recycling and waste management\",\n",
    "\n",
    "    \"Criminal justice reform\",\n",
    "    \"Police oversight and accountability\",\n",
    "    \"Firearms and gun control\",\n",
    "    \"Corrections and parole\",\n",
    "    \"Emergency services and disaster response\",\n",
    "    \"Human trafficking prevention\",\n",
    "\n",
    "    \"State budget and fiscal policy\",\n",
    "    \"Personal and corporate income taxes\",\n",
    "    \"Sales and use taxes\",\n",
    "    \"Proposition 13 and property tax\",\n",
    "    \"State bonds and financing\",\n",
    "    \"Local government finance\",\n",
    "\n",
    "    \"Workplace safety and Cal/OSHA\",\n",
    "    \"Paid family leave\",\n",
    "    \"Minimum wage and wage theft\",\n",
    "    \"Public employee unions\",\n",
    "    \"Employment discrimination and DEI\",\n",
    "    \"Workforce development\",\n",
    "\n",
    "    \"Redistricting and electoral reform\",\n",
    "    \"Voter access and registration\",\n",
    "    \"Campaign finance and lobbying\",\n",
    "    \"Open meetings and transparency (Brown Act)\",\n",
    "    \"Public records and data access\",\n",
    "    \"Government agency operations\",\n",
    "\n",
    "    \"Roads and highways (Caltrans)\",\n",
    "    \"Public transit and rail\",\n",
    "    \"High-speed rail\",\n",
    "    \"Ports and logistics\",\n",
    "    \"Vehicle emissions and EV policy\",\n",
    "    \"Infrastructure resilience\",\n",
    "\n",
    "    \"Affordable housing development\",\n",
    "    \"Zoning and local control\",\n",
    "    \"Tenant protections and rent control\",\n",
    "    \"Homelessness and supportive housing\",\n",
    "    \"CEQA and environmental permitting\",\n",
    "    \"Redevelopment and gentrification\",\n",
    "\n",
    "    \"Electric grid and reliability\",\n",
    "    \"Renewable energy incentives\",\n",
    "    \"Utility regulation (CPUC)\",\n",
    "    \"Natural gas and oil regulation\",\n",
    "    \"Wildfire liability (PG&E)\",\n",
    "    \"Broadband and digital equity\",\n",
    "\n",
    "    \"Immigration and sanctuary laws\",\n",
    "    \"LGBTQ+ rights\",\n",
    "    \"Gender equity and reproductive health\",\n",
    "    \"Racial equity and anti-discrimination\",\n",
    "    \"Food insecurity and public benefits\",\n",
    "    \"Language access and cultural inclusion\",\n",
    "\n",
    "    \"Water rights and agriculture\",\n",
    "    \"Pesticide regulation\",\n",
    "    \"Farmworker labor conditions\",\n",
    "    \"Fisheries and marine policy\",\n",
    "    \"Wildlife conservation\",\n",
    "    \"Timber and land management\",\n",
    "\n",
    "    \"Small business support\",\n",
    "    \"Technology and innovation\",\n",
    "    \"Cannabis regulation\",\n",
    "    \"Insurance industry oversight\",\n",
    "    \"Economic stimulus and recovery\",\n",
    "    \"Licensing and regulation (e.g., BAR, ABC)\",\n",
    "\n",
    "    \"Financial services and predatory lending\",\n",
    "    \"Data privacy and cybersecurity\",\n",
    "    \"Product safety and recalls\",\n",
    "    \"Housing scams and fraud\",\n",
    "    \"Telemarketing and spam regulation\",\n",
    "\n",
    "    \"Freedom of speech and assembly\",\n",
    "    \"Facial recognition and surveillance\",\n",
    "    \"Disability rights\",\n",
    "    \"Due process protections\",\n",
    "    \"First Amendment in schools/public spaces\",\n",
    "\n",
    "    \"State-local relations\",\n",
    "    \"Tribal affairs\",\n",
    "    \"Military and veterans issues\",\n",
    "    \"COVID-19 response and recovery\",\n",
    "    \"Technology in government\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gnn_data.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m d = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgnn_data.pt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/torch/serialization.py:1425\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1423\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1426\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1427\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1428\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1429\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1430\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/torch/serialization.py:751\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[32m    750\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m751\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/torch/serialization.py:732\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'gnn_data.pt'"
     ]
    }
   ],
   "source": [
    "d = torch.load('gnn_data.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  bill_version={\n",
       "    x={\n",
       "      digest=[142952, 384],\n",
       "      VoteRequired=[142952, 1],\n",
       "      LocalProgram=[142952, 1],\n",
       "      FiscalCommittee=[142952, 1],\n",
       "      TaxLevy=[142952, 1],\n",
       "      Urgency=[142952, 1],\n",
       "    },\n",
       "  },\n",
       "  bill={\n",
       "    x={\n",
       "      title=[43937, 384],\n",
       "      subject=[43937, 384],\n",
       "      measure_type=[43937, 1],\n",
       "    },\n",
       "  },\n",
       "  legislator={\n",
       "    x={\n",
       "      party=[508, 1],\n",
       "      occupation=[508, 384],\n",
       "    },\n",
       "  },\n",
       "  legislator_term={\n",
       "    x={\n",
       "      chamber=[1448, 1],\n",
       "      district=[1448, 1],\n",
       "      term=[1448, 1],\n",
       "    },\n",
       "  },\n",
       "  committee={\n",
       "    x={\n",
       "      name=[1707, 384],\n",
       "      chamber=[1707, 1],\n",
       "    },\n",
       "  },\n",
       "  lobby_firm={\n",
       "    x={ name=[1206, 384] },\n",
       "  },\n",
       "  donor={\n",
       "    x={ name=[429, 384] },\n",
       "  },\n",
       "  (bill_version, Version, bill)={\n",
       "    edge_index=[2, 146100],\n",
       "    edge_attr={ order=[146100, 1] },\n",
       "  },\n",
       "  (bill_version, nextVersion, bill_version)={\n",
       "    edge_index=[2, 102093],\n",
       "    edge_attr={},\n",
       "  },\n",
       "  (legislator_term, samePerson, legislator)={\n",
       "    edge_index=[2, 1448],\n",
       "    edge_attr={},\n",
       "  },\n",
       "  (committee, member, legislator_term)={\n",
       "    edge_index=[2, 17633],\n",
       "    edge_attr={ position=[17633, 1] },\n",
       "  },\n",
       "  (legislator_term, lobbying, lobby_firm)={\n",
       "    edge_index=[2, 65280],\n",
       "    edge_attr={\n",
       "      amount=[65280, 1],\n",
       "      date=[65280, 1],\n",
       "      expn_dscr=[65127, 384],\n",
       "    },\n",
       "  },\n",
       "  (committee, lobbying, lobby_firm)={\n",
       "    edge_index=[2, 3419],\n",
       "    edge_attr={\n",
       "      amount=[3419, 1],\n",
       "      date=[3419, 1],\n",
       "      expn_dscr=[3408, 384],\n",
       "    },\n",
       "  },\n",
       "  (legislator_term, campaigncontribution, donor)={\n",
       "    edge_index=[2, 7028],\n",
       "    edge_attr={\n",
       "      amount=[7028, 1],\n",
       "      date=[7028, 1],\n",
       "    },\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be868bf50a04e649ff625e7410f5ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', truncate_dim=256)\n",
    "topic_embs = model.encode(california_topics, normalize_embeddings=True, convert_to_tensor=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m kmeans = KMeans(n_clusters=k, random_state=\u001b[32m40\u001b[39m)\n\u001b[32m     16\u001b[39m cluster_ids = kmeans.fit_predict(z_text_all.cpu())\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m score = \u001b[43msilhouette_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_text_all\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkmeans\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlabels_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/metrics/cluster/_unsupervised.py:139\u001b[39m, in \u001b[36msilhouette_score\u001b[39m\u001b[34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[39m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    138\u001b[39m         X, labels = X[indices], labels[indices]\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(\u001b[43msilhouette_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:189\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m func_sig = signature(func)\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/metrics/cluster/_unsupervised.py:303\u001b[39m, in \u001b[36msilhouette_samples\u001b[39m\u001b[34m(X, labels, metric, **kwds)\u001b[39m\n\u001b[32m    299\u001b[39m kwds[\u001b[33m\"\u001b[39m\u001b[33mmetric\u001b[39m\u001b[33m\"\u001b[39m] = metric\n\u001b[32m    300\u001b[39m reduce_func = functools.partial(\n\u001b[32m    301\u001b[39m     _silhouette_reduce, labels=labels, label_freqs=label_freqs\n\u001b[32m    302\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m303\u001b[39m results = \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    304\u001b[39m intra_clust_dists, inter_clust_dists = results\n\u001b[32m    305\u001b[39m intra_clust_dists = np.concatenate(intra_clust_dists)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:2261\u001b[39m, in \u001b[36mpairwise_distances_chunked\u001b[39m\u001b[34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[39m\n\u001b[32m   2259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reduce_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2260\u001b[39m     chunk_size = D_chunk.shape[\u001b[32m0\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m2261\u001b[39m     D_chunk = \u001b[43mreduce_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2262\u001b[39m     _check_chunk_size(D_chunk, chunk_size)\n\u001b[32m   2263\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m D_chunk\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.12/site-packages/sklearn/metrics/cluster/_unsupervised.py:180\u001b[39m, in \u001b[36m_silhouette_reduce\u001b[39m\u001b[34m(D_chunk, start, labels, label_freqs)\u001b[39m\n\u001b[32m    178\u001b[39m         sample_weights = D_chunk[i]\n\u001b[32m    179\u001b[39m         sample_labels = labels\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m         cluster_distances[i] += \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbincount\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m            \u001b[49m\u001b[43msample_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminlength\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabel_freqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# intra_index selects intra-cluster distances within cluster_distances\u001b[39;00m\n\u001b[32m    185\u001b[39m end = start + n_chunk_samples\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "z_text_all = torch.cat([\n",
    "    z['bill'],\n",
    "    z['bill_version'],\n",
    "    z['committee'],\n",
    "    z['legislator'],\n",
    "    z['donor'],\n",
    "    z['lobby_firm'],\n",
    "], dim=0)\n",
    "\n",
    "k = 25\n",
    "kmeans = KMeans(n_clusters=k, random_state=40)\n",
    "cluster_ids = kmeans.fit_predict(z_text_all.cpu())\n",
    "score = silhouette_score(z_text_all.cpu(), kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "centroids = kmeans.cluster_centers_\n",
    "sims = cosine_similarity(centroids, topic_embs.cpu().numpy())\n",
    "top_topic_ids = sims.argmax(axis=1)\n",
    "cluster_topic_labels = [california_topics[i] for i in top_topic_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'cluster': list(range(k)),\n",
    "    'predicted_topic': cluster_topic_labels,\n",
    "    'most_similar_score': sims.max(axis=1)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
